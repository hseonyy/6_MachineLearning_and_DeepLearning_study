{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","## 인공신경망 활용\n","-----\n","- pytorch를 사용하여 기본적인 인공신경망을 생성하여 이미지 분류기를 생성합니다.\n","- 데이터셋: [Fashion MNIST](https://pytorch.org/vision/0.9/datasets.html#fashion-mnist)\n","\n","- **reference**\n","    - https://tutorials.pytorch.kr/beginner/basics/buildmodel_tutorial.html\n","    - https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"],"metadata":{"id":"UZfgLyXW88Nh"}},{"cell_type":"markdown","source":["## Fashion MNIST Classifier\n","----\n","Fashion MNIST 데이터셋을 사용하여 옷의 품목을 구분하는 분류기를 신경망을 사용하여 구현해봅니다."],"metadata":{"id":"MtFXwWlM-f_a"}},{"cell_type":"markdown","source":["# 1번\n","- 필요한 모듈을 모두 이곳에 나열하세요\n","- 2점"],"metadata":{"id":"UdsAY_OFiAwA"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision.transforms import ToTensor\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"uElb3wYUv9qi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2번\n","- FashionMNIST 데이터(train, test)를 불러오세요\n","- 2점"],"metadata":{"id":"izKdPzZu7zvd"}},{"cell_type":"code","source":["# train(학습용) 데이터셋 로드\n","train_data = datasets.FashionMNIST(root='data',\n","                                   train=True,        # 학습용 데이터셋 설정(True)\n","                                   download=True,\n","                                   transform=ToTensor()\n","                                  )\n","\n","# test(학습용) 데이터셋 로드\n","test_data = datasets.FashionMNIST(root='data',\n","                                  train=False,        # 검증용 데이터셋 설정(False)\n","                                  download=True,\n","                                  transform=ToTensor()\n","                                 )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iR0XXlRPYC_x","executionInfo":{"status":"ok","timestamp":1721350290111,"user_tz":-540,"elapsed":18396,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"6b6ca03d-d337-4c98-e531-fee1e4ba4a25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:13<00:00, 1984090.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 176634.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3232314.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 20389307.83it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# 3번\n","- train, test DataLoader를 만듭니다.\n","- 배치사이즈: 64\n","- 2점"],"metadata":{"id":"7Vg9INIm94Nt"}},{"cell_type":"code","source":["# 배치사이즈: 64\n","batch_size = 64 # batch_size 지정\n","num_workers = 8 # Thread 숫자 지정 (병렬 처리에 활용할 쓰레드 숫자 지정)"],"metadata":{"id":"Rdstqlek1m0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train, test DataLoader\n","train_loader = torch.utils.data.DataLoader(train_data,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(test_data,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          num_workers=num_workers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgeFi7q0dLyi","executionInfo":{"status":"ok","timestamp":1721350290111,"user_tz":-540,"elapsed":10,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"11f37b6e-4086-4dbf-b8d6-42223db9369f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"markdown","source":["# 4번\n","- Device 설정은 GPU로 합니다\n","- 2점"],"metadata":{"id":"pDqQL8xBdXfc"}},{"cell_type":"code","source":["# device 설정 (cuda:0 혹은 cpu)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"W5rfIbWdwrUr","executionInfo":{"status":"ok","timestamp":1721350290111,"user_tz":-540,"elapsed":9,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd1ef625-1587-49a6-f382-bd6989c8f273"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["# 5번\n","- train, test의 shape를 확인합니다.\n","- 2점"],"metadata":{"id":"LPFgyjYn-wgO"}},{"cell_type":"code","source":["# train, test의 shape를 확인\n","print(train_data.data.shape)\n","print(test_data.data.shape)"],"metadata":{"id":"E0jHzAjg1-yu","executionInfo":{"status":"ok","timestamp":1721350290111,"user_tz":-540,"elapsed":8,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2cd301e8-20d7-4371-d5cb-c4c6dbbcb75b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([60000, 28, 28])\n","torch.Size([10000, 28, 28])\n"]}]},{"cell_type":"markdown","source":["# 6번\n","- train, test의 첫번째 인덱스 데이터를 이미지로 확인합니다.\n","- 2점"],"metadata":{"id":"EcwGOt2eDXtZ"}},{"cell_type":"code","source":["# train의 첫번째 인덱스 데이터를 이미지로 확인\n","# DataLoader에서 첫 번째 배치 가져오기\n","batch_train = iter(train_loader)\n","\n","# 첫 번째 인덱스의 이미지와 레이블 가져오기\n","imgs, labels = next(batch_train)\n","\n","train_img, train_label = imgs[0], labels[0]\n","\n","fig, ax = plt.subplots(figsize=(3, 4))\n","\n","# 이미지 시각화\n","ax.imshow(train_img.squeeze(), cmap='gray')\n","ax.set_title(f'Train Label: {train_label.item()}')\n","ax.axis('off')\n","\n","plt.show()"],"metadata":{"id":"wlntPz1Pqg4Z","executionInfo":{"status":"ok","timestamp":1721350749184,"user_tz":-540,"elapsed":1289,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/","height":291},"outputId":"18c470fe-11b5-44e8-a48d-d2344d6600ca"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 300x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# test의 첫번째 인덱스 데이터를 이미지로 확인\n","# DataLoader에서 첫 번째 배치 가져오기\n","batch_test = iter(test_loader)\n","\n","# 첫 번째 인덱스의 이미지와 레이블 가져오기\n","imgs2, labels2 = next(batch_test)\n","\n","test_img, test_label = imgs2[0], labels2[0]\n","\n","fig, ax = plt.subplots(figsize=(3, 4))\n","\n","# 이미지 시각화\n","ax.imshow(test_img.squeeze(), cmap='gray')\n","ax.set_title(f'Test Label: {test_label.item()}')\n","ax.axis('off')\n","\n","plt.show()"],"metadata":{"id":"2y4JrngVsUxG","executionInfo":{"status":"ok","timestamp":1721350754572,"user_tz":-540,"elapsed":2057,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/","height":291},"outputId":"fd9323c6-86b2-4c28-8baf-9fd80cca0a93"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 300x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# 7번\n","- FashionMNIST의 클래스를 labels_map 이름의 딕셔너리로 생성합니다.\n","- 2점"],"metadata":{"id":"3IZ6GO3mpZYM"}},{"cell_type":"code","source":["# 7. FashionMNIST의 클래스를 labels_map 이름의 딕셔너리로 생성\n","labels_map = {\n","    0: 'T-shirt/top',\n","    1: 'Trouser',\n","    2: 'Pullover',\n","    3: 'Dress',\n","    4: 'Coat',\n","    5: 'Sandal',\n","    6: 'Shirt',\n","    7: 'Sneaker',\n","    8: 'Bag',\n","    9: 'Ankle boot'\n","}\n","\n","# 딕셔너리 확인\n","print(labels_map)"],"metadata":{"id":"-nHIax8LjHTt","executionInfo":{"status":"ok","timestamp":1721350807335,"user_tz":-540,"elapsed":536,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"935dd0e1-0339-4735-c137-b55b876e3dde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n"]}]},{"cell_type":"markdown","source":["# 8번\n","- 2행 5열로 train 데이터를 이미지로 출력합니다.\n","- labels_map를 이용하여 이미지의 label도 함께 출력합니다.\n","- 2점"],"metadata":{"id":"RfTEDUTHjILY"}},{"cell_type":"code","source":["# 2행 5열의 이미지 그리드 생성\n","fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(12, 6))\n","\n","# 2x5 그리드에 이미지와 레이블 출력\n","for i, ax in enumerate(axes.flat):\n","    img = imgs[i].squeeze()\n","    label = labels_map[labels[i].item()]\n","    ax.imshow(img, cmap='gray')\n","    ax.set_title(label)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"id":"Mtd8NU2CgXnR","executionInfo":{"status":"ok","timestamp":1721350853792,"user_tz":-540,"elapsed":3010,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"outputId":"4e2dae10-9123-4d74-e5f3-ea983ecf7126"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# 9번\n","- reference를 참고하여 인공신경망 클래스를 설계합니다.\n","- 2점"],"metadata":{"id":"BJ9iQln4FEhF"}},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        # 입력 이미지를 1차원 벡터로 평탄화\n","        self.flatten = nn.Flatten()\n","        # 신경망 계층 정의\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512), # 입력 크기: 28x28, 출력 크기: 512\n","            nn.ReLU(),\n","            nn.Linear(512, 512),   # 입력 크기: 512, 출력 크기: 512\n","            nn.ReLU(),\n","            nn.Linear(512, 10),    # 입력 크기: 512, 출력 크기: 10 (출력 클래스 수)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)          # 입력을 평탄화\n","        logits = self.linear_relu_stack(x) # 신경망 계층 통과\n","        return logits"],"metadata":{"id":"ILKVquTp-4if"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 10번\n","- 인공신경망 객체를 GPU에 저장합니다.\n","- 2점"],"metadata":{"id":"FDgZ56RzGAN3"}},{"cell_type":"code","source":["# GPU 장치 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n","\n","# NeuralNetwork 클래스 인스턴스 생성\n","model = NeuralNetwork()\n","\n","# 모델을 지정한 장치(GPU 또는 CPU)로 이동\n","model.to(device)"],"metadata":{"id":"QauxUnzM_zcQ","executionInfo":{"status":"ok","timestamp":1721351270897,"user_tz":-540,"elapsed":547,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b473e3a1-f993-4c32-efd0-87b1d3996cba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# 11번\n","- 28*28 텐서를 GPU에 만들어 인공신경망에 input으로 넣어줍니다.\n","- 학습되지 않은 모델의 예측 결과를 출력합니다.\n","- 3점"],"metadata":{"id":"8h8h5hlVGPIl"}},{"cell_type":"code","source":["# 28x28 텐서를 GPU에 생성\n","test_input = torch.randn(1, 1, 28, 28).to(device)  # 배치 크기 1, 28x28 크기의 입력\n","\n","# 학습되지 않은 모델의 예측 결과 출력\n","model.eval()  # 모델을 평가 모드로 설정\n","with torch.no_grad():  # 기울기 계산 비활성화\n","    output = model(test_input)\n","    probabilities = F.softmax(output, dim=1)\n","    _, predicted = torch.max(probabilities, 1)\n","\n","print(f'Input Tensor: {test_input}')\n","print(f'Predicted class index: {predicted.item()}')\n","print(f'Probabilities: {probabilities}')"],"metadata":{"id":"R_-Fu2gv__t8","executionInfo":{"status":"ok","timestamp":1721354332679,"user_tz":-540,"elapsed":778,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a55be7a0-223a-4119-e6a2-1974ac20c298"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Tensor: tensor([[[[ 4.6676e-01, -2.4584e-01, -7.2009e-01,  8.4110e-01, -1.2410e+00,\n","           -4.7407e-01, -4.6162e-03,  1.2153e+00,  1.8595e+00,  3.4649e-02,\n","            2.2649e-01, -4.7351e-02,  1.0400e+00, -5.7578e-02,  6.5013e-01,\n","           -1.3447e+00, -2.5799e+00,  1.2407e+00, -2.4962e+00,  2.3351e+00,\n","            7.0796e-01,  4.2403e-01,  2.0474e+00,  9.4291e-01,  3.4892e-01,\n","           -1.0755e+00,  6.8714e-01, -1.7046e+00],\n","          [-5.3702e-01,  8.8164e-01, -6.2707e-01,  1.1168e+00, -5.0941e-01,\n","           -1.3841e-01, -1.5547e+00,  6.4781e-01,  1.0312e+00, -7.7138e-01,\n","            3.6288e-01,  6.6408e-01,  1.5487e+00, -1.7889e+00,  3.9227e-01,\n","           -9.3389e-01,  4.3369e-01,  4.3227e-01, -9.6628e-01,  4.2502e-01,\n","           -1.6821e+00,  5.5665e-01, -8.2289e-02, -7.0565e-01, -3.4625e-02,\n","           -1.0163e+00,  7.4906e-01, -1.3782e+00],\n","          [-1.1314e+00, -1.6904e+00,  1.7449e+00,  1.1324e+00, -4.6987e-02,\n","            9.2529e-01, -8.0717e-01,  7.5632e-01,  1.3981e+00,  9.5658e-01,\n","           -6.6632e-01, -1.0820e+00, -2.0034e+00,  6.7128e-01,  8.5512e-01,\n","            9.7988e-01,  8.2759e-01, -1.5455e+00, -1.4705e-01, -1.6894e+00,\n","           -1.6981e+00, -8.2609e-01,  1.1659e+00, -7.7853e-01,  1.2547e+00,\n","            1.2815e+00,  1.0091e-01, -4.7271e-01],\n","          [ 2.8559e+00, -5.7020e-02, -9.3945e-01, -2.5238e-01, -5.0686e-01,\n","            1.7028e+00, -4.2691e-01, -8.4037e-01,  3.3886e-01,  8.6255e-01,\n","            1.2097e+00,  5.3566e-01,  1.7969e-01,  1.3044e+00, -9.2322e-01,\n","            4.3250e-02,  1.5507e-02,  1.6163e+00,  1.4238e+00,  4.0840e-01,\n","           -5.5178e-02,  8.0977e-01, -3.7162e-01, -1.6180e-02, -1.3804e+00,\n","           -3.9690e-01, -5.0945e-01,  9.6546e-01],\n","          [ 9.7004e-01, -7.8005e-01,  1.2882e+00,  7.7612e-01, -1.6703e-01,\n","            1.4125e-01,  6.4281e-02,  7.8826e-01,  6.9178e-01, -7.0205e-01,\n","           -5.8559e-01,  1.0482e-01, -2.2667e+00, -1.1389e-02, -3.3694e-01,\n","           -3.5368e-01, -1.7448e-01,  3.6571e-01, -1.3645e-01,  1.6756e-01,\n","            1.7808e+00,  2.6363e-01, -1.1345e+00, -1.2508e+00, -2.5173e+00,\n","            4.2887e-02,  1.0578e+00, -1.5161e+00],\n","          [-1.0702e+00,  2.1662e-02,  4.8454e-01,  9.4149e-01, -2.0334e+00,\n","           -4.2754e-01,  1.0987e+00, -8.0998e-02, -8.2437e-01,  3.4474e-02,\n","            2.7207e-01, -9.6635e-01, -2.1961e-01,  1.3437e+00, -1.2563e+00,\n","           -4.9355e-02, -2.7484e-01, -1.5055e-01,  3.0851e-01,  1.8898e+00,\n","           -7.5079e-01, -9.3547e-01, -1.2605e+00,  4.3013e-01,  7.3706e-01,\n","           -1.1244e+00,  3.0001e-01, -3.2403e-01],\n","          [-5.7255e-01, -4.3769e-01, -1.0372e+00,  1.9677e+00, -1.5019e-01,\n","            1.6180e+00,  5.7597e-01, -1.3069e-01,  1.5974e+00, -1.2992e+00,\n","            1.1042e+00,  2.3749e-01, -1.7484e-02,  4.8549e-02,  5.8963e-01,\n","            8.3108e-01,  8.6450e-01,  3.2315e-01, -1.3426e+00,  2.1518e+00,\n","           -4.8312e-01, -7.3374e-01,  3.3606e-01, -7.5051e-01,  2.6942e-02,\n","            6.7750e-01,  1.0199e+00, -4.2716e-01],\n","          [ 7.2748e-01, -3.0984e-01, -1.0950e-01,  1.7197e+00, -2.0479e-01,\n","           -8.7265e-01,  6.9292e-01, -1.3138e+00, -9.1598e-01,  2.4676e+00,\n","            1.3726e+00, -5.7336e-01,  1.8220e-01,  4.0439e-01,  1.1724e+00,\n","            5.2654e-01, -2.0537e+00,  1.3682e+00,  8.6137e-01, -9.0461e-01,\n","            4.1525e-01,  1.7994e+00, -1.7100e-01, -9.3158e-01,  9.7532e-01,\n","           -8.5613e-01, -7.7596e-01,  1.3522e+00],\n","          [-3.7181e-01,  4.4269e-01,  4.3877e-02, -1.8066e+00, -2.1219e-01,\n","           -1.6494e+00,  7.6709e-01,  7.6752e-02, -9.9635e-01, -8.8778e-03,\n","            8.8664e-02,  8.6921e-01, -2.1569e-01,  1.5787e+00, -5.7053e-01,\n","           -6.0242e-01,  2.1260e-01, -2.7391e-01,  1.6458e+00,  2.1822e+00,\n","           -2.5062e-02, -1.4981e+00, -8.5700e-03,  6.6956e-01,  6.1346e-01,\n","            8.9922e-01, -2.1746e+00,  4.1780e-01],\n","          [ 5.0587e-01, -3.7952e-01, -1.8721e+00,  1.5656e-01, -3.6463e-02,\n","            6.1952e-01,  1.2870e+00, -1.9415e+00, -7.7581e-01,  1.1186e+00,\n","           -1.4029e+00, -2.0932e+00, -5.6364e-02,  9.1376e-01,  1.4478e+00,\n","           -1.3644e+00,  1.1759e+00,  3.6958e-01,  1.3647e+00,  1.8666e+00,\n","            2.3369e-01, -9.6851e-02, -3.8462e-01, -9.5592e-01, -1.0125e+00,\n","           -9.1809e-01, -3.1517e-01,  1.8579e+00],\n","          [-9.0489e-01, -2.4398e+00,  8.8375e-01,  3.1365e-01, -1.1462e+00,\n","           -2.3936e-01, -4.2467e-01,  4.3973e-01, -1.4018e+00, -5.6399e-01,\n","           -6.4525e-01, -6.2531e-01, -1.1745e+00, -1.2586e+00, -2.7904e+00,\n","           -3.2226e-01, -4.4203e-01, -5.2085e-01, -2.3733e-01, -1.7672e+00,\n","           -1.3823e+00,  8.3923e-01, -1.2136e-01, -1.6159e+00,  1.1207e+00,\n","            1.2529e+00,  8.0630e-01, -2.5894e-01],\n","          [-1.0668e+00, -2.6924e-01,  1.2154e+00, -3.7849e-01, -8.9883e-01,\n","            3.9631e-01,  1.5946e+00,  2.2829e+00, -1.7666e-01, -5.8216e-01,\n","           -3.2238e-01,  1.0656e+00,  1.9911e-02,  1.2357e+00, -6.5271e-01,\n","           -1.0166e+00,  1.6310e+00,  8.8540e-01, -9.4566e-01, -9.8990e-01,\n","            8.6805e-02,  7.6701e-01,  1.2117e-02,  1.3840e+00, -1.5878e-02,\n","           -4.5915e-01, -6.4236e-02,  1.7839e+00],\n","          [ 1.3068e+00,  3.5856e-01, -2.8147e-01, -1.2408e+00,  1.9218e-01,\n","            2.9017e-01,  9.7970e-02,  1.6725e-01,  1.2805e+00,  3.8330e-01,\n","            3.3580e-01, -4.3074e-01, -7.1785e-01, -7.1981e-01,  6.4379e-01,\n","            1.3388e-01, -6.1393e-01,  9.3399e-01,  4.9667e-01, -1.4858e+00,\n","           -2.2718e-01, -2.5226e-02,  1.2694e+00, -1.3979e+00, -8.8611e-01,\n","           -6.3863e-01,  2.5765e-02, -7.5065e-01],\n","          [-1.7370e-01,  5.0739e-01, -2.7620e-01, -1.3049e-01, -1.1985e+00,\n","            2.4989e+00,  1.4782e-01,  1.1299e+00,  2.9752e-01, -1.2381e+00,\n","            5.4839e-02, -8.7016e-01,  4.3800e-01, -4.7014e-01, -4.7349e-01,\n","           -1.6559e+00,  5.2569e-01,  5.2208e-01,  2.4617e+00, -6.5553e-02,\n","           -1.7575e+00, -4.2708e-01,  2.3210e+00, -1.4957e+00,  6.3924e-01,\n","           -1.4525e+00,  5.8006e-01, -1.0424e+00],\n","          [ 1.0172e+00,  5.8527e-02,  6.8482e-01,  2.9306e+00, -7.1364e-01,\n","            1.0185e+00,  6.0889e-01,  2.5608e+00,  8.9136e-01, -2.2424e-01,\n","           -4.5386e-01,  1.3243e+00,  2.8926e-02,  1.7110e+00,  2.0345e-01,\n","            1.7904e-01,  1.0381e+00, -2.3026e+00,  1.5096e+00, -1.3254e+00,\n","           -4.0884e-01, -3.8005e-01, -7.0179e-01, -4.5042e-01,  1.1114e+00,\n","            7.0231e-01, -2.7227e+00, -2.7128e+00],\n","          [ 1.4356e-01, -1.0319e+00,  1.9431e+00, -6.4345e-01, -1.5563e-01,\n","            2.8903e-02,  6.5560e-02, -1.4392e+00,  9.2591e-02,  1.3101e+00,\n","           -6.2721e-01, -3.0894e-01, -3.3219e-01,  5.2685e-01, -1.3232e-01,\n","           -1.2665e+00, -1.2179e+00,  5.7232e-02,  1.6741e+00, -8.3096e-01,\n","           -1.4224e+00, -3.0851e-01,  9.0577e-02, -2.3336e-01, -1.0815e+00,\n","            8.5848e-01, -5.6547e-01,  4.8243e-01],\n","          [-8.0238e-01, -1.3121e-01,  6.6208e-01,  5.0461e-01, -6.4241e-01,\n","           -1.7568e-01,  1.2245e+00,  6.5792e-01,  4.1576e-02,  3.5005e-01,\n","           -4.9379e-01,  2.0562e+00,  2.8254e-01,  4.1359e-01,  5.0075e-01,\n","            1.5451e+00,  1.4292e+00,  7.7491e-01, -4.9986e-01,  8.8645e-01,\n","           -7.5597e-01, -4.6858e-01, -3.5362e-01,  2.0469e+00,  1.8958e+00,\n","            8.0147e-01, -1.2226e+00,  7.6785e-02],\n","          [-1.7085e-01,  3.7353e-01,  3.9572e-02, -2.8025e-01, -1.0226e+00,\n","            1.3818e+00,  5.3309e-01,  1.0623e+00,  8.6084e-01, -1.2963e-02,\n","            1.0184e+00, -6.1718e-01,  5.5690e-01,  4.0902e-03,  6.7335e-01,\n","           -2.5493e-01,  1.4290e+00,  2.0422e+00, -2.8203e+00,  1.4039e+00,\n","           -3.8383e-01, -3.5046e-01, -2.6524e-02, -7.7764e-01,  6.0273e-02,\n","            1.7403e-01, -3.5728e-01, -1.9307e+00],\n","          [ 3.8952e-01, -6.4136e-01, -9.2981e-01,  8.0713e-01, -1.0606e+00,\n","            1.4525e+00, -2.2860e+00,  2.6507e-01,  2.8697e-01, -6.6838e-01,\n","           -7.1510e-04,  4.5257e-01, -1.1331e+00, -1.1059e-01, -1.1299e+00,\n","            5.9951e-02, -6.3482e-01, -8.7767e-01,  1.1055e+00, -9.2479e-01,\n","            1.2358e+00, -1.1100e-01, -1.1224e+00,  7.2537e-01, -8.4187e-02,\n","           -5.9213e-01, -1.9460e+00,  6.1316e-01],\n","          [ 6.2450e-01,  7.4677e-01, -5.7915e-01, -2.9917e-01,  4.1512e-02,\n","           -2.1166e+00, -1.1033e+00,  4.0802e-01,  3.4094e-01,  1.6525e-01,\n","            5.5470e-01, -9.8351e-01,  1.2818e+00, -4.0096e-01,  9.8195e-01,\n","            2.7935e+00, -9.6965e-01,  2.3545e-01, -1.4417e+00, -3.2245e-01,\n","           -8.6096e-01,  5.5466e-01, -2.4157e-01, -1.5470e+00, -1.1024e+00,\n","            3.0070e-01,  5.2633e-01, -8.5264e-02],\n","          [-1.4972e+00, -2.3357e-01, -1.1193e+00,  5.0161e-01,  4.2488e-01,\n","            1.5588e-01,  4.9715e-01, -6.2184e-01, -3.6443e-01,  2.7186e-01,\n","           -1.0961e+00,  5.0582e-02,  1.0879e-01,  7.7918e-01,  9.2180e-01,\n","           -3.0628e-01,  1.0002e-01,  3.1608e-01,  4.8696e-01,  6.0858e-01,\n","            1.1833e-01, -3.9563e-01, -4.2343e-01, -7.1492e-02, -9.3617e-01,\n","           -2.3509e-01,  2.0358e-02, -4.2156e-01],\n","          [-8.6343e-01,  6.3087e-01, -1.2277e+00, -6.8302e-01,  1.3201e+00,\n","            7.2965e-01,  2.3125e-01,  8.8845e-01, -3.8407e-01,  1.2493e+00,\n","           -5.5877e-01, -7.4806e-01,  7.7384e-01,  1.5602e+00,  2.9341e-01,\n","           -1.7516e+00, -1.3319e+00,  3.5805e-01,  6.5937e-01, -7.9070e-01,\n","            1.9232e-01,  1.8568e+00,  9.2958e-01,  1.6539e+00, -6.4628e-01,\n","            1.4562e-01, -1.2398e+00, -7.3746e-01],\n","          [ 1.1318e-01,  3.9432e-01, -3.7976e-01,  1.6854e+00,  4.8596e-01,\n","           -2.4396e-02, -7.1796e-01,  2.5378e-01,  1.3366e+00, -1.4209e-01,\n","           -6.5791e-01,  2.7040e-01, -6.6888e-01, -6.3982e-01,  1.9135e-01,\n","           -9.3544e-01, -1.9030e+00, -5.4590e-01, -1.1698e+00, -9.8070e-01,\n","           -1.1403e-02, -9.0089e-01, -2.5074e-01,  1.9238e-01,  2.5180e-01,\n","           -7.3498e-01,  6.1029e-01,  1.9377e-01],\n","          [ 1.4519e-02,  1.6273e-01,  1.9674e+00,  8.8046e-01,  6.1460e-01,\n","            9.2731e-01,  3.3780e-01, -1.4848e+00,  3.2067e-01,  1.4075e+00,\n","            5.2852e-01, -3.1066e-01, -2.4480e-02,  1.8677e+00, -8.9833e-01,\n","           -5.1089e-02, -8.2217e-01, -3.3790e-01, -4.8531e-01,  1.8006e+00,\n","           -1.8624e+00,  6.7739e-02,  8.3773e-01, -8.1005e-01, -4.2073e-01,\n","           -4.3908e-01, -1.1900e+00, -4.2704e-01],\n","          [-1.1575e+00, -2.0803e-01,  6.5109e-01, -9.3902e-01,  1.4306e-01,\n","            1.5156e+00, -1.3063e+00,  3.2338e-01,  1.1515e-01, -5.2459e-01,\n","            1.0406e-02, -3.1086e-01, -7.0905e-01,  1.4771e+00, -1.4500e+00,\n","           -6.3427e-02,  1.5314e+00,  5.9605e-02,  5.7070e-01,  3.7454e-01,\n","           -1.6779e-01, -1.2313e+00, -1.3586e-01,  1.2180e+00, -7.4041e-01,\n","           -1.5166e-01,  9.7482e-01, -6.2807e-01],\n","          [ 1.3391e+00, -1.2898e+00,  9.2297e-01, -1.7781e+00,  3.3956e-02,\n","            2.0184e-01,  1.6609e+00,  2.8764e-01,  1.8201e+00,  5.8102e-01,\n","            6.2106e-01, -2.1510e+00,  6.6095e-02, -8.8550e-01, -7.9634e-01,\n","           -1.2259e-01,  1.4695e+00, -5.3023e-01, -2.1198e-01,  1.3243e+00,\n","           -5.9915e-01, -4.3114e-02, -5.3617e-01,  2.4418e-01, -5.8821e-02,\n","            8.6605e-01,  6.7356e-01, -6.9412e-01],\n","          [ 6.0006e-01,  2.0343e+00,  2.3828e-02, -4.4504e-01,  4.0082e-01,\n","            6.6085e-01, -9.9166e-01, -1.8502e+00,  2.8736e-02,  6.6554e-02,\n","            1.9962e-01,  1.0358e+00, -1.0310e+00,  9.1960e-01, -8.9425e-02,\n","           -5.4707e-01,  6.2425e-01, -2.0047e-01,  6.1243e-01, -7.3848e-01,\n","           -2.6722e-01, -1.4760e+00,  2.0898e+00, -6.1760e-01,  6.1494e-02,\n","           -4.6301e-01, -1.1740e+00,  5.3627e-01],\n","          [ 7.6672e-01, -2.0360e-01,  2.4945e-01,  9.1081e-02, -1.4563e-01,\n","           -8.6489e-01, -2.1311e-01,  1.0175e+00, -1.9632e-01, -8.7913e-01,\n","           -1.4052e-01,  2.7724e-01,  6.7653e-01, -1.8961e+00,  1.0825e+00,\n","            1.5695e-01,  4.3854e-01,  1.3987e+00, -8.8456e-01,  7.2095e-01,\n","            5.7422e-01, -2.1629e-01, -4.0912e-01, -9.6763e-01, -1.4170e-01,\n","            1.0833e+00, -1.1501e+00,  1.8298e+00]]]], device='cuda:0')\n","Predicted class index: 5\n","Probabilities: tensor([[0.0000e+00, 1.1194e-22, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n","         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["# 12번\n","- 예측값을 소프트맥스 함수를 넣고 가장 높은 확률의 값을 출력합니다.\n","- 3점"],"metadata":{"id":"DnWvKwFC6otw"}},{"cell_type":"code","source":["# 28x28 텐서를 GPU에 생성\n","input_tensor = torch.rand(1, 1, 28, 28).to(device)\n","\n","# 모델에 입력으로 넣고 예측 결과 출력\n","with torch.no_grad():\n","    output = model(input_tensor)\n","    probabilities = F.softmax(output, dim=1)\n","    predicted_class = torch.argmax(probabilities, dim=1)\n","    highest_prob = torch.max(probabilities, dim=1)[0]\n","    print(f'Predicted class: {predicted_class.item()} with probability: {highest_prob.item()}')"],"metadata":{"id":"4NE2DvhdDUM2","executionInfo":{"status":"ok","timestamp":1721351450811,"user_tz":-540,"elapsed":523,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ddec56ff-1524-465b-bb5d-78d75b0042b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: 6 with probability: 0.11034665256738663\n"]}]},{"cell_type":"markdown","source":["# 13번\n","- Loss 함수를 정의합니다.\n","- 학습률을 0.001로 설정합니다.\n","- 옵티마이저는 Adam을 사용합니다.\n","- 3점"],"metadata":{"id":"RwM8c2TdGseO"}},{"cell_type":"code","source":["# 손실 함수 정의 (Cross-Entropy Loss)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 학습률 설정\n","learning_rate = 0.001\n","\n","# 옵티마이저 설정 (Adam)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"o_C41-ZIEuxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 14번\n","- 학습 함수를 train_loop로 작성합니다.\n","- 매개변수(데이터로더, 모델, loss 함수, 옵티마이저)\n","- 데이터로더의 인덱스가 배치사이즈마다 loss를 출력합니다.\n","- 3점"],"metadata":{"id":"ikRtBCZAG_iP"}},{"cell_type":"code","source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    model.train()  # 모델을 학습 모드로 설정\n","    for batch_idx, (X, y) in enumerate(dataloader):\n","        # 입력 데이터와 레이블을 GPU로 이동\n","        X, y = X.to(device), y.to(device)\n","\n","        # 예측 및 손실 계산\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # 역전파(backpropagation)를 통해 그라디언트 계산 및 가중치 업데이트\n","        optimizer.zero_grad()  # 옵티마이저의 그라디언트 초기화\n","        loss.backward()  # 역전파 단계\n","        optimizer.step()  # 가중치 업데이트 단계\n","\n","        # 배치마다 손실 출력\n","        if batch_idx % 10 == 0:  # 원하는 출력 빈도에 따라 수정 가능\n","            print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n","\n","# 예시로 train_loader를 사용하여 train_loop 호출\n","# train_loader는 데이터로더 객체입니다.\n","# model, loss_fn, optimizer는 이미 정의된 객체입니다.\n","train_loop(train_loader, model, loss_fn, optimizer)"],"metadata":{"id":"akMkoDgGHAUd","executionInfo":{"status":"ok","timestamp":1721351564593,"user_tz":-540,"elapsed":11667,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36a16cd9-7b4f-46e1-a87d-1a4cd708df9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0, Loss: 2.3095293045043945\n","Batch 10, Loss: 1.216967225074768\n","Batch 20, Loss: 0.9599982500076294\n","Batch 30, Loss: 0.9419736266136169\n","Batch 40, Loss: 0.6963231563568115\n","Batch 50, Loss: 0.8074942231178284\n","Batch 60, Loss: 0.675710916519165\n","Batch 70, Loss: 0.6506773233413696\n","Batch 80, Loss: 0.6021479964256287\n","Batch 90, Loss: 0.5540080666542053\n","Batch 100, Loss: 0.793602466583252\n","Batch 110, Loss: 0.6023797392845154\n","Batch 120, Loss: 0.5796027183532715\n","Batch 130, Loss: 0.5134931802749634\n","Batch 140, Loss: 0.47515708208084106\n","Batch 150, Loss: 0.5192916989326477\n","Batch 160, Loss: 0.4660463035106659\n","Batch 170, Loss: 0.5668383836746216\n","Batch 180, Loss: 0.6493415832519531\n","Batch 190, Loss: 0.3278205692768097\n","Batch 200, Loss: 0.4474227726459503\n","Batch 210, Loss: 0.509369432926178\n","Batch 220, Loss: 0.46303248405456543\n","Batch 230, Loss: 0.47594600915908813\n","Batch 240, Loss: 0.4258238971233368\n","Batch 250, Loss: 0.6282480359077454\n","Batch 260, Loss: 0.25415468215942383\n","Batch 270, Loss: 0.4279680848121643\n","Batch 280, Loss: 0.4397498667240143\n","Batch 290, Loss: 0.44477084279060364\n","Batch 300, Loss: 0.3294505476951599\n","Batch 310, Loss: 0.4264918565750122\n","Batch 320, Loss: 0.51606285572052\n","Batch 330, Loss: 0.32304850220680237\n","Batch 340, Loss: 0.25312402844429016\n","Batch 350, Loss: 0.4230309724807739\n","Batch 360, Loss: 0.4182894825935364\n","Batch 370, Loss: 0.5372709631919861\n","Batch 380, Loss: 0.45507532358169556\n","Batch 390, Loss: 0.31384244561195374\n","Batch 400, Loss: 0.42185908555984497\n","Batch 410, Loss: 0.29823800921440125\n","Batch 420, Loss: 0.42973920702934265\n","Batch 430, Loss: 0.5237597227096558\n","Batch 440, Loss: 0.44273725152015686\n","Batch 450, Loss: 0.35355672240257263\n","Batch 460, Loss: 0.30049625039100647\n","Batch 470, Loss: 0.44552141427993774\n","Batch 480, Loss: 0.5551818013191223\n","Batch 490, Loss: 0.5830065011978149\n","Batch 500, Loss: 0.35836225748062134\n","Batch 510, Loss: 0.4456601142883301\n","Batch 520, Loss: 0.33028870820999146\n","Batch 530, Loss: 0.5809855461120605\n","Batch 540, Loss: 0.39628490805625916\n","Batch 550, Loss: 0.43646925687789917\n","Batch 560, Loss: 0.4254368841648102\n","Batch 570, Loss: 0.45033666491508484\n","Batch 580, Loss: 0.7017035484313965\n","Batch 590, Loss: 0.2405177354812622\n","Batch 600, Loss: 0.4693312346935272\n","Batch 610, Loss: 0.49819010496139526\n","Batch 620, Loss: 0.3906099200248718\n","Batch 630, Loss: 0.416639506816864\n","Batch 640, Loss: 0.5927433371543884\n","Batch 650, Loss: 0.3081488311290741\n","Batch 660, Loss: 0.4914062023162842\n","Batch 670, Loss: 0.35311922430992126\n","Batch 680, Loss: 0.38075894117355347\n","Batch 690, Loss: 0.5099640488624573\n","Batch 700, Loss: 0.4826453924179077\n","Batch 710, Loss: 0.37929555773735046\n","Batch 720, Loss: 0.4501360356807709\n","Batch 730, Loss: 0.3009534180164337\n","Batch 740, Loss: 0.36465826630592346\n","Batch 750, Loss: 0.3747054636478424\n","Batch 760, Loss: 0.27196913957595825\n","Batch 770, Loss: 0.3453472852706909\n","Batch 780, Loss: 0.4020254611968994\n","Batch 790, Loss: 0.1570555418729782\n","Batch 800, Loss: 0.45752468705177307\n","Batch 810, Loss: 0.4355448782444\n","Batch 820, Loss: 0.5228259563446045\n","Batch 830, Loss: 0.5159604549407959\n","Batch 840, Loss: 0.288556307554245\n","Batch 850, Loss: 0.35057586431503296\n","Batch 860, Loss: 0.23571638762950897\n","Batch 870, Loss: 0.23586530983448029\n","Batch 880, Loss: 0.3539915978908539\n","Batch 890, Loss: 0.5414244532585144\n","Batch 900, Loss: 0.3406270742416382\n","Batch 910, Loss: 0.24218355119228363\n","Batch 920, Loss: 0.34536364674568176\n","Batch 930, Loss: 0.27100223302841187\n"]}]},{"cell_type":"markdown","source":["# 15번\n","- 테스트 함수를 test_loop로 작성합니다.\n","- 매개변수(데이터로더, 모델, loss 함수)\n","- 데이터로더의 크기만큼 반복하며 loss를 출력하고 전체 accuracy와 평균 loss를 구합니다.\n","- 3점"],"metadata":{"id":"Sn1ny3mCH92_"}},{"cell_type":"code","source":["def test_loop(dataloader, model, loss_fn):\n","    model.eval()  # 모델을 평가 모드로 설정\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():  # 평가 단계에서는 그라디언트 계산을 비활성화\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    accuracy = correct / size\n","\n","    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","\n","# 예시로 test_loader를 사용하여 test_loop 호출\n","# test_loader는 데이터로더 객체입니다.\n","# model, loss_fn는 이미 정의된 객체입니다.\n","test_loop(test_loader, model, loss_fn)"],"metadata":{"id":"6n8JuGukIJGF","executionInfo":{"status":"ok","timestamp":1721351603250,"user_tz":-540,"elapsed":1817,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56ff2ba1-276e-4b9c-a807-c2e5d79c3ffd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 85.2%, Avg loss: 0.417860 \n","\n"]}]},{"cell_type":"markdown","source":["# 16번\n","- 100번의 epochs를 돌며 학습을 반복합니다.\n","- 3점"],"metadata":{"id":"2OtZ9fhmJBeP"}},{"cell_type":"code","source":["num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    train_loop(train_loader, model, loss_fn, optimizer)\n","    test_loop(test_loader, model, loss_fn)\n","    print(\"-\" * 50)"],"metadata":{"id":"mObQZhKQ2Z9E","executionInfo":{"status":"ok","timestamp":1721353013111,"user_tz":-540,"elapsed":1313261,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d255402d-8c5e-440e-c1c6-5fe9c843b141"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Batch 480, Loss: 0.038748010993003845\n","Batch 490, Loss: 0.08331236243247986\n","Batch 500, Loss: 0.07925177365541458\n","Batch 510, Loss: 0.07492920011281967\n","Batch 520, Loss: 0.04315323755145073\n","Batch 530, Loss: 0.02286987006664276\n","Batch 540, Loss: 0.005701302085071802\n","Batch 550, Loss: 0.03704298660159111\n","Batch 560, Loss: 0.04147292301058769\n","Batch 570, Loss: 0.07013300806283951\n","Batch 580, Loss: 0.01809374988079071\n","Batch 590, Loss: 0.010535003617405891\n","Batch 600, Loss: 0.030450014397501945\n","Batch 610, Loss: 0.023569952696561813\n","Batch 620, Loss: 0.056116629391908646\n","Batch 630, Loss: 0.12560543417930603\n","Batch 640, Loss: 0.01004802156239748\n","Batch 650, Loss: 0.03867409750819206\n","Batch 660, Loss: 0.12083090841770172\n","Batch 670, Loss: 0.03396096080541611\n","Batch 680, Loss: 0.057837311178445816\n","Batch 690, Loss: 0.08283057808876038\n","Batch 700, Loss: 0.06098967045545578\n","Batch 710, Loss: 0.07499224692583084\n","Batch 720, Loss: 0.04683848097920418\n","Batch 730, Loss: 0.052111513912677765\n","Batch 740, Loss: 0.08337481319904327\n","Batch 750, Loss: 0.021167324855923653\n","Batch 760, Loss: 0.07500503957271576\n","Batch 770, Loss: 0.1030953899025917\n","Batch 780, Loss: 0.02536146529018879\n","Batch 790, Loss: 0.10120464116334915\n","Batch 800, Loss: 0.13642030954360962\n","Batch 810, Loss: 0.06376297771930695\n","Batch 820, Loss: 0.04689778387546539\n","Batch 830, Loss: 0.01409692782908678\n","Batch 840, Loss: 0.031569141894578934\n","Batch 850, Loss: 0.059354234486818314\n","Batch 860, Loss: 0.02547285705804825\n","Batch 870, Loss: 0.2275577187538147\n","Batch 880, Loss: 0.01522765401750803\n","Batch 890, Loss: 0.014737381599843502\n","Batch 900, Loss: 0.09134756773710251\n","Batch 910, Loss: 0.10757212340831757\n","Batch 920, Loss: 0.06555583328008652\n","Batch 930, Loss: 0.04956066608428955\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.698808 \n","\n","--------------------------------------------------\n","Epoch 51/100\n","Batch 0, Loss: 0.03602674603462219\n","Batch 10, Loss: 0.023152310401201248\n","Batch 20, Loss: 0.04357697814702988\n","Batch 30, Loss: 0.09248580783605576\n","Batch 40, Loss: 0.02035636641085148\n","Batch 50, Loss: 0.05728483945131302\n","Batch 60, Loss: 0.04703819751739502\n","Batch 70, Loss: 0.006442847196012735\n","Batch 80, Loss: 0.0638667643070221\n","Batch 90, Loss: 0.041203007102012634\n","Batch 100, Loss: 0.044049788266420364\n","Batch 110, Loss: 0.007397453300654888\n","Batch 120, Loss: 0.011971867643296719\n","Batch 130, Loss: 0.01051842700690031\n","Batch 140, Loss: 0.029276469722390175\n","Batch 150, Loss: 0.02768522873520851\n","Batch 160, Loss: 0.03344700112938881\n","Batch 170, Loss: 0.1454395353794098\n","Batch 180, Loss: 0.009473859332501888\n","Batch 190, Loss: 0.07243111729621887\n","Batch 200, Loss: 0.010064360685646534\n","Batch 210, Loss: 0.13033658266067505\n","Batch 220, Loss: 0.03916788101196289\n","Batch 230, Loss: 0.08568789809942245\n","Batch 240, Loss: 0.013131950981914997\n","Batch 250, Loss: 0.05622079595923424\n","Batch 260, Loss: 0.07956171035766602\n","Batch 270, Loss: 0.03624562546610832\n","Batch 280, Loss: 0.07221558690071106\n","Batch 290, Loss: 0.026263821870088577\n","Batch 300, Loss: 0.026568014174699783\n","Batch 310, Loss: 0.007947366684675217\n","Batch 320, Loss: 0.07540658116340637\n","Batch 330, Loss: 0.041084446012973785\n","Batch 340, Loss: 0.07532954961061478\n","Batch 350, Loss: 0.010615186765789986\n","Batch 360, Loss: 0.06830422580242157\n","Batch 370, Loss: 0.006777165457606316\n","Batch 380, Loss: 0.06530537456274033\n","Batch 390, Loss: 0.0363948680460453\n","Batch 400, Loss: 0.0634206011891365\n","Batch 410, Loss: 0.11749760806560516\n","Batch 420, Loss: 0.008312812075018883\n","Batch 430, Loss: 0.02377624250948429\n","Batch 440, Loss: 0.021760599687695503\n","Batch 450, Loss: 0.04318086430430412\n","Batch 460, Loss: 0.04552672058343887\n","Batch 470, Loss: 0.0311714056879282\n","Batch 480, Loss: 0.022473366931080818\n","Batch 490, Loss: 0.02303471602499485\n","Batch 500, Loss: 0.01584435999393463\n","Batch 510, Loss: 0.027145087718963623\n","Batch 520, Loss: 0.060398634523153305\n","Batch 530, Loss: 0.07026135921478271\n","Batch 540, Loss: 0.022642729803919792\n","Batch 550, Loss: 0.020386267453432083\n","Batch 560, Loss: 0.08241572976112366\n","Batch 570, Loss: 0.13732023537158966\n","Batch 580, Loss: 0.042055580765008926\n","Batch 590, Loss: 0.04122474789619446\n","Batch 600, Loss: 0.03417234495282173\n","Batch 610, Loss: 0.12299489974975586\n","Batch 620, Loss: 0.12710946798324585\n","Batch 630, Loss: 0.08324985206127167\n","Batch 640, Loss: 0.023393163457512856\n","Batch 650, Loss: 0.06981761753559113\n","Batch 660, Loss: 0.020592795684933662\n","Batch 670, Loss: 0.02754298225045204\n","Batch 680, Loss: 0.055961452424526215\n","Batch 690, Loss: 0.026896856725215912\n","Batch 700, Loss: 0.03312026709318161\n","Batch 710, Loss: 0.015865150839090347\n","Batch 720, Loss: 0.09969008713960648\n","Batch 730, Loss: 0.02970116212964058\n","Batch 740, Loss: 0.09888210147619247\n","Batch 750, Loss: 0.09620516747236252\n","Batch 760, Loss: 0.0365631990134716\n","Batch 770, Loss: 0.0951157659292221\n","Batch 780, Loss: 0.0345195010304451\n","Batch 790, Loss: 0.10081321001052856\n","Batch 800, Loss: 0.11225337535142899\n","Batch 810, Loss: 0.15510869026184082\n","Batch 820, Loss: 0.02953958325088024\n","Batch 830, Loss: 0.07609758526086807\n","Batch 840, Loss: 0.030721306800842285\n","Batch 850, Loss: 0.1069297343492508\n","Batch 860, Loss: 0.033769816160202026\n","Batch 870, Loss: 0.08694060146808624\n","Batch 880, Loss: 0.0912344753742218\n","Batch 890, Loss: 0.014740345068275928\n","Batch 900, Loss: 0.032356150448322296\n","Batch 910, Loss: 0.03442854434251785\n","Batch 920, Loss: 0.09076005220413208\n","Batch 930, Loss: 0.11975903809070587\n","Test Error: \n"," Accuracy: 88.8%, Avg loss: 0.676509 \n","\n","--------------------------------------------------\n","Epoch 52/100\n","Batch 0, Loss: 0.06807111948728561\n","Batch 10, Loss: 0.0425293855369091\n","Batch 20, Loss: 0.024017566815018654\n","Batch 30, Loss: 0.05395016446709633\n","Batch 40, Loss: 0.16512425243854523\n","Batch 50, Loss: 0.04014851525425911\n","Batch 60, Loss: 0.015262382104992867\n","Batch 70, Loss: 0.012245537713170052\n","Batch 80, Loss: 0.05448990315198898\n","Batch 90, Loss: 0.06259456276893616\n","Batch 100, Loss: 0.06359247118234634\n","Batch 110, Loss: 0.018568698316812515\n","Batch 120, Loss: 0.026428593322634697\n","Batch 130, Loss: 0.02843640372157097\n","Batch 140, Loss: 0.0516684390604496\n","Batch 150, Loss: 0.010840470902621746\n","Batch 160, Loss: 0.008396574296057224\n","Batch 170, Loss: 0.0282279085367918\n","Batch 180, Loss: 0.08190519362688065\n","Batch 190, Loss: 0.016256151720881462\n","Batch 200, Loss: 0.04684443026781082\n","Batch 210, Loss: 0.01131804846227169\n","Batch 220, Loss: 0.0028132786974310875\n","Batch 230, Loss: 0.019703542813658714\n","Batch 240, Loss: 0.023114468902349472\n","Batch 250, Loss: 0.016039349138736725\n","Batch 260, Loss: 0.053156979382038116\n","Batch 270, Loss: 0.005870025139302015\n","Batch 280, Loss: 0.04136103391647339\n","Batch 290, Loss: 0.11117386072874069\n","Batch 300, Loss: 0.11667794734239578\n","Batch 310, Loss: 0.023626530542969704\n","Batch 320, Loss: 0.03305300697684288\n","Batch 330, Loss: 0.03282869607210159\n","Batch 340, Loss: 0.1441611498594284\n","Batch 350, Loss: 0.03139318898320198\n","Batch 360, Loss: 0.023276301100850105\n","Batch 370, Loss: 0.02812875621020794\n","Batch 380, Loss: 0.014455527998507023\n","Batch 390, Loss: 0.040324680507183075\n","Batch 400, Loss: 0.05238889530301094\n","Batch 410, Loss: 0.037459325045347214\n","Batch 420, Loss: 0.06604939699172974\n","Batch 430, Loss: 0.05643370747566223\n","Batch 440, Loss: 0.032791800796985626\n","Batch 450, Loss: 0.07436753064393997\n","Batch 460, Loss: 0.01590218022465706\n","Batch 470, Loss: 0.0170796699821949\n","Batch 480, Loss: 0.007423684932291508\n","Batch 490, Loss: 0.048726826906204224\n","Batch 500, Loss: 0.08752107620239258\n","Batch 510, Loss: 0.09817786514759064\n","Batch 520, Loss: 0.04264749214053154\n","Batch 530, Loss: 0.08238295465707779\n","Batch 540, Loss: 0.0374467559158802\n","Batch 550, Loss: 0.042640622705221176\n","Batch 560, Loss: 0.05944332852959633\n","Batch 570, Loss: 0.047313425689935684\n","Batch 580, Loss: 0.03838755935430527\n","Batch 590, Loss: 0.058843109756708145\n","Batch 600, Loss: 0.09713485836982727\n","Batch 610, Loss: 0.006796116475015879\n","Batch 620, Loss: 0.01702658273279667\n","Batch 630, Loss: 0.07235731184482574\n","Batch 640, Loss: 0.11223840713500977\n","Batch 650, Loss: 0.02819099649786949\n","Batch 660, Loss: 0.0135873444378376\n","Batch 670, Loss: 0.07347610592842102\n","Batch 680, Loss: 0.056610435247421265\n","Batch 690, Loss: 0.051842037588357925\n","Batch 700, Loss: 0.07971405982971191\n","Batch 710, Loss: 0.035856861621141434\n","Batch 720, Loss: 0.020872274413704872\n","Batch 730, Loss: 0.0035879381466656923\n","Batch 740, Loss: 0.027699636295437813\n","Batch 750, Loss: 0.0858025923371315\n","Batch 760, Loss: 0.05317024141550064\n","Batch 770, Loss: 0.03539368137717247\n","Batch 780, Loss: 0.24868449568748474\n","Batch 790, Loss: 0.043295156210660934\n","Batch 800, Loss: 0.05284855142235756\n","Batch 810, Loss: 0.17980767786502838\n","Batch 820, Loss: 0.03861265629529953\n","Batch 830, Loss: 0.06754487752914429\n","Batch 840, Loss: 0.00479718204587698\n","Batch 850, Loss: 0.04126594215631485\n","Batch 860, Loss: 0.09545300900936127\n","Batch 870, Loss: 0.02541780099272728\n","Batch 880, Loss: 0.038948725908994675\n","Batch 890, Loss: 0.025881148874759674\n","Batch 900, Loss: 0.05798705667257309\n","Batch 910, Loss: 0.1267600655555725\n","Batch 920, Loss: 0.05428950861096382\n","Batch 930, Loss: 0.07491447031497955\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.772250 \n","\n","--------------------------------------------------\n","Epoch 53/100\n","Batch 0, Loss: 0.0949157103896141\n","Batch 10, Loss: 0.06455694884061813\n","Batch 20, Loss: 0.007076303008943796\n","Batch 30, Loss: 0.07034651935100555\n","Batch 40, Loss: 0.03603542968630791\n","Batch 50, Loss: 0.15151415765285492\n","Batch 60, Loss: 0.0820097103714943\n","Batch 70, Loss: 0.13577266037464142\n","Batch 80, Loss: 0.0329979732632637\n","Batch 90, Loss: 0.1966797113418579\n","Batch 100, Loss: 0.07736833393573761\n","Batch 110, Loss: 0.043206628412008286\n","Batch 120, Loss: 0.12075088918209076\n","Batch 130, Loss: 0.030247149989008904\n","Batch 140, Loss: 0.015466534532606602\n","Batch 150, Loss: 0.04274908825755119\n","Batch 160, Loss: 0.011068482883274555\n","Batch 170, Loss: 0.026362551376223564\n","Batch 180, Loss: 0.01877640001475811\n","Batch 190, Loss: 0.04963524639606476\n","Batch 200, Loss: 0.04804196581244469\n","Batch 210, Loss: 0.03656834363937378\n","Batch 220, Loss: 0.027898799628019333\n","Batch 230, Loss: 0.04181138426065445\n","Batch 240, Loss: 0.11140250414609909\n","Batch 250, Loss: 0.016602836549282074\n","Batch 260, Loss: 0.048563502728939056\n","Batch 270, Loss: 0.011851374059915543\n","Batch 280, Loss: 0.01798727922141552\n","Batch 290, Loss: 0.09617731720209122\n","Batch 300, Loss: 0.0360809862613678\n","Batch 310, Loss: 0.14248524606227875\n","Batch 320, Loss: 0.05532936379313469\n","Batch 330, Loss: 0.16154421865940094\n","Batch 340, Loss: 0.02587982639670372\n","Batch 350, Loss: 0.024932673200964928\n","Batch 360, Loss: 0.0799964889883995\n","Batch 370, Loss: 0.02097308821976185\n","Batch 380, Loss: 0.023492339998483658\n","Batch 390, Loss: 0.03929867595434189\n","Batch 400, Loss: 0.11164427548646927\n","Batch 410, Loss: 0.04579548165202141\n","Batch 420, Loss: 0.03541545569896698\n","Batch 430, Loss: 0.00768336933106184\n","Batch 440, Loss: 0.028073852881789207\n","Batch 450, Loss: 0.022466078400611877\n","Batch 460, Loss: 0.011982372030615807\n","Batch 470, Loss: 0.0981966108083725\n","Batch 480, Loss: 0.04445211589336395\n","Batch 490, Loss: 0.0766916498541832\n","Batch 500, Loss: 0.031101739034056664\n","Batch 510, Loss: 0.03553811088204384\n","Batch 520, Loss: 0.028732869774103165\n","Batch 530, Loss: 0.08174443989992142\n","Batch 540, Loss: 0.022945990785956383\n","Batch 550, Loss: 0.11697915941476822\n","Batch 560, Loss: 0.11652106046676636\n","Batch 570, Loss: 0.04127756878733635\n","Batch 580, Loss: 0.062453676015138626\n","Batch 590, Loss: 0.07050502300262451\n","Batch 600, Loss: 0.03971110284328461\n","Batch 610, Loss: 0.05469274893403053\n","Batch 620, Loss: 0.018547609448432922\n","Batch 630, Loss: 0.01665707305073738\n","Batch 640, Loss: 0.029008572921156883\n","Batch 650, Loss: 0.06904640048742294\n","Batch 660, Loss: 0.0865827351808548\n","Batch 670, Loss: 0.04522678256034851\n","Batch 680, Loss: 0.01370017509907484\n","Batch 690, Loss: 0.036683861166238785\n","Batch 700, Loss: 0.043268777430057526\n","Batch 710, Loss: 0.041835494339466095\n","Batch 720, Loss: 0.03107282519340515\n","Batch 730, Loss: 0.024544840678572655\n","Batch 740, Loss: 0.059705961495637894\n","Batch 750, Loss: 0.043003033846616745\n","Batch 760, Loss: 0.020682021975517273\n","Batch 770, Loss: 0.050384748727083206\n","Batch 780, Loss: 0.07667753100395203\n","Batch 790, Loss: 0.023856814950704575\n","Batch 800, Loss: 0.17052417993545532\n","Batch 810, Loss: 0.004674452356994152\n","Batch 820, Loss: 0.06657671928405762\n","Batch 830, Loss: 0.04070762172341347\n","Batch 840, Loss: 0.020186852663755417\n","Batch 850, Loss: 0.10296108573675156\n","Batch 860, Loss: 0.050404664129018784\n","Batch 870, Loss: 0.012361811473965645\n","Batch 880, Loss: 0.09280088543891907\n","Batch 890, Loss: 0.06432519108057022\n","Batch 900, Loss: 0.02458920143544674\n","Batch 910, Loss: 0.0658029317855835\n","Batch 920, Loss: 0.01795862801373005\n","Batch 930, Loss: 0.010326598770916462\n","Test Error: \n"," Accuracy: 89.2%, Avg loss: 0.737575 \n","\n","--------------------------------------------------\n","Epoch 54/100\n","Batch 0, Loss: 0.22190625965595245\n","Batch 10, Loss: 0.0636732429265976\n","Batch 20, Loss: 0.07913659512996674\n","Batch 30, Loss: 0.016761261969804764\n","Batch 40, Loss: 0.19884510338306427\n","Batch 50, Loss: 0.01353449933230877\n","Batch 60, Loss: 0.07801979780197144\n","Batch 70, Loss: 0.04153475537896156\n","Batch 80, Loss: 0.25710535049438477\n","Batch 90, Loss: 0.1272561401128769\n","Batch 100, Loss: 0.08437826484441757\n","Batch 110, Loss: 0.21633966267108917\n","Batch 120, Loss: 0.054363466799259186\n","Batch 130, Loss: 0.11369330435991287\n","Batch 140, Loss: 0.07543129473924637\n","Batch 150, Loss: 0.05147215723991394\n","Batch 160, Loss: 0.07402914017438889\n","Batch 170, Loss: 0.007705965079367161\n","Batch 180, Loss: 0.02394724451005459\n","Batch 190, Loss: 0.018514666706323624\n","Batch 200, Loss: 0.029324719682335854\n","Batch 210, Loss: 0.028108488768339157\n","Batch 220, Loss: 0.08469637483358383\n","Batch 230, Loss: 0.04637371748685837\n","Batch 240, Loss: 0.04384621977806091\n","Batch 250, Loss: 0.023945428431034088\n","Batch 260, Loss: 0.026167096570134163\n","Batch 270, Loss: 0.13326168060302734\n","Batch 280, Loss: 0.023635391145944595\n","Batch 290, Loss: 0.02830437384545803\n","Batch 300, Loss: 0.017709603533148766\n","Batch 310, Loss: 0.06203511729836464\n","Batch 320, Loss: 0.0020569849293679\n","Batch 330, Loss: 0.020511789247393608\n","Batch 340, Loss: 0.11749205738306046\n","Batch 350, Loss: 0.00783104170113802\n","Batch 360, Loss: 0.08114932477474213\n","Batch 370, Loss: 0.019720017910003662\n","Batch 380, Loss: 0.03441251069307327\n","Batch 390, Loss: 0.08449845761060715\n","Batch 400, Loss: 0.224847212433815\n","Batch 410, Loss: 0.08938655257225037\n","Batch 420, Loss: 0.020137259736657143\n","Batch 430, Loss: 0.06712627410888672\n","Batch 440, Loss: 0.05054682865738869\n","Batch 450, Loss: 0.011010140180587769\n","Batch 460, Loss: 0.10261557996273041\n","Batch 470, Loss: 0.1117158830165863\n","Batch 480, Loss: 0.05676654353737831\n","Batch 490, Loss: 0.07128942012786865\n","Batch 500, Loss: 0.03260340541601181\n","Batch 510, Loss: 0.12882931530475616\n","Batch 520, Loss: 0.07317544519901276\n","Batch 530, Loss: 0.09551697224378586\n","Batch 540, Loss: 0.13810427486896515\n","Batch 550, Loss: 0.1254468709230423\n","Batch 560, Loss: 0.06944365799427032\n","Batch 570, Loss: 0.05594853311777115\n","Batch 580, Loss: 0.06351320445537567\n","Batch 590, Loss: 0.05218534916639328\n","Batch 600, Loss: 0.07245174795389175\n","Batch 610, Loss: 0.04899279400706291\n","Batch 620, Loss: 0.029770787805318832\n","Batch 630, Loss: 0.013702058233320713\n","Batch 640, Loss: 0.03921300917863846\n","Batch 650, Loss: 0.03952797129750252\n","Batch 660, Loss: 0.033095553517341614\n","Batch 670, Loss: 0.03967542201280594\n","Batch 680, Loss: 0.025442838668823242\n","Batch 690, Loss: 0.01718463934957981\n","Batch 700, Loss: 0.00895152147859335\n","Batch 710, Loss: 0.015621073544025421\n","Batch 720, Loss: 0.018764417618513107\n","Batch 730, Loss: 0.058857664465904236\n","Batch 740, Loss: 0.04004359617829323\n","Batch 750, Loss: 0.019122321158647537\n","Batch 760, Loss: 0.031143665313720703\n","Batch 770, Loss: 0.009875920601189137\n","Batch 780, Loss: 0.05248567834496498\n","Batch 790, Loss: 0.04652226343750954\n","Batch 800, Loss: 0.010510613210499287\n","Batch 810, Loss: 0.05062364786863327\n","Batch 820, Loss: 0.031130585819482803\n","Batch 830, Loss: 0.04748116806149483\n","Batch 840, Loss: 0.028043562546372414\n","Batch 850, Loss: 0.02692529745399952\n","Batch 860, Loss: 0.033622417598962784\n","Batch 870, Loss: 0.017232229933142662\n","Batch 880, Loss: 0.01010827999562025\n","Batch 890, Loss: 0.03315844386816025\n","Batch 900, Loss: 0.057856958359479904\n","Batch 910, Loss: 0.11789245158433914\n","Batch 920, Loss: 0.03770208731293678\n","Batch 930, Loss: 0.015737896785140038\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.753787 \n","\n","--------------------------------------------------\n","Epoch 55/100\n","Batch 0, Loss: 0.04428380727767944\n","Batch 10, Loss: 0.029087785631418228\n","Batch 20, Loss: 0.01850641332566738\n","Batch 30, Loss: 0.056562379002571106\n","Batch 40, Loss: 0.04035588726401329\n","Batch 50, Loss: 0.02662302553653717\n","Batch 60, Loss: 0.01596168428659439\n","Batch 70, Loss: 0.038534898310899734\n","Batch 80, Loss: 0.07428888976573944\n","Batch 90, Loss: 0.015910562127828598\n","Batch 100, Loss: 0.03417418152093887\n","Batch 110, Loss: 0.11646566540002823\n","Batch 120, Loss: 0.01336043979972601\n","Batch 130, Loss: 0.018975725397467613\n","Batch 140, Loss: 0.004195153247565031\n","Batch 150, Loss: 0.028609968721866608\n","Batch 160, Loss: 0.0547407828271389\n","Batch 170, Loss: 0.0748341754078865\n","Batch 180, Loss: 0.09545508027076721\n","Batch 190, Loss: 0.06915004551410675\n","Batch 200, Loss: 0.013735276646912098\n","Batch 210, Loss: 0.02579694613814354\n","Batch 220, Loss: 0.038581158965826035\n","Batch 230, Loss: 0.009936613030731678\n","Batch 240, Loss: 0.03184140846133232\n","Batch 250, Loss: 0.062220498919487\n","Batch 260, Loss: 0.060961127281188965\n","Batch 270, Loss: 0.07943401485681534\n","Batch 280, Loss: 0.06039423495531082\n","Batch 290, Loss: 0.0147864930331707\n","Batch 300, Loss: 0.032893795520067215\n","Batch 310, Loss: 0.2741946876049042\n","Batch 320, Loss: 0.07806214690208435\n","Batch 330, Loss: 0.12281754612922668\n","Batch 340, Loss: 0.0442824587225914\n","Batch 350, Loss: 0.10642139613628387\n","Batch 360, Loss: 0.07020171731710434\n","Batch 370, Loss: 0.012894376181066036\n","Batch 380, Loss: 0.11360736936330795\n","Batch 390, Loss: 0.033997148275375366\n","Batch 400, Loss: 0.0718928873538971\n","Batch 410, Loss: 0.03203801065683365\n","Batch 420, Loss: 0.024156836792826653\n","Batch 430, Loss: 0.012184666469693184\n","Batch 440, Loss: 0.06989704817533493\n","Batch 450, Loss: 0.020793311297893524\n","Batch 460, Loss: 0.0685800313949585\n","Batch 470, Loss: 0.16051770746707916\n","Batch 480, Loss: 0.0578569658100605\n","Batch 490, Loss: 0.0056450143456459045\n","Batch 500, Loss: 0.03308439254760742\n","Batch 510, Loss: 0.058049075305461884\n","Batch 520, Loss: 0.01968921720981598\n","Batch 530, Loss: 0.07593464106321335\n","Batch 540, Loss: 0.03744740039110184\n","Batch 550, Loss: 0.04997429996728897\n","Batch 560, Loss: 0.12589934468269348\n","Batch 570, Loss: 0.02985752373933792\n","Batch 580, Loss: 0.011745503172278404\n","Batch 590, Loss: 0.02899155579507351\n","Batch 600, Loss: 0.024207981303334236\n","Batch 610, Loss: 0.015733571723103523\n","Batch 620, Loss: 0.024720950052142143\n","Batch 630, Loss: 0.013786627911031246\n","Batch 640, Loss: 0.0908563956618309\n","Batch 650, Loss: 0.007853275164961815\n","Batch 660, Loss: 0.06258116662502289\n","Batch 670, Loss: 0.04333681985735893\n","Batch 680, Loss: 0.023704856634140015\n","Batch 690, Loss: 0.12805260717868805\n","Batch 700, Loss: 0.046186789870262146\n","Batch 710, Loss: 0.00840170681476593\n","Batch 720, Loss: 0.04683121666312218\n","Batch 730, Loss: 0.012118988670408726\n","Batch 740, Loss: 0.09036581218242645\n","Batch 750, Loss: 0.04262134060263634\n","Batch 760, Loss: 0.20403115451335907\n","Batch 770, Loss: 0.026466703042387962\n","Batch 780, Loss: 0.11629117280244827\n","Batch 790, Loss: 0.03101077489554882\n","Batch 800, Loss: 0.00536702387034893\n","Batch 810, Loss: 0.08261611312627792\n","Batch 820, Loss: 0.0770462155342102\n","Batch 830, Loss: 0.02818303555250168\n","Batch 840, Loss: 0.06264036893844604\n","Batch 850, Loss: 0.10859642922878265\n","Batch 860, Loss: 0.1851637214422226\n","Batch 870, Loss: 0.07431032508611679\n","Batch 880, Loss: 0.08215118944644928\n","Batch 890, Loss: 0.01717471517622471\n","Batch 900, Loss: 0.08722366392612457\n","Batch 910, Loss: 0.06752372533082962\n","Batch 920, Loss: 0.11169419437646866\n","Batch 930, Loss: 0.012214265763759613\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.751700 \n","\n","--------------------------------------------------\n","Epoch 56/100\n","Batch 0, Loss: 0.02208220213651657\n","Batch 10, Loss: 0.02488081157207489\n","Batch 20, Loss: 0.0820096954703331\n","Batch 30, Loss: 0.013783924281597137\n","Batch 40, Loss: 0.04856414347887039\n","Batch 50, Loss: 0.07688353955745697\n","Batch 60, Loss: 0.05403915420174599\n","Batch 70, Loss: 0.011549427174031734\n","Batch 80, Loss: 0.05600875988602638\n","Batch 90, Loss: 0.015635458752512932\n","Batch 100, Loss: 0.04670774191617966\n","Batch 110, Loss: 0.04756151884794235\n","Batch 120, Loss: 0.09532514214515686\n","Batch 130, Loss: 0.020788680762052536\n","Batch 140, Loss: 0.010580325499176979\n","Batch 150, Loss: 0.08718626946210861\n","Batch 160, Loss: 0.09575384110212326\n","Batch 170, Loss: 0.11477040499448776\n","Batch 180, Loss: 0.05783522129058838\n","Batch 190, Loss: 0.021535765379667282\n","Batch 200, Loss: 0.06598994880914688\n","Batch 210, Loss: 0.122778981924057\n","Batch 220, Loss: 0.00611987104639411\n","Batch 230, Loss: 0.005323903635144234\n","Batch 240, Loss: 0.01905599981546402\n","Batch 250, Loss: 0.04143119603395462\n","Batch 260, Loss: 0.02856932021677494\n","Batch 270, Loss: 0.018322138115763664\n","Batch 280, Loss: 0.14538714289665222\n","Batch 290, Loss: 0.016058392822742462\n","Batch 300, Loss: 0.016713541001081467\n","Batch 310, Loss: 0.003183615393936634\n","Batch 320, Loss: 0.03904649615287781\n","Batch 330, Loss: 0.04257717356085777\n","Batch 340, Loss: 0.04458790272474289\n","Batch 350, Loss: 0.06343959271907806\n","Batch 360, Loss: 0.06968361884355545\n","Batch 370, Loss: 0.0510939285159111\n","Batch 380, Loss: 0.01808173768222332\n","Batch 390, Loss: 0.13473238050937653\n","Batch 400, Loss: 0.13787193596363068\n","Batch 410, Loss: 0.16969360411167145\n","Batch 420, Loss: 0.05549415200948715\n","Batch 430, Loss: 0.029441529884934425\n","Batch 440, Loss: 0.03650746867060661\n","Batch 450, Loss: 0.03775906562805176\n","Batch 460, Loss: 0.016245711594820023\n","Batch 470, Loss: 0.04690590873360634\n","Batch 480, Loss: 0.021592045202851295\n","Batch 490, Loss: 0.0035608545877039433\n","Batch 500, Loss: 0.09441536664962769\n","Batch 510, Loss: 0.02495826780796051\n","Batch 520, Loss: 0.017989005893468857\n","Batch 530, Loss: 0.10955251753330231\n","Batch 540, Loss: 0.1404837816953659\n","Batch 550, Loss: 0.0547446571290493\n","Batch 560, Loss: 0.041321948170661926\n","Batch 570, Loss: 0.13513439893722534\n","Batch 580, Loss: 0.14591459929943085\n","Batch 590, Loss: 0.053735941648483276\n","Batch 600, Loss: 0.007629614323377609\n","Batch 610, Loss: 0.12519633769989014\n","Batch 620, Loss: 0.16504767537117004\n","Batch 630, Loss: 0.02804035134613514\n","Batch 640, Loss: 0.06562585383653641\n","Batch 650, Loss: 0.21104225516319275\n","Batch 660, Loss: 0.05510985106229782\n","Batch 670, Loss: 0.05808171629905701\n","Batch 680, Loss: 0.16592542827129364\n","Batch 690, Loss: 0.030904727056622505\n","Batch 700, Loss: 0.023376723751425743\n","Batch 710, Loss: 0.04349307715892792\n","Batch 720, Loss: 0.10275082290172577\n","Batch 730, Loss: 0.06486857682466507\n","Batch 740, Loss: 0.01672736369073391\n","Batch 750, Loss: 0.009648793376982212\n","Batch 760, Loss: 0.059305790811777115\n","Batch 770, Loss: 0.04914187267422676\n","Batch 780, Loss: 0.040846582502126694\n","Batch 790, Loss: 0.02505910024046898\n","Batch 800, Loss: 0.15593546628952026\n","Batch 810, Loss: 0.14938771724700928\n","Batch 820, Loss: 0.007939444854855537\n","Batch 830, Loss: 0.023709654808044434\n","Batch 840, Loss: 0.05904263257980347\n","Batch 850, Loss: 0.07557011395692825\n","Batch 860, Loss: 0.027563396841287613\n","Batch 870, Loss: 0.025235265493392944\n","Batch 880, Loss: 0.01687917485833168\n","Batch 890, Loss: 0.05452737957239151\n","Batch 900, Loss: 0.07696837186813354\n","Batch 910, Loss: 0.09010667353868484\n","Batch 920, Loss: 0.04149037227034569\n","Batch 930, Loss: 0.038223374634981155\n","Test Error: \n"," Accuracy: 89.7%, Avg loss: 0.729917 \n","\n","--------------------------------------------------\n","Epoch 57/100\n","Batch 0, Loss: 0.0459713414311409\n","Batch 10, Loss: 0.023238439112901688\n","Batch 20, Loss: 0.058677952736616135\n","Batch 30, Loss: 0.03240120783448219\n","Batch 40, Loss: 0.030007872730493546\n","Batch 50, Loss: 0.07509347051382065\n","Batch 60, Loss: 0.0742817297577858\n","Batch 70, Loss: 0.07107605040073395\n","Batch 80, Loss: 0.029725419357419014\n","Batch 90, Loss: 0.002225445816293359\n","Batch 100, Loss: 0.028887590393424034\n","Batch 110, Loss: 0.04279986396431923\n","Batch 120, Loss: 0.018361203372478485\n","Batch 130, Loss: 0.009045866318047047\n","Batch 140, Loss: 0.03580648824572563\n","Batch 150, Loss: 0.016596313565969467\n","Batch 160, Loss: 0.03972100093960762\n","Batch 170, Loss: 0.02358803153038025\n","Batch 180, Loss: 0.008780374191701412\n","Batch 190, Loss: 0.07048854231834412\n","Batch 200, Loss: 0.128845676779747\n","Batch 210, Loss: 0.013792651705443859\n","Batch 220, Loss: 0.03942042216658592\n","Batch 230, Loss: 0.028170136734843254\n","Batch 240, Loss: 0.04453620687127113\n","Batch 250, Loss: 0.05454134941101074\n","Batch 260, Loss: 0.014183113351464272\n","Batch 270, Loss: 0.038365986198186874\n","Batch 280, Loss: 0.00662958063185215\n","Batch 290, Loss: 0.03867750242352486\n","Batch 300, Loss: 0.014039945788681507\n","Batch 310, Loss: 0.031337808817625046\n","Batch 320, Loss: 0.05078716576099396\n","Batch 330, Loss: 0.0029047727584838867\n","Batch 340, Loss: 0.019718661904335022\n","Batch 350, Loss: 0.04156987741589546\n","Batch 360, Loss: 0.03690710291266441\n","Batch 370, Loss: 0.08117538690567017\n","Batch 380, Loss: 0.010324505157768726\n","Batch 390, Loss: 0.05700119957327843\n","Batch 400, Loss: 0.011261305771768093\n","Batch 410, Loss: 0.018355969339609146\n","Batch 420, Loss: 0.053254008293151855\n","Batch 430, Loss: 0.03730526193976402\n","Batch 440, Loss: 0.14189031720161438\n","Batch 450, Loss: 0.11156866699457169\n","Batch 460, Loss: 0.05289464816451073\n","Batch 470, Loss: 0.04505890607833862\n","Batch 480, Loss: 0.045060932636260986\n","Batch 490, Loss: 0.030465930700302124\n","Batch 500, Loss: 0.0746447890996933\n","Batch 510, Loss: 0.003510343376547098\n","Batch 520, Loss: 0.02438020147383213\n","Batch 530, Loss: 0.12326232343912125\n","Batch 540, Loss: 0.04352479800581932\n","Batch 550, Loss: 0.01048348844051361\n","Batch 560, Loss: 0.026324870064854622\n","Batch 570, Loss: 0.032661814242601395\n","Batch 580, Loss: 0.090519480407238\n","Batch 590, Loss: 0.08387042582035065\n","Batch 600, Loss: 0.015732014551758766\n","Batch 610, Loss: 0.0022019112948328257\n","Batch 620, Loss: 0.012238269671797752\n","Batch 630, Loss: 0.07296045869588852\n","Batch 640, Loss: 0.028031401336193085\n","Batch 650, Loss: 0.17472399771213531\n","Batch 660, Loss: 0.02128235436975956\n","Batch 670, Loss: 0.051076389849185944\n","Batch 680, Loss: 0.04422733187675476\n","Batch 690, Loss: 0.014022362418472767\n","Batch 700, Loss: 0.0022606798447668552\n","Batch 710, Loss: 0.09976717829704285\n","Batch 720, Loss: 0.058555249124765396\n","Batch 730, Loss: 0.05989225208759308\n","Batch 740, Loss: 0.01897815242409706\n","Batch 750, Loss: 0.03734184429049492\n","Batch 760, Loss: 0.04761107265949249\n","Batch 770, Loss: 0.05498885735869408\n","Batch 780, Loss: 0.006351670250296593\n","Batch 790, Loss: 0.017706820741295815\n","Batch 800, Loss: 0.06352539360523224\n","Batch 810, Loss: 0.032201677560806274\n","Batch 820, Loss: 0.004915878176689148\n","Batch 830, Loss: 0.007089451886713505\n","Batch 840, Loss: 0.011806420981884003\n","Batch 850, Loss: 0.024075476452708244\n","Batch 860, Loss: 0.027330780401825905\n","Batch 870, Loss: 0.051635999232530594\n","Batch 880, Loss: 0.08346758782863617\n","Batch 890, Loss: 0.05005941540002823\n","Batch 900, Loss: 0.03970586135983467\n","Batch 910, Loss: 0.04915321245789528\n","Batch 920, Loss: 0.3177413046360016\n","Batch 930, Loss: 0.040210969746112823\n","Test Error: \n"," Accuracy: 88.7%, Avg loss: 0.753707 \n","\n","--------------------------------------------------\n","Epoch 58/100\n","Batch 0, Loss: 0.06957827508449554\n","Batch 10, Loss: 0.08596546947956085\n","Batch 20, Loss: 0.0504307895898819\n","Batch 30, Loss: 0.054071106016635895\n","Batch 40, Loss: 0.057138681411743164\n","Batch 50, Loss: 0.05442620813846588\n","Batch 60, Loss: 0.013251819647848606\n","Batch 70, Loss: 0.04575306177139282\n","Batch 80, Loss: 0.0276462621986866\n","Batch 90, Loss: 0.04717560112476349\n","Batch 100, Loss: 0.02590210922062397\n","Batch 110, Loss: 0.00190830253995955\n","Batch 120, Loss: 0.0022250344045460224\n","Batch 130, Loss: 0.015865350142121315\n","Batch 140, Loss: 0.005382864736020565\n","Batch 150, Loss: 0.018555879592895508\n","Batch 160, Loss: 0.04986261576414108\n","Batch 170, Loss: 0.07330463081598282\n","Batch 180, Loss: 0.01844227872788906\n","Batch 190, Loss: 0.037019241601228714\n","Batch 200, Loss: 0.018220538273453712\n","Batch 210, Loss: 0.016490474343299866\n","Batch 220, Loss: 0.018102774396538734\n","Batch 230, Loss: 0.06605342775583267\n","Batch 240, Loss: 0.04144175350666046\n","Batch 250, Loss: 0.02195146307349205\n","Batch 260, Loss: 0.07083959877490997\n","Batch 270, Loss: 0.07328080385923386\n","Batch 280, Loss: 0.07846156507730484\n","Batch 290, Loss: 0.01568501628935337\n","Batch 300, Loss: 0.17604917287826538\n","Batch 310, Loss: 0.024206796661019325\n","Batch 320, Loss: 0.03624812141060829\n","Batch 330, Loss: 0.009366397745907307\n","Batch 340, Loss: 0.01827617920935154\n","Batch 350, Loss: 0.11998134851455688\n","Batch 360, Loss: 0.05999026820063591\n","Batch 370, Loss: 0.023728448897600174\n","Batch 380, Loss: 0.025551991537213326\n","Batch 390, Loss: 0.048496395349502563\n","Batch 400, Loss: 0.023424886167049408\n","Batch 410, Loss: 0.1298375427722931\n","Batch 420, Loss: 0.028999928385019302\n","Batch 430, Loss: 0.03645073249936104\n","Batch 440, Loss: 0.06018394976854324\n","Batch 450, Loss: 0.04594527184963226\n","Batch 460, Loss: 0.04700986295938492\n","Batch 470, Loss: 0.011267491616308689\n","Batch 480, Loss: 0.07861297577619553\n","Batch 490, Loss: 0.018344426527619362\n","Batch 500, Loss: 0.93301922082901\n","Batch 510, Loss: 0.04722139984369278\n","Batch 520, Loss: 0.048970308154821396\n","Batch 530, Loss: 0.31520935893058777\n","Batch 540, Loss: 0.039724018424749374\n","Batch 550, Loss: 0.08712019771337509\n","Batch 560, Loss: 0.09467972815036774\n","Batch 570, Loss: 0.08500564843416214\n","Batch 580, Loss: 0.06475568562746048\n","Batch 590, Loss: 0.04138577729463577\n","Batch 600, Loss: 0.1655207723379135\n","Batch 610, Loss: 0.17973746359348297\n","Batch 620, Loss: 0.2179948091506958\n","Batch 630, Loss: 0.024776797741651535\n","Batch 640, Loss: 0.27417677640914917\n","Batch 650, Loss: 0.010826914571225643\n","Batch 660, Loss: 0.1095508262515068\n","Batch 670, Loss: 0.1235225647687912\n","Batch 680, Loss: 0.021667946130037308\n","Batch 690, Loss: 0.021346919238567352\n","Batch 700, Loss: 0.05596723034977913\n","Batch 710, Loss: 0.11140453070402145\n","Batch 720, Loss: 0.05028178542852402\n","Batch 730, Loss: 0.03668879717588425\n","Batch 740, Loss: 0.08810202777385712\n","Batch 750, Loss: 0.07169191539287567\n","Batch 760, Loss: 0.010479297488927841\n","Batch 770, Loss: 0.02820606157183647\n","Batch 780, Loss: 0.022714434191584587\n","Batch 790, Loss: 0.016343940049409866\n","Batch 800, Loss: 0.023825103417038918\n","Batch 810, Loss: 0.008466051891446114\n","Batch 820, Loss: 0.0277948509901762\n","Batch 830, Loss: 0.04398912191390991\n","Batch 840, Loss: 0.08616963028907776\n","Batch 850, Loss: 0.030998587608337402\n","Batch 860, Loss: 0.025234248489141464\n","Batch 870, Loss: 0.0798095092177391\n","Batch 880, Loss: 0.06215965375304222\n","Batch 890, Loss: 0.004295881371945143\n","Batch 900, Loss: 0.099690742790699\n","Batch 910, Loss: 0.01896768808364868\n","Batch 920, Loss: 0.01916186884045601\n","Batch 930, Loss: 0.027746601030230522\n","Test Error: \n"," Accuracy: 89.0%, Avg loss: 0.811427 \n","\n","--------------------------------------------------\n","Epoch 59/100\n","Batch 0, Loss: 0.12696172297000885\n","Batch 10, Loss: 0.06714487075805664\n","Batch 20, Loss: 0.0297711044549942\n","Batch 30, Loss: 0.023015819489955902\n","Batch 40, Loss: 0.046724312007427216\n","Batch 50, Loss: 0.07355087995529175\n","Batch 60, Loss: 0.04619915038347244\n","Batch 70, Loss: 0.025622893124818802\n","Batch 80, Loss: 0.01095420029014349\n","Batch 90, Loss: 0.009557612240314484\n","Batch 100, Loss: 0.007746229879558086\n","Batch 110, Loss: 0.05873865634202957\n","Batch 120, Loss: 0.030445480719208717\n","Batch 130, Loss: 0.0355231836438179\n","Batch 140, Loss: 0.00948844663798809\n","Batch 150, Loss: 0.11284042149782181\n","Batch 160, Loss: 0.0023052399046719074\n","Batch 170, Loss: 0.11753677576780319\n","Batch 180, Loss: 0.014087537303566933\n","Batch 190, Loss: 0.02531920000910759\n","Batch 200, Loss: 0.08529110997915268\n","Batch 210, Loss: 0.010815076529979706\n","Batch 220, Loss: 0.016590874642133713\n","Batch 230, Loss: 0.023511670529842377\n","Batch 240, Loss: 0.02978365309536457\n","Batch 250, Loss: 0.03387865051627159\n","Batch 260, Loss: 0.03024078905582428\n","Batch 270, Loss: 0.033723317086696625\n","Batch 280, Loss: 0.04460038244724274\n","Batch 290, Loss: 0.03269374743103981\n","Batch 300, Loss: 0.029541071504354477\n","Batch 310, Loss: 0.10515373945236206\n","Batch 320, Loss: 0.1174975037574768\n","Batch 330, Loss: 0.021791577339172363\n","Batch 340, Loss: 0.02388070523738861\n","Batch 350, Loss: 0.06584730744361877\n","Batch 360, Loss: 0.0033189926762133837\n","Batch 370, Loss: 0.021544577553868294\n","Batch 380, Loss: 0.029078396037220955\n","Batch 390, Loss: 0.0628526508808136\n","Batch 400, Loss: 0.006997232791036367\n","Batch 410, Loss: 0.016175756230950356\n","Batch 420, Loss: 0.04966941475868225\n","Batch 430, Loss: 0.07153452932834625\n","Batch 440, Loss: 0.148373082280159\n","Batch 450, Loss: 0.004763571545481682\n","Batch 460, Loss: 0.029648754745721817\n","Batch 470, Loss: 0.025319967418909073\n","Batch 480, Loss: 0.04665464162826538\n","Batch 490, Loss: 0.12497851252555847\n","Batch 500, Loss: 0.05051654949784279\n","Batch 510, Loss: 0.13843591511249542\n","Batch 520, Loss: 0.021924437955021858\n","Batch 530, Loss: 0.0526394285261631\n","Batch 540, Loss: 0.0802706703543663\n","Batch 550, Loss: 0.06493046134710312\n","Batch 560, Loss: 0.020653188228607178\n","Batch 570, Loss: 0.006170391570776701\n","Batch 580, Loss: 0.0980321541428566\n","Batch 590, Loss: 0.009072509594261646\n","Batch 600, Loss: 0.1080210953950882\n","Batch 610, Loss: 0.056732580065727234\n","Batch 620, Loss: 0.15962925553321838\n","Batch 630, Loss: 0.07546616345643997\n","Batch 640, Loss: 0.05205395817756653\n","Batch 650, Loss: 0.09421069175004959\n","Batch 660, Loss: 0.030913572758436203\n","Batch 670, Loss: 0.025136170908808708\n","Batch 680, Loss: 0.04487079381942749\n","Batch 690, Loss: 0.06959253549575806\n","Batch 700, Loss: 0.1027870625257492\n","Batch 710, Loss: 0.04804481565952301\n","Batch 720, Loss: 0.03576678782701492\n","Batch 730, Loss: 0.047816962003707886\n","Batch 740, Loss: 0.005117400083690882\n","Batch 750, Loss: 0.04824088513851166\n","Batch 760, Loss: 0.11511115729808807\n","Batch 770, Loss: 0.05507506802678108\n","Batch 780, Loss: 0.08860276639461517\n","Batch 790, Loss: 0.0985390767455101\n","Batch 800, Loss: 0.11359760165214539\n","Batch 810, Loss: 0.02085971087217331\n","Batch 820, Loss: 0.0462174154818058\n","Batch 830, Loss: 0.03545312583446503\n","Batch 840, Loss: 0.04924291744828224\n","Batch 850, Loss: 0.0025201127864420414\n","Batch 860, Loss: 0.0019725195597857237\n","Batch 870, Loss: 0.0281662754714489\n","Batch 880, Loss: 0.04499449208378792\n","Batch 890, Loss: 0.06073969230055809\n","Batch 900, Loss: 0.03137219324707985\n","Batch 910, Loss: 0.023044399917125702\n","Batch 920, Loss: 0.044346883893013\n","Batch 930, Loss: 0.03421885520219803\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.809932 \n","\n","--------------------------------------------------\n","Epoch 60/100\n","Batch 0, Loss: 0.06981666386127472\n","Batch 10, Loss: 0.016491927206516266\n","Batch 20, Loss: 0.09056881815195084\n","Batch 30, Loss: 0.04780742526054382\n","Batch 40, Loss: 0.04491524025797844\n","Batch 50, Loss: 0.0712166577577591\n","Batch 60, Loss: 0.0066908011212944984\n","Batch 70, Loss: 0.026105115190148354\n","Batch 80, Loss: 0.015888821333646774\n","Batch 90, Loss: 0.07107406109571457\n","Batch 100, Loss: 0.08539218455553055\n","Batch 110, Loss: 0.06139514222741127\n","Batch 120, Loss: 0.038883280009031296\n","Batch 130, Loss: 0.018232187256217003\n","Batch 140, Loss: 0.021759776398539543\n","Batch 150, Loss: 0.015014924108982086\n","Batch 160, Loss: 0.024884739890694618\n","Batch 170, Loss: 0.04858306050300598\n","Batch 180, Loss: 0.013096822425723076\n","Batch 190, Loss: 0.0021008034236729145\n","Batch 200, Loss: 0.003009944222867489\n","Batch 210, Loss: 0.005328275263309479\n","Batch 220, Loss: 0.06802152842283249\n","Batch 230, Loss: 0.00364617258310318\n","Batch 240, Loss: 0.049155689775943756\n","Batch 250, Loss: 0.19372303783893585\n","Batch 260, Loss: 0.025821173563599586\n","Batch 270, Loss: 0.014648936688899994\n","Batch 280, Loss: 0.0971391499042511\n","Batch 290, Loss: 0.02474880777299404\n","Batch 300, Loss: 0.08865823596715927\n","Batch 310, Loss: 0.04153851792216301\n","Batch 320, Loss: 0.05320347473025322\n","Batch 330, Loss: 0.0253116674721241\n","Batch 340, Loss: 0.0145608801394701\n","Batch 350, Loss: 0.00421894108876586\n","Batch 360, Loss: 0.016877198591828346\n","Batch 370, Loss: 0.08849772810935974\n","Batch 380, Loss: 0.022602777928113937\n","Batch 390, Loss: 0.017872704192996025\n","Batch 400, Loss: 0.09669285267591476\n","Batch 410, Loss: 0.0034218409564346075\n","Batch 420, Loss: 0.00661895889788866\n","Batch 430, Loss: 0.010014536790549755\n","Batch 440, Loss: 0.006253163330256939\n","Batch 450, Loss: 0.011705191805958748\n","Batch 460, Loss: 0.01941595785319805\n","Batch 470, Loss: 0.05776160582900047\n","Batch 480, Loss: 0.041998784989118576\n","Batch 490, Loss: 0.04946546256542206\n","Batch 500, Loss: 0.18438820540905\n","Batch 510, Loss: 0.06826938688755035\n","Batch 520, Loss: 0.025461290031671524\n","Batch 530, Loss: 0.048000723123550415\n","Batch 540, Loss: 0.05501329153776169\n","Batch 550, Loss: 0.03775792941451073\n","Batch 560, Loss: 0.006607141811400652\n","Batch 570, Loss: 0.08734029531478882\n","Batch 580, Loss: 0.014756223186850548\n","Batch 590, Loss: 0.0086680231615901\n","Batch 600, Loss: 0.08345754444599152\n","Batch 610, Loss: 0.08254854381084442\n","Batch 620, Loss: 0.018716270104050636\n","Batch 630, Loss: 0.08260747045278549\n","Batch 640, Loss: 0.012653701938688755\n","Batch 650, Loss: 0.008502235636115074\n","Batch 660, Loss: 0.005280615761876106\n","Batch 670, Loss: 0.025934692472219467\n","Batch 680, Loss: 0.03473127260804176\n","Batch 690, Loss: 0.07039555162191391\n","Batch 700, Loss: 0.09429949522018433\n","Batch 710, Loss: 0.005197084508836269\n","Batch 720, Loss: 0.010957579128444195\n","Batch 730, Loss: 0.02938879281282425\n","Batch 740, Loss: 0.019965823739767075\n","Batch 750, Loss: 0.0915113016963005\n","Batch 760, Loss: 0.0015337837394326925\n","Batch 770, Loss: 0.018637055531144142\n","Batch 780, Loss: 0.09837828576564789\n","Batch 790, Loss: 0.007858751341700554\n","Batch 800, Loss: 0.03415762633085251\n","Batch 810, Loss: 0.04841843992471695\n","Batch 820, Loss: 0.045697636902332306\n","Batch 830, Loss: 0.008694330230355263\n","Batch 840, Loss: 0.06067076325416565\n","Batch 850, Loss: 0.02082959935069084\n","Batch 860, Loss: 0.014080417342483997\n","Batch 870, Loss: 0.08780556917190552\n","Batch 880, Loss: 0.01910589262843132\n","Batch 890, Loss: 0.037970516830682755\n","Batch 900, Loss: 0.04279053211212158\n","Batch 910, Loss: 0.15709993243217468\n","Batch 920, Loss: 0.03460420295596123\n","Batch 930, Loss: 0.014762559905648232\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.821751 \n","\n","--------------------------------------------------\n","Epoch 61/100\n","Batch 0, Loss: 0.04742055386304855\n","Batch 10, Loss: 0.01992633007466793\n","Batch 20, Loss: 0.007298637181520462\n","Batch 30, Loss: 0.024520020931959152\n","Batch 40, Loss: 0.06896460056304932\n","Batch 50, Loss: 0.004968952853232622\n","Batch 60, Loss: 0.01844617910683155\n","Batch 70, Loss: 0.024598998948931694\n","Batch 80, Loss: 0.016503890976309776\n","Batch 90, Loss: 0.037162840366363525\n","Batch 100, Loss: 0.0076460642740130424\n","Batch 110, Loss: 0.04850231483578682\n","Batch 120, Loss: 0.01516610849648714\n","Batch 130, Loss: 0.022903015837073326\n","Batch 140, Loss: 0.02851046249270439\n","Batch 150, Loss: 0.00970170833170414\n","Batch 160, Loss: 0.01712987944483757\n","Batch 170, Loss: 0.025503749027848244\n","Batch 180, Loss: 0.013398488983511925\n","Batch 190, Loss: 0.009760892018675804\n","Batch 200, Loss: 0.007290537003427744\n","Batch 210, Loss: 0.05077541992068291\n","Batch 220, Loss: 0.03423536941409111\n","Batch 230, Loss: 0.010691467672586441\n","Batch 240, Loss: 0.03674022853374481\n","Batch 250, Loss: 0.004564791452139616\n","Batch 260, Loss: 0.04872508719563484\n","Batch 270, Loss: 0.05443292856216431\n","Batch 280, Loss: 0.0783785954117775\n","Batch 290, Loss: 0.05112122744321823\n","Batch 300, Loss: 0.07722757756710052\n","Batch 310, Loss: 0.011365678161382675\n","Batch 320, Loss: 0.009470714256167412\n","Batch 330, Loss: 0.15506036579608917\n","Batch 340, Loss: 0.014066319912672043\n","Batch 350, Loss: 0.0453195758163929\n","Batch 360, Loss: 0.05996694043278694\n","Batch 370, Loss: 0.02096647396683693\n","Batch 380, Loss: 0.04211195930838585\n","Batch 390, Loss: 0.006453483831137419\n","Batch 400, Loss: 0.04022335633635521\n","Batch 410, Loss: 0.10290051251649857\n","Batch 420, Loss: 0.04801873490214348\n","Batch 430, Loss: 0.09030833840370178\n","Batch 440, Loss: 0.11148790270090103\n","Batch 450, Loss: 0.055437520146369934\n","Batch 460, Loss: 0.016211478039622307\n","Batch 470, Loss: 0.027519021183252335\n","Batch 480, Loss: 0.05581206455826759\n","Batch 490, Loss: 0.005513424053788185\n","Batch 500, Loss: 0.04127407446503639\n","Batch 510, Loss: 0.02827945351600647\n","Batch 520, Loss: 0.02578890509903431\n","Batch 530, Loss: 0.08488570898771286\n","Batch 540, Loss: 0.032650142908096313\n","Batch 550, Loss: 0.0005353153683245182\n","Batch 560, Loss: 0.05015049874782562\n","Batch 570, Loss: 0.003265789709985256\n","Batch 580, Loss: 0.04934738576412201\n","Batch 590, Loss: 0.0356147438287735\n","Batch 600, Loss: 0.014949014410376549\n","Batch 610, Loss: 0.1710171401500702\n","Batch 620, Loss: 0.14841435849666595\n","Batch 630, Loss: 0.04888250306248665\n","Batch 640, Loss: 0.026111939921975136\n","Batch 650, Loss: 0.019797425717115402\n","Batch 660, Loss: 0.012369750067591667\n","Batch 670, Loss: 0.01687292382121086\n","Batch 680, Loss: 0.009115993045270443\n","Batch 690, Loss: 0.016881274059414864\n","Batch 700, Loss: 0.009501286782324314\n","Batch 710, Loss: 0.01770244538784027\n","Batch 720, Loss: 0.03928053006529808\n","Batch 730, Loss: 0.03497661277651787\n","Batch 740, Loss: 0.05326446518301964\n","Batch 750, Loss: 0.027531340718269348\n","Batch 760, Loss: 0.1290576308965683\n","Batch 770, Loss: 0.012320632115006447\n","Batch 780, Loss: 0.014764214865863323\n","Batch 790, Loss: 0.024403166025877\n","Batch 800, Loss: 0.0761299729347229\n","Batch 810, Loss: 0.03169061243534088\n","Batch 820, Loss: 0.011386063881218433\n","Batch 830, Loss: 0.05713343992829323\n","Batch 840, Loss: 0.010900101624429226\n","Batch 850, Loss: 0.020572908222675323\n","Batch 860, Loss: 0.01204437855631113\n","Batch 870, Loss: 0.024302171543240547\n","Batch 880, Loss: 0.014001894742250443\n","Batch 890, Loss: 0.003814325202256441\n","Batch 900, Loss: 0.026588870212435722\n","Batch 910, Loss: 0.08283710479736328\n","Batch 920, Loss: 0.008532844483852386\n","Batch 930, Loss: 0.08957027643918991\n","Test Error: \n"," Accuracy: 89.7%, Avg loss: 0.850609 \n","\n","--------------------------------------------------\n","Epoch 62/100\n","Batch 0, Loss: 0.2438853681087494\n","Batch 10, Loss: 0.17097064852714539\n","Batch 20, Loss: 0.10716007649898529\n","Batch 30, Loss: 0.09530479460954666\n","Batch 40, Loss: 0.10030429065227509\n","Batch 50, Loss: 0.011775828897953033\n","Batch 60, Loss: 0.19334068894386292\n","Batch 70, Loss: 0.006504233460873365\n","Batch 80, Loss: 0.07821745425462723\n","Batch 90, Loss: 0.08702084422111511\n","Batch 100, Loss: 0.014854451641440392\n","Batch 110, Loss: 0.005426483694463968\n","Batch 120, Loss: 0.018972784280776978\n","Batch 130, Loss: 0.1727154701948166\n","Batch 140, Loss: 0.031867362558841705\n","Batch 150, Loss: 0.10244821012020111\n","Batch 160, Loss: 0.03375246003270149\n","Batch 170, Loss: 0.03993792459368706\n","Batch 180, Loss: 0.036999255418777466\n","Batch 190, Loss: 0.029192492365837097\n","Batch 200, Loss: 0.02595933899283409\n","Batch 210, Loss: 0.005615989677608013\n","Batch 220, Loss: 0.02025165781378746\n","Batch 230, Loss: 0.004362647421658039\n","Batch 240, Loss: 0.020026303827762604\n","Batch 250, Loss: 0.007931015454232693\n","Batch 260, Loss: 0.03171022981405258\n","Batch 270, Loss: 0.029811756685376167\n","Batch 280, Loss: 0.02606404945254326\n","Batch 290, Loss: 0.008887765929102898\n","Batch 300, Loss: 0.018205150961875916\n","Batch 310, Loss: 0.03672052174806595\n","Batch 320, Loss: 0.01588066667318344\n","Batch 330, Loss: 0.014503044076263905\n","Batch 340, Loss: 0.03739617392420769\n","Batch 350, Loss: 0.00023472747125197202\n","Batch 360, Loss: 0.04306861758232117\n","Batch 370, Loss: 0.03736766055226326\n","Batch 380, Loss: 0.04562734067440033\n","Batch 390, Loss: 0.03661007434129715\n","Batch 400, Loss: 0.09677859395742416\n","Batch 410, Loss: 0.08079754561185837\n","Batch 420, Loss: 0.03239654377102852\n","Batch 430, Loss: 0.01684514619410038\n","Batch 440, Loss: 0.0430571511387825\n","Batch 450, Loss: 0.06480101495981216\n","Batch 460, Loss: 0.02063116431236267\n","Batch 470, Loss: 0.0742378979921341\n","Batch 480, Loss: 0.12980550527572632\n","Batch 490, Loss: 0.06894265860319138\n","Batch 500, Loss: 0.0274856835603714\n","Batch 510, Loss: 0.007244236301630735\n","Batch 520, Loss: 0.05623706802725792\n","Batch 530, Loss: 0.09470933675765991\n","Batch 540, Loss: 0.05512845516204834\n","Batch 550, Loss: 0.02748764120042324\n","Batch 560, Loss: 0.004199264571070671\n","Batch 570, Loss: 0.022503986954689026\n","Batch 580, Loss: 0.12264254689216614\n","Batch 590, Loss: 0.08494912087917328\n","Batch 600, Loss: 0.1274857521057129\n","Batch 610, Loss: 0.008222490549087524\n","Batch 620, Loss: 0.054105449467897415\n","Batch 630, Loss: 0.041549503803253174\n","Batch 640, Loss: 0.04377435892820358\n","Batch 650, Loss: 0.02295815572142601\n","Batch 660, Loss: 0.19985537230968475\n","Batch 670, Loss: 0.05005202442407608\n","Batch 680, Loss: 0.06548182666301727\n","Batch 690, Loss: 0.03231519088149071\n","Batch 700, Loss: 0.1451723575592041\n","Batch 710, Loss: 0.0782991498708725\n","Batch 720, Loss: 0.01695430837571621\n","Batch 730, Loss: 0.06158445402979851\n","Batch 740, Loss: 0.04779546335339546\n","Batch 750, Loss: 0.05144631117582321\n","Batch 760, Loss: 0.004153350833803415\n","Batch 770, Loss: 0.14115998148918152\n","Batch 780, Loss: 0.030071325600147247\n","Batch 790, Loss: 0.010206147097051144\n","Batch 800, Loss: 0.02927447482943535\n","Batch 810, Loss: 0.0711335763335228\n","Batch 820, Loss: 0.124758280813694\n","Batch 830, Loss: 0.03353559598326683\n","Batch 840, Loss: 0.12522932887077332\n","Batch 850, Loss: 0.00674815010279417\n","Batch 860, Loss: 0.15819129347801208\n","Batch 870, Loss: 0.019610963761806488\n","Batch 880, Loss: 0.19649231433868408\n","Batch 890, Loss: 0.029304983094334602\n","Batch 900, Loss: 0.04344439134001732\n","Batch 910, Loss: 0.01088488008826971\n","Batch 920, Loss: 0.07883372157812119\n","Batch 930, Loss: 0.263132780790329\n","Test Error: \n"," Accuracy: 88.9%, Avg loss: 0.906337 \n","\n","--------------------------------------------------\n","Epoch 63/100\n","Batch 0, Loss: 0.014164143241941929\n","Batch 10, Loss: 0.020241832360625267\n","Batch 20, Loss: 0.07147765904664993\n","Batch 30, Loss: 0.11625120788812637\n","Batch 40, Loss: 0.02879762277007103\n","Batch 50, Loss: 0.0867532417178154\n","Batch 60, Loss: 0.06038825586438179\n","Batch 70, Loss: 0.0029412726871669292\n","Batch 80, Loss: 0.02830846607685089\n","Batch 90, Loss: 0.015418886207044125\n","Batch 100, Loss: 0.016346201300621033\n","Batch 110, Loss: 0.02932334877550602\n","Batch 120, Loss: 0.032921336591243744\n","Batch 130, Loss: 0.02782002091407776\n","Batch 140, Loss: 0.03139631822705269\n","Batch 150, Loss: 0.050932031124830246\n","Batch 160, Loss: 0.04590265825390816\n","Batch 170, Loss: 0.10826306790113449\n","Batch 180, Loss: 0.0180501751601696\n","Batch 190, Loss: 0.0158573966473341\n","Batch 200, Loss: 0.03410405293107033\n","Batch 210, Loss: 0.02933797426521778\n","Batch 220, Loss: 0.0616646409034729\n","Batch 230, Loss: 0.00509003596380353\n","Batch 240, Loss: 0.013834024779498577\n","Batch 250, Loss: 0.08399458974599838\n","Batch 260, Loss: 0.014924177899956703\n","Batch 270, Loss: 0.02481664903461933\n","Batch 280, Loss: 0.03504357114434242\n","Batch 290, Loss: 0.02464975044131279\n","Batch 300, Loss: 0.002832251600921154\n","Batch 310, Loss: 0.005792930256575346\n","Batch 320, Loss: 0.06434208154678345\n","Batch 330, Loss: 0.007887067273259163\n","Batch 340, Loss: 0.08091496676206589\n","Batch 350, Loss: 0.024895407259464264\n","Batch 360, Loss: 0.07839513570070267\n","Batch 370, Loss: 0.05630921572446823\n","Batch 380, Loss: 0.033464208245277405\n","Batch 390, Loss: 0.1768587827682495\n","Batch 400, Loss: 0.007216413971036673\n","Batch 410, Loss: 0.026874352246522903\n","Batch 420, Loss: 0.3657270669937134\n","Batch 430, Loss: 0.07739098370075226\n","Batch 440, Loss: 0.10206196457147598\n","Batch 450, Loss: 0.14212127029895782\n","Batch 460, Loss: 0.0089085903018713\n","Batch 470, Loss: 0.05747364088892937\n","Batch 480, Loss: 0.012075496837496758\n","Batch 490, Loss: 0.020872533321380615\n","Batch 500, Loss: 0.07823311537504196\n","Batch 510, Loss: 0.12537425756454468\n","Batch 520, Loss: 0.016589129343628883\n","Batch 530, Loss: 0.1432168334722519\n","Batch 540, Loss: 0.07057158648967743\n","Batch 550, Loss: 0.09650371968746185\n","Batch 560, Loss: 0.030358972027897835\n","Batch 570, Loss: 0.03677348792552948\n","Batch 580, Loss: 0.024399062618613243\n","Batch 590, Loss: 0.021749326959252357\n","Batch 600, Loss: 0.03010489232838154\n","Batch 610, Loss: 0.03922674432396889\n","Batch 620, Loss: 0.06195821985602379\n","Batch 630, Loss: 0.056209746748209\n","Batch 640, Loss: 0.06442935019731522\n","Batch 650, Loss: 0.017109671607613564\n","Batch 660, Loss: 0.002766955178231001\n","Batch 670, Loss: 0.017129896208643913\n","Batch 680, Loss: 0.053654201328754425\n","Batch 690, Loss: 0.007753949612379074\n","Batch 700, Loss: 0.010119779966771603\n","Batch 710, Loss: 0.04658477380871773\n","Batch 720, Loss: 0.12075264751911163\n","Batch 730, Loss: 0.007470274809747934\n","Batch 740, Loss: 0.007485599257051945\n","Batch 750, Loss: 0.03914330154657364\n","Batch 760, Loss: 0.005448619369417429\n","Batch 770, Loss: 0.009374750778079033\n","Batch 780, Loss: 0.038889940828084946\n","Batch 790, Loss: 0.003953688312321901\n","Batch 800, Loss: 0.07808686792850494\n","Batch 810, Loss: 0.0242015328258276\n","Batch 820, Loss: 0.0658802017569542\n","Batch 830, Loss: 0.10288038849830627\n","Batch 840, Loss: 0.011913119815289974\n","Batch 850, Loss: 0.08110691606998444\n","Batch 860, Loss: 0.0010439555626362562\n","Batch 870, Loss: 0.01947270892560482\n","Batch 880, Loss: 0.01881839521229267\n","Batch 890, Loss: 0.027058284729719162\n","Batch 900, Loss: 0.02631615847349167\n","Batch 910, Loss: 0.09544658660888672\n","Batch 920, Loss: 0.014174161478877068\n","Batch 930, Loss: 0.10354716330766678\n","Test Error: \n"," Accuracy: 89.8%, Avg loss: 0.787439 \n","\n","--------------------------------------------------\n","Epoch 64/100\n","Batch 0, Loss: 0.05985766276717186\n","Batch 10, Loss: 0.11372722685337067\n","Batch 20, Loss: 0.014923924580216408\n","Batch 30, Loss: 0.016356920823454857\n","Batch 40, Loss: 0.03761715814471245\n","Batch 50, Loss: 0.06674256175756454\n","Batch 60, Loss: 0.007678406313061714\n","Batch 70, Loss: 0.007136612199246883\n","Batch 80, Loss: 0.033602725714445114\n","Batch 90, Loss: 0.040859583765268326\n","Batch 100, Loss: 0.006507588550448418\n","Batch 110, Loss: 0.043661098927259445\n","Batch 120, Loss: 0.05230611935257912\n","Batch 130, Loss: 0.032313551753759384\n","Batch 140, Loss: 0.009714950807392597\n","Batch 150, Loss: 0.05580015480518341\n","Batch 160, Loss: 0.011082376353442669\n","Batch 170, Loss: 0.07155447453260422\n","Batch 180, Loss: 0.0033299371134489775\n","Batch 190, Loss: 0.07410312443971634\n","Batch 200, Loss: 0.01301480270922184\n","Batch 210, Loss: 0.006928424350917339\n","Batch 220, Loss: 0.032645102590322495\n","Batch 230, Loss: 0.029901403933763504\n","Batch 240, Loss: 0.014771710149943829\n","Batch 250, Loss: 0.02690913714468479\n","Batch 260, Loss: 0.0193052738904953\n","Batch 270, Loss: 0.00582580640912056\n","Batch 280, Loss: 0.03564555197954178\n","Batch 290, Loss: 0.00365117727778852\n","Batch 300, Loss: 0.008615707978606224\n","Batch 310, Loss: 0.014295217581093311\n","Batch 320, Loss: 0.015811143442988396\n","Batch 330, Loss: 0.032209157943725586\n","Batch 340, Loss: 0.019299454987049103\n","Batch 350, Loss: 0.017681129276752472\n","Batch 360, Loss: 0.33816981315612793\n","Batch 370, Loss: 0.01148925069719553\n","Batch 380, Loss: 0.018238581717014313\n","Batch 390, Loss: 0.06720221787691116\n","Batch 400, Loss: 0.00523810600861907\n","Batch 410, Loss: 0.010036105290055275\n","Batch 420, Loss: 0.006762139033526182\n","Batch 430, Loss: 0.011274545453488827\n","Batch 440, Loss: 0.02652355283498764\n","Batch 450, Loss: 0.04257733002305031\n","Batch 460, Loss: 0.024757815524935722\n","Batch 470, Loss: 0.11547591537237167\n","Batch 480, Loss: 0.5049616694450378\n","Batch 490, Loss: 0.03766431659460068\n","Batch 500, Loss: 0.05428491160273552\n","Batch 510, Loss: 0.036968525499105453\n","Batch 520, Loss: 0.03283093869686127\n","Batch 530, Loss: 0.07458818703889847\n","Batch 540, Loss: 0.04812874272465706\n","Batch 550, Loss: 0.0855615958571434\n","Batch 560, Loss: 0.05553438887000084\n","Batch 570, Loss: 0.09456106275320053\n","Batch 580, Loss: 0.06300101429224014\n","Batch 590, Loss: 0.032791223376989365\n","Batch 600, Loss: 0.05870451033115387\n","Batch 610, Loss: 0.06372818350791931\n","Batch 620, Loss: 0.01869932934641838\n","Batch 630, Loss: 0.032817497849464417\n","Batch 640, Loss: 0.04624488204717636\n","Batch 650, Loss: 0.06845489889383316\n","Batch 660, Loss: 0.09244367480278015\n","Batch 670, Loss: 0.047157756984233856\n","Batch 680, Loss: 0.06702611595392227\n","Batch 690, Loss: 0.040356509387493134\n","Batch 700, Loss: 0.04247022792696953\n","Batch 710, Loss: 0.011808271519839764\n","Batch 720, Loss: 0.0018709253054112196\n","Batch 730, Loss: 0.020813124254345894\n","Batch 740, Loss: 0.051965706050395966\n","Batch 750, Loss: 0.036006614565849304\n","Batch 760, Loss: 0.009154627099633217\n","Batch 770, Loss: 0.00950739998370409\n","Batch 780, Loss: 0.014671409502625465\n","Batch 790, Loss: 0.10306195169687271\n","Batch 800, Loss: 0.030411219224333763\n","Batch 810, Loss: 0.008778469637036324\n","Batch 820, Loss: 0.015576065517961979\n","Batch 830, Loss: 0.024038435891270638\n","Batch 840, Loss: 0.029281137511134148\n","Batch 850, Loss: 0.14300301671028137\n","Batch 860, Loss: 0.03324232995510101\n","Batch 870, Loss: 0.0613531693816185\n","Batch 880, Loss: 0.013896677643060684\n","Batch 890, Loss: 0.019094306975603104\n","Batch 900, Loss: 0.017182083800435066\n","Batch 910, Loss: 0.06399030983448029\n","Batch 920, Loss: 0.11121432483196259\n","Batch 930, Loss: 0.025554144755005836\n","Test Error: \n"," Accuracy: 89.9%, Avg loss: 0.816974 \n","\n","--------------------------------------------------\n","Epoch 65/100\n","Batch 0, Loss: 0.08238125592470169\n","Batch 10, Loss: 0.022676479071378708\n","Batch 20, Loss: 0.07060332596302032\n","Batch 30, Loss: 0.03187406435608864\n","Batch 40, Loss: 0.0061020865105092525\n","Batch 50, Loss: 0.07133392989635468\n","Batch 60, Loss: 0.06931520253419876\n","Batch 70, Loss: 0.07491154223680496\n","Batch 80, Loss: 0.01041223481297493\n","Batch 90, Loss: 0.011186509393155575\n","Batch 100, Loss: 0.056775834411382675\n","Batch 110, Loss: 0.02718540094792843\n","Batch 120, Loss: 0.033673208206892014\n","Batch 130, Loss: 0.005526880733668804\n","Batch 140, Loss: 0.06285596638917923\n","Batch 150, Loss: 0.017940232530236244\n","Batch 160, Loss: 0.12484408915042877\n","Batch 170, Loss: 0.043400734663009644\n","Batch 180, Loss: 0.03179208189249039\n","Batch 190, Loss: 0.06295976042747498\n","Batch 200, Loss: 0.009295301511883736\n","Batch 210, Loss: 0.01436722930520773\n","Batch 220, Loss: 0.008574246428906918\n","Batch 230, Loss: 0.004488836973905563\n","Batch 240, Loss: 0.008714081719517708\n","Batch 250, Loss: 0.016529886052012444\n","Batch 260, Loss: 0.04801584407687187\n","Batch 270, Loss: 0.0026348289102315903\n","Batch 280, Loss: 0.10629066079854965\n","Batch 290, Loss: 0.03396247699856758\n","Batch 300, Loss: 0.02092650905251503\n","Batch 310, Loss: 0.016189781948924065\n","Batch 320, Loss: 0.05859051272273064\n","Batch 330, Loss: 0.02094319835305214\n","Batch 340, Loss: 0.0210796557366848\n","Batch 350, Loss: 0.009781710803508759\n","Batch 360, Loss: 0.03390003368258476\n","Batch 370, Loss: 0.04895917698740959\n","Batch 380, Loss: 0.016904935240745544\n","Batch 390, Loss: 0.018383415415883064\n","Batch 400, Loss: 0.02620004303753376\n","Batch 410, Loss: 0.028107311576604843\n","Batch 420, Loss: 0.026892397552728653\n","Batch 430, Loss: 0.00786905363202095\n","Batch 440, Loss: 0.025436557829380035\n","Batch 450, Loss: 0.013912703841924667\n","Batch 460, Loss: 0.004053337499499321\n","Batch 470, Loss: 0.017861250787973404\n","Batch 480, Loss: 0.044879019260406494\n","Batch 490, Loss: 0.07292115688323975\n","Batch 500, Loss: 0.04659668356180191\n","Batch 510, Loss: 0.10207565873861313\n","Batch 520, Loss: 0.03943591192364693\n","Batch 530, Loss: 0.020064301788806915\n","Batch 540, Loss: 0.04427507892251015\n","Batch 550, Loss: 0.037458572536706924\n","Batch 560, Loss: 0.04615356773138046\n","Batch 570, Loss: 0.012431859970092773\n","Batch 580, Loss: 0.040569547563791275\n","Batch 590, Loss: 0.02759692817926407\n","Batch 600, Loss: 0.03367569297552109\n","Batch 610, Loss: 0.011776341125369072\n","Batch 620, Loss: 0.0983247235417366\n","Batch 630, Loss: 0.1105927899479866\n","Batch 640, Loss: 0.006839788053184748\n","Batch 650, Loss: 0.04833135008811951\n","Batch 660, Loss: 0.0880785584449768\n","Batch 670, Loss: 0.01239097397774458\n","Batch 680, Loss: 0.006168270017951727\n","Batch 690, Loss: 0.09182003140449524\n","Batch 700, Loss: 0.01657877489924431\n","Batch 710, Loss: 0.011481410823762417\n","Batch 720, Loss: 0.024758778512477875\n","Batch 730, Loss: 0.03281382471323013\n","Batch 740, Loss: 0.018626438453793526\n","Batch 750, Loss: 0.002736237132921815\n","Batch 760, Loss: 0.01155321579426527\n","Batch 770, Loss: 0.03685566410422325\n","Batch 780, Loss: 0.0047965808771550655\n","Batch 790, Loss: 0.020358635112643242\n","Batch 800, Loss: 0.029764289036393166\n","Batch 810, Loss: 0.02257990837097168\n","Batch 820, Loss: 0.03341011703014374\n","Batch 830, Loss: 0.003203815780580044\n","Batch 840, Loss: 0.009366657584905624\n","Batch 850, Loss: 0.003315828274935484\n","Batch 860, Loss: 0.05895407125353813\n","Batch 870, Loss: 0.010286536067724228\n","Batch 880, Loss: 0.04558983072638512\n","Batch 890, Loss: 0.023720692843198776\n","Batch 900, Loss: 0.017169037833809853\n","Batch 910, Loss: 0.01461317203938961\n","Batch 920, Loss: 0.029114743694663048\n","Batch 930, Loss: 0.04005071893334389\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 0.806583 \n","\n","--------------------------------------------------\n","Epoch 66/100\n","Batch 0, Loss: 0.01726626232266426\n","Batch 10, Loss: 0.00551976403221488\n","Batch 20, Loss: 0.023966412991285324\n","Batch 30, Loss: 0.08257048577070236\n","Batch 40, Loss: 0.007665911689400673\n","Batch 50, Loss: 0.008866913616657257\n","Batch 60, Loss: 0.07755131274461746\n","Batch 70, Loss: 0.016745062544941902\n","Batch 80, Loss: 0.06853066384792328\n","Batch 90, Loss: 0.021250249817967415\n","Batch 100, Loss: 0.021012723445892334\n","Batch 110, Loss: 0.052020471543073654\n","Batch 120, Loss: 0.19290636479854584\n","Batch 130, Loss: 0.040215589106082916\n","Batch 140, Loss: 0.06176307424902916\n","Batch 150, Loss: 0.04831578582525253\n","Batch 160, Loss: 0.04353318363428116\n","Batch 170, Loss: 0.004496189299970865\n","Batch 180, Loss: 0.08612803369760513\n","Batch 190, Loss: 0.1774667203426361\n","Batch 200, Loss: 0.075595423579216\n","Batch 210, Loss: 0.054514531046152115\n","Batch 220, Loss: 0.011255807243287563\n","Batch 230, Loss: 0.05799379199743271\n","Batch 240, Loss: 0.03218747302889824\n","Batch 250, Loss: 0.013179927133023739\n","Batch 260, Loss: 0.02633609063923359\n","Batch 270, Loss: 0.005043502897024155\n","Batch 280, Loss: 0.08012638986110687\n","Batch 290, Loss: 0.003199598053470254\n","Batch 300, Loss: 5.164679896552116e-05\n","Batch 310, Loss: 0.10993778705596924\n","Batch 320, Loss: 0.010810134932398796\n","Batch 330, Loss: 0.006786872632801533\n","Batch 340, Loss: 0.020136190578341484\n","Batch 350, Loss: 0.0358688049018383\n","Batch 360, Loss: 0.12851953506469727\n","Batch 370, Loss: 0.012116951867938042\n","Batch 380, Loss: 0.010406664572656155\n","Batch 390, Loss: 0.06874081492424011\n","Batch 400, Loss: 0.02155088260769844\n","Batch 410, Loss: 0.06554549932479858\n","Batch 420, Loss: 0.03678571805357933\n","Batch 430, Loss: 0.02422814816236496\n","Batch 440, Loss: 0.00300918729044497\n","Batch 450, Loss: 0.08734461665153503\n","Batch 460, Loss: 0.013722081668674946\n","Batch 470, Loss: 0.07427823543548584\n","Batch 480, Loss: 0.029535064473748207\n","Batch 490, Loss: 0.028236182406544685\n","Batch 500, Loss: 0.06710437685251236\n","Batch 510, Loss: 0.08384740352630615\n","Batch 520, Loss: 0.06750741600990295\n","Batch 530, Loss: 0.015938470140099525\n","Batch 540, Loss: 0.04068614915013313\n","Batch 550, Loss: 0.02289709821343422\n","Batch 560, Loss: 0.14535515010356903\n","Batch 570, Loss: 0.003302802098914981\n","Batch 580, Loss: 0.14634078741073608\n","Batch 590, Loss: 0.010336562991142273\n","Batch 600, Loss: 0.06021902710199356\n","Batch 610, Loss: 0.007114805281162262\n","Batch 620, Loss: 0.06718724966049194\n","Batch 630, Loss: 0.05308414250612259\n","Batch 640, Loss: 0.12801338732242584\n","Batch 650, Loss: 0.07700711488723755\n","Batch 660, Loss: 0.10248234868049622\n","Batch 670, Loss: 0.0747227892279625\n","Batch 680, Loss: 0.020425355061888695\n","Batch 690, Loss: 0.16741053760051727\n","Batch 700, Loss: 0.009832385927438736\n","Batch 710, Loss: 0.004862170200794935\n","Batch 720, Loss: 0.007123472169041634\n","Batch 730, Loss: 0.048575546592473984\n","Batch 740, Loss: 0.06977558135986328\n","Batch 750, Loss: 0.010027660056948662\n","Batch 760, Loss: 0.021870901808142662\n","Batch 770, Loss: 0.16018329560756683\n","Batch 780, Loss: 0.012888314202427864\n","Batch 790, Loss: 0.029261520132422447\n","Batch 800, Loss: 0.07275468111038208\n","Batch 810, Loss: 0.09942750632762909\n","Batch 820, Loss: 0.022357620298862457\n","Batch 830, Loss: 0.009900248609483242\n","Batch 840, Loss: 0.013722733594477177\n","Batch 850, Loss: 0.005926141515374184\n","Batch 860, Loss: 0.13458651304244995\n","Batch 870, Loss: 0.005957564804702997\n","Batch 880, Loss: 0.013557198457419872\n","Batch 890, Loss: 0.03785970062017441\n","Batch 900, Loss: 0.035301581025123596\n","Batch 910, Loss: 0.03381568193435669\n","Batch 920, Loss: 0.040178511291742325\n","Batch 930, Loss: 0.012264721095561981\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.811500 \n","\n","--------------------------------------------------\n","Epoch 67/100\n","Batch 0, Loss: 0.07017017900943756\n","Batch 10, Loss: 0.009279216639697552\n","Batch 20, Loss: 0.03522079437971115\n","Batch 30, Loss: 0.008966060355305672\n","Batch 40, Loss: 0.01979101076722145\n","Batch 50, Loss: 0.03899398073554039\n","Batch 60, Loss: 0.11797108501195908\n","Batch 70, Loss: 0.028867246583104134\n","Batch 80, Loss: 0.017898719757795334\n","Batch 90, Loss: 0.01471063680946827\n","Batch 100, Loss: 0.012498258613049984\n","Batch 110, Loss: 0.02454647794365883\n","Batch 120, Loss: 0.028362715616822243\n","Batch 130, Loss: 0.0022343206219375134\n","Batch 140, Loss: 0.04441537335515022\n","Batch 150, Loss: 0.02061139978468418\n","Batch 160, Loss: 0.131886288523674\n","Batch 170, Loss: 0.06694169342517853\n","Batch 180, Loss: 0.0829964205622673\n","Batch 190, Loss: 0.029309416189789772\n","Batch 200, Loss: 0.05176578462123871\n","Batch 210, Loss: 0.09852577745914459\n","Batch 220, Loss: 0.0804453045129776\n","Batch 230, Loss: 0.03937346860766411\n","Batch 240, Loss: 0.03316093608736992\n","Batch 250, Loss: 0.07973131537437439\n","Batch 260, Loss: 0.002815699903294444\n","Batch 270, Loss: 0.031327322125434875\n","Batch 280, Loss: 0.013601227663457394\n","Batch 290, Loss: 0.009959043934941292\n","Batch 300, Loss: 0.11845588684082031\n","Batch 310, Loss: 0.04949107766151428\n","Batch 320, Loss: 0.010560966096818447\n","Batch 330, Loss: 0.018346033990383148\n","Batch 340, Loss: 0.03324850648641586\n","Batch 350, Loss: 0.032247480005025864\n","Batch 360, Loss: 0.010680628009140491\n","Batch 370, Loss: 0.00425546383485198\n","Batch 380, Loss: 0.008122086524963379\n","Batch 390, Loss: 0.0006677160272374749\n","Batch 400, Loss: 0.038762547075748444\n","Batch 410, Loss: 0.03983398899435997\n","Batch 420, Loss: 0.022230859845876694\n","Batch 430, Loss: 0.08164603263139725\n","Batch 440, Loss: 0.103175088763237\n","Batch 450, Loss: 0.02709091082215309\n","Batch 460, Loss: 0.02014412172138691\n","Batch 470, Loss: 0.006327023264020681\n","Batch 480, Loss: 0.015622414648532867\n","Batch 490, Loss: 0.05993227660655975\n","Batch 500, Loss: 0.047007687389850616\n","Batch 510, Loss: 0.08669059723615646\n","Batch 520, Loss: 0.008602823130786419\n","Batch 530, Loss: 0.020493075251579285\n","Batch 540, Loss: 0.07179495692253113\n","Batch 550, Loss: 0.028982413932681084\n","Batch 560, Loss: 0.03856941685080528\n","Batch 570, Loss: 0.014525946229696274\n","Batch 580, Loss: 0.121982641518116\n","Batch 590, Loss: 0.03762546181678772\n","Batch 600, Loss: 0.028134144842624664\n","Batch 610, Loss: 0.006452186033129692\n","Batch 620, Loss: 0.02921799011528492\n","Batch 630, Loss: 0.0704408660531044\n","Batch 640, Loss: 0.005833230447024107\n","Batch 650, Loss: 0.009980026632547379\n","Batch 660, Loss: 0.03647678345441818\n","Batch 670, Loss: 0.0876748114824295\n","Batch 680, Loss: 0.04204336553812027\n","Batch 690, Loss: 0.08432338386774063\n","Batch 700, Loss: 0.07854907214641571\n","Batch 710, Loss: 0.02170475386083126\n","Batch 720, Loss: 0.028601214289665222\n","Batch 730, Loss: 0.01801908016204834\n","Batch 740, Loss: 0.051339223980903625\n","Batch 750, Loss: 0.029182743281126022\n","Batch 760, Loss: 0.17274148762226105\n","Batch 770, Loss: 0.05708688497543335\n","Batch 780, Loss: 0.026066675782203674\n","Batch 790, Loss: 0.13285450637340546\n","Batch 800, Loss: 0.0859537199139595\n","Batch 810, Loss: 0.0093461275100708\n","Batch 820, Loss: 0.07505520433187485\n","Batch 830, Loss: 0.05232838913798332\n","Batch 840, Loss: 0.04672076180577278\n","Batch 850, Loss: 0.03880395367741585\n","Batch 860, Loss: 0.025151433423161507\n","Batch 870, Loss: 0.07634476572275162\n","Batch 880, Loss: 0.11475858092308044\n","Batch 890, Loss: 0.14046582579612732\n","Batch 900, Loss: 0.15894882380962372\n","Batch 910, Loss: 0.0425497330725193\n","Batch 920, Loss: 0.09540371596813202\n","Batch 930, Loss: 0.0421280562877655\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.889037 \n","\n","--------------------------------------------------\n","Epoch 68/100\n","Batch 0, Loss: 0.010931323282420635\n","Batch 10, Loss: 0.06267634779214859\n","Batch 20, Loss: 0.05625170096755028\n","Batch 30, Loss: 0.016959019005298615\n","Batch 40, Loss: 0.10572003573179245\n","Batch 50, Loss: 0.02331683225929737\n","Batch 60, Loss: 0.019023476168513298\n","Batch 70, Loss: 0.0436362698674202\n","Batch 80, Loss: 0.021112000569701195\n","Batch 90, Loss: 0.09547749161720276\n","Batch 100, Loss: 0.012077514082193375\n","Batch 110, Loss: 0.08426957577466965\n","Batch 120, Loss: 0.03159836307168007\n","Batch 130, Loss: 0.06912335753440857\n","Batch 140, Loss: 0.22554433345794678\n","Batch 150, Loss: 0.01940486766397953\n","Batch 160, Loss: 0.07245011627674103\n","Batch 170, Loss: 0.03629770874977112\n","Batch 180, Loss: 0.042060017585754395\n","Batch 190, Loss: 0.05081896111369133\n","Batch 200, Loss: 0.22565065324306488\n","Batch 210, Loss: 0.09835736453533173\n","Batch 220, Loss: 0.05824088677763939\n","Batch 230, Loss: 0.0509769432246685\n","Batch 240, Loss: 0.019673245027661324\n","Batch 250, Loss: 0.05589817091822624\n","Batch 260, Loss: 0.009981513023376465\n","Batch 270, Loss: 0.016300853341817856\n","Batch 280, Loss: 0.008905777707695961\n","Batch 290, Loss: 0.02018820494413376\n","Batch 300, Loss: 0.0004449295811355114\n","Batch 310, Loss: 0.049480173736810684\n","Batch 320, Loss: 0.050983138382434845\n","Batch 330, Loss: 0.0009082177421078086\n","Batch 340, Loss: 0.06524570286273956\n","Batch 350, Loss: 0.07808460295200348\n","Batch 360, Loss: 0.012721613049507141\n","Batch 370, Loss: 0.06257165223360062\n","Batch 380, Loss: 0.13272477686405182\n","Batch 390, Loss: 0.043435242027044296\n","Batch 400, Loss: 0.09365319460630417\n","Batch 410, Loss: 0.07468137890100479\n","Batch 420, Loss: 0.003552757203578949\n","Batch 430, Loss: 0.08385670185089111\n","Batch 440, Loss: 0.009198775514960289\n","Batch 450, Loss: 0.005772160366177559\n","Batch 460, Loss: 0.01941024139523506\n","Batch 470, Loss: 0.049745287746191025\n","Batch 480, Loss: 0.019217979162931442\n","Batch 490, Loss: 0.12350953370332718\n","Batch 500, Loss: 0.026435958221554756\n","Batch 510, Loss: 0.0013644832652062178\n","Batch 520, Loss: 0.0029322304762899876\n","Batch 530, Loss: 0.007598314434289932\n","Batch 540, Loss: 0.03864474222064018\n","Batch 550, Loss: 0.04963616281747818\n","Batch 560, Loss: 0.008737259544432163\n","Batch 570, Loss: 0.12627564370632172\n","Batch 580, Loss: 0.02205793559551239\n","Batch 590, Loss: 0.031108587980270386\n","Batch 600, Loss: 0.005264673847705126\n","Batch 610, Loss: 0.016611021012067795\n","Batch 620, Loss: 0.02390391007065773\n","Batch 630, Loss: 0.03168642148375511\n","Batch 640, Loss: 0.032324180006980896\n","Batch 650, Loss: 0.018567614257335663\n","Batch 660, Loss: 0.024301370605826378\n","Batch 670, Loss: 0.0499819852411747\n","Batch 680, Loss: 0.05769699439406395\n","Batch 690, Loss: 0.032052408903837204\n","Batch 700, Loss: 0.1176019236445427\n","Batch 710, Loss: 0.006450596731156111\n","Batch 720, Loss: 0.01877073384821415\n","Batch 730, Loss: 0.07197745889425278\n","Batch 740, Loss: 0.019592583179473877\n","Batch 750, Loss: 0.03975014016032219\n","Batch 760, Loss: 0.005017457529902458\n","Batch 770, Loss: 0.0024647328536957502\n","Batch 780, Loss: 0.04461143910884857\n","Batch 790, Loss: 0.08813445270061493\n","Batch 800, Loss: 0.06924302130937576\n","Batch 810, Loss: 0.036199163645505905\n","Batch 820, Loss: 0.03954266011714935\n","Batch 830, Loss: 0.013966144062578678\n","Batch 840, Loss: 0.03813587874174118\n","Batch 850, Loss: 0.03311240300536156\n","Batch 860, Loss: 0.06684668362140656\n","Batch 870, Loss: 0.036965884268283844\n","Batch 880, Loss: 0.019310740754008293\n","Batch 890, Loss: 0.026169322431087494\n","Batch 900, Loss: 0.004029419738799334\n","Batch 910, Loss: 0.023743344470858574\n","Batch 920, Loss: 0.07610148936510086\n","Batch 930, Loss: 0.012695115990936756\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.917255 \n","\n","--------------------------------------------------\n","Epoch 69/100\n","Batch 0, Loss: 0.0018113383557647467\n","Batch 10, Loss: 0.10130234807729721\n","Batch 20, Loss: 0.03445390239357948\n","Batch 30, Loss: 0.1094624474644661\n","Batch 40, Loss: 0.12199687957763672\n","Batch 50, Loss: 0.007694428786635399\n","Batch 60, Loss: 0.013177304528653622\n","Batch 70, Loss: 0.027416488155722618\n","Batch 80, Loss: 0.0015236556064337492\n","Batch 90, Loss: 0.036032792180776596\n","Batch 100, Loss: 0.00801384262740612\n","Batch 110, Loss: 0.001766112633049488\n","Batch 120, Loss: 0.005089754704385996\n","Batch 130, Loss: 0.03498459234833717\n","Batch 140, Loss: 0.09562099725008011\n","Batch 150, Loss: 0.0218188539147377\n","Batch 160, Loss: 0.057926781475543976\n","Batch 170, Loss: 0.007490172516554594\n","Batch 180, Loss: 0.03716660663485527\n","Batch 190, Loss: 0.051236510276794434\n","Batch 200, Loss: 0.030772117897868156\n","Batch 210, Loss: 0.04039277508854866\n","Batch 220, Loss: 0.09086143225431442\n","Batch 230, Loss: 0.21195729076862335\n","Batch 240, Loss: 0.04131608083844185\n","Batch 250, Loss: 0.05720663443207741\n","Batch 260, Loss: 0.05306832864880562\n","Batch 270, Loss: 0.009150419384241104\n","Batch 280, Loss: 0.06293308734893799\n","Batch 290, Loss: 0.04846380650997162\n","Batch 300, Loss: 0.055226828902959824\n","Batch 310, Loss: 0.11068261414766312\n","Batch 320, Loss: 0.10406005382537842\n","Batch 330, Loss: 0.0340043269097805\n","Batch 340, Loss: 0.04095425829291344\n","Batch 350, Loss: 0.0010327294003218412\n","Batch 360, Loss: 0.05304861441254616\n","Batch 370, Loss: 0.08713320642709732\n","Batch 380, Loss: 0.01503875944763422\n","Batch 390, Loss: 0.00035867400583811104\n","Batch 400, Loss: 0.01995720900595188\n","Batch 410, Loss: 0.1237998902797699\n","Batch 420, Loss: 0.02731115184724331\n","Batch 430, Loss: 0.08528266102075577\n","Batch 440, Loss: 0.011974098160862923\n","Batch 450, Loss: 0.034978799521923065\n","Batch 460, Loss: 0.06913740932941437\n","Batch 470, Loss: 0.02207588031888008\n","Batch 480, Loss: 0.012447701767086983\n","Batch 490, Loss: 0.02613980881869793\n","Batch 500, Loss: 0.0012160587357357144\n","Batch 510, Loss: 0.035076938569545746\n","Batch 520, Loss: 0.0008537676185369492\n","Batch 530, Loss: 0.10230167955160141\n","Batch 540, Loss: 0.056655772030353546\n","Batch 550, Loss: 0.0031840645242482424\n","Batch 560, Loss: 0.027454789727926254\n","Batch 570, Loss: 0.02425035461783409\n","Batch 580, Loss: 0.09268728643655777\n","Batch 590, Loss: 0.5075140595436096\n","Batch 600, Loss: 0.08054721355438232\n","Batch 610, Loss: 0.10169906169176102\n","Batch 620, Loss: 0.05082576349377632\n","Batch 630, Loss: 0.054363515228033066\n","Batch 640, Loss: 0.029210872948169708\n","Batch 650, Loss: 0.00358080817386508\n","Batch 660, Loss: 0.016284441575407982\n","Batch 670, Loss: 0.012414483353495598\n","Batch 680, Loss: 0.07655342668294907\n","Batch 690, Loss: 0.03304450213909149\n","Batch 700, Loss: 0.15149861574172974\n","Batch 710, Loss: 0.006890228018164635\n","Batch 720, Loss: 0.03661426156759262\n","Batch 730, Loss: 0.009973878040909767\n","Batch 740, Loss: 0.037747737020254135\n","Batch 750, Loss: 0.005813853349536657\n","Batch 760, Loss: 0.02080455608665943\n","Batch 770, Loss: 0.0662657842040062\n","Batch 780, Loss: 0.013900365680456161\n","Batch 790, Loss: 0.028338473290205002\n","Batch 800, Loss: 0.04521416127681732\n","Batch 810, Loss: 0.006066891364753246\n","Batch 820, Loss: 0.08392539620399475\n","Batch 830, Loss: 0.12513993680477142\n","Batch 840, Loss: 0.03707459941506386\n","Batch 850, Loss: 0.022283349186182022\n","Batch 860, Loss: 0.0017591887153685093\n","Batch 870, Loss: 0.024179670959711075\n","Batch 880, Loss: 0.009516939520835876\n","Batch 890, Loss: 0.00733205396682024\n","Batch 900, Loss: 0.08951114118099213\n","Batch 910, Loss: 0.005866662133485079\n","Batch 920, Loss: 0.08559305220842361\n","Batch 930, Loss: 0.029669340699911118\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 0.891314 \n","\n","--------------------------------------------------\n","Epoch 70/100\n","Batch 0, Loss: 0.06950652599334717\n","Batch 10, Loss: 0.09023451060056686\n","Batch 20, Loss: 0.03795923292636871\n","Batch 30, Loss: 0.017703978344798088\n","Batch 40, Loss: 0.006654541939496994\n","Batch 50, Loss: 0.07209549844264984\n","Batch 60, Loss: 0.014545939862728119\n","Batch 70, Loss: 0.021925458684563637\n","Batch 80, Loss: 0.023046184331178665\n","Batch 90, Loss: 0.03352060541510582\n","Batch 100, Loss: 0.006346599664539099\n","Batch 110, Loss: 0.05414608120918274\n","Batch 120, Loss: 0.019398143514990807\n","Batch 130, Loss: 0.019829895347356796\n","Batch 140, Loss: 0.014658307656645775\n","Batch 150, Loss: 0.10197072476148605\n","Batch 160, Loss: 0.019718559458851814\n","Batch 170, Loss: 0.003981753718107939\n","Batch 180, Loss: 0.015466802753508091\n","Batch 190, Loss: 0.040131185203790665\n","Batch 200, Loss: 0.027322757989168167\n","Batch 210, Loss: 0.062188662588596344\n","Batch 220, Loss: 0.03523256257176399\n","Batch 230, Loss: 0.05238719657063484\n","Batch 240, Loss: 0.026598364114761353\n","Batch 250, Loss: 0.03639310225844383\n","Batch 260, Loss: 0.0018410364864394069\n","Batch 270, Loss: 0.001141925691626966\n","Batch 280, Loss: 0.14801795780658722\n","Batch 290, Loss: 0.035641614347696304\n","Batch 300, Loss: 0.035748422145843506\n","Batch 310, Loss: 0.05492014437913895\n","Batch 320, Loss: 0.005640256218612194\n","Batch 330, Loss: 0.041363030672073364\n","Batch 340, Loss: 0.0523482970893383\n","Batch 350, Loss: 0.06857803463935852\n","Batch 360, Loss: 0.003355936845764518\n","Batch 370, Loss: 0.004259574227035046\n","Batch 380, Loss: 0.011314590461552143\n","Batch 390, Loss: 0.07962905615568161\n","Batch 400, Loss: 0.014647599309682846\n","Batch 410, Loss: 0.010820189490914345\n","Batch 420, Loss: 0.06477692723274231\n","Batch 430, Loss: 0.02161620743572712\n","Batch 440, Loss: 0.05641847848892212\n","Batch 450, Loss: 0.051411885768175125\n","Batch 460, Loss: 0.032996729016304016\n","Batch 470, Loss: 0.11418285220861435\n","Batch 480, Loss: 0.03610742837190628\n","Batch 490, Loss: 0.0303197018802166\n","Batch 500, Loss: 0.027808355167508125\n","Batch 510, Loss: 0.029569484293460846\n","Batch 520, Loss: 0.020088255405426025\n","Batch 530, Loss: 0.04596085101366043\n","Batch 540, Loss: 0.11543809622526169\n","Batch 550, Loss: 0.07221252471208572\n","Batch 560, Loss: 0.03639163076877594\n","Batch 570, Loss: 0.02498011663556099\n","Batch 580, Loss: 0.041420068591833115\n","Batch 590, Loss: 0.12052592635154724\n","Batch 600, Loss: 0.041344013065099716\n","Batch 610, Loss: 0.01949138008058071\n","Batch 620, Loss: 0.03544968366622925\n","Batch 630, Loss: 0.09866687655448914\n","Batch 640, Loss: 0.034124042838811874\n","Batch 650, Loss: 0.026399176567792892\n","Batch 660, Loss: 0.023885613307356834\n","Batch 670, Loss: 0.05655065178871155\n","Batch 680, Loss: 0.015608690679073334\n","Batch 690, Loss: 0.1292276382446289\n","Batch 700, Loss: 0.03842610493302345\n","Batch 710, Loss: 0.02471891976892948\n","Batch 720, Loss: 0.06497979909181595\n","Batch 730, Loss: 0.006810564547777176\n","Batch 740, Loss: 0.05461423844099045\n","Batch 750, Loss: 0.07247059792280197\n","Batch 760, Loss: 0.023070288822054863\n","Batch 770, Loss: 0.05974217504262924\n","Batch 780, Loss: 0.06706080585718155\n","Batch 790, Loss: 0.00743428710848093\n","Batch 800, Loss: 0.017736922949552536\n","Batch 810, Loss: 0.012033338658511639\n","Batch 820, Loss: 0.12046604603528976\n","Batch 830, Loss: 0.004638903774321079\n","Batch 840, Loss: 0.04433364048600197\n","Batch 850, Loss: 0.032273150980472565\n","Batch 860, Loss: 0.06774385273456573\n","Batch 870, Loss: 0.019353115931153297\n","Batch 880, Loss: 0.037086956202983856\n","Batch 890, Loss: 0.017129961401224136\n","Batch 900, Loss: 0.11204047501087189\n","Batch 910, Loss: 0.09332486242055893\n","Batch 920, Loss: 0.06029123812913895\n","Batch 930, Loss: 0.10966131091117859\n","Test Error: \n"," Accuracy: 89.1%, Avg loss: 0.900806 \n","\n","--------------------------------------------------\n","Epoch 71/100\n","Batch 0, Loss: 0.06576623767614365\n","Batch 10, Loss: 0.014401128515601158\n","Batch 20, Loss: 0.014358831569552422\n","Batch 30, Loss: 0.04853445291519165\n","Batch 40, Loss: 0.031245587393641472\n","Batch 50, Loss: 0.012559947557747364\n","Batch 60, Loss: 0.05388791486620903\n","Batch 70, Loss: 0.03880136460065842\n","Batch 80, Loss: 0.0892188772559166\n","Batch 90, Loss: 0.012433239258825779\n","Batch 100, Loss: 0.16612675786018372\n","Batch 110, Loss: 0.179042786359787\n","Batch 120, Loss: 0.02511792629957199\n","Batch 130, Loss: 0.02843586914241314\n","Batch 140, Loss: 0.05376444756984711\n","Batch 150, Loss: 0.018715547397732735\n","Batch 160, Loss: 0.049993664026260376\n","Batch 170, Loss: 0.03393811360001564\n","Batch 180, Loss: 0.04482044652104378\n","Batch 190, Loss: 0.0016221122350543737\n","Batch 200, Loss: 0.025064412504434586\n","Batch 210, Loss: 0.009195945225656033\n","Batch 220, Loss: 0.004587912932038307\n","Batch 230, Loss: 0.1658051609992981\n","Batch 240, Loss: 0.1318143606185913\n","Batch 250, Loss: 0.1427645981311798\n","Batch 260, Loss: 0.05315340310335159\n","Batch 270, Loss: 0.004429774358868599\n","Batch 280, Loss: 0.004782704636454582\n","Batch 290, Loss: 0.04184458404779434\n","Batch 300, Loss: 0.1335994303226471\n","Batch 310, Loss: 0.026614779606461525\n","Batch 320, Loss: 0.014038226567208767\n","Batch 330, Loss: 0.06635128706693649\n","Batch 340, Loss: 0.11288638412952423\n","Batch 350, Loss: 0.0023494455963373184\n","Batch 360, Loss: 0.030283920466899872\n","Batch 370, Loss: 0.0010182379046455026\n","Batch 380, Loss: 0.017403047531843185\n","Batch 390, Loss: 0.00616133026778698\n","Batch 400, Loss: 0.02045459672808647\n","Batch 410, Loss: 0.08203253149986267\n","Batch 420, Loss: 0.005901692435145378\n","Batch 430, Loss: 0.03126409649848938\n","Batch 440, Loss: 0.03310060873627663\n","Batch 450, Loss: 0.01831749826669693\n","Batch 460, Loss: 0.038167282938957214\n","Batch 470, Loss: 0.025228191167116165\n","Batch 480, Loss: 0.020387006923556328\n","Batch 490, Loss: 0.07022877037525177\n","Batch 500, Loss: 0.005183028522878885\n","Batch 510, Loss: 0.03843231126666069\n","Batch 520, Loss: 0.004858613945543766\n","Batch 530, Loss: 0.0020380860660225153\n","Batch 540, Loss: 0.040517501533031464\n","Batch 550, Loss: 0.005784386768937111\n","Batch 560, Loss: 0.0344562791287899\n","Batch 570, Loss: 0.010657798498868942\n","Batch 580, Loss: 0.023824989795684814\n","Batch 590, Loss: 0.0180363692343235\n","Batch 600, Loss: 0.03271107003092766\n","Batch 610, Loss: 0.01566857285797596\n","Batch 620, Loss: 0.001279144547879696\n","Batch 630, Loss: 0.03116796351969242\n","Batch 640, Loss: 0.06405144184827805\n","Batch 650, Loss: 0.03496116027235985\n","Batch 660, Loss: 0.020593931898474693\n","Batch 670, Loss: 0.04597330838441849\n","Batch 680, Loss: 0.023391878232359886\n","Batch 690, Loss: 0.01749000884592533\n","Batch 700, Loss: 0.008638512343168259\n","Batch 710, Loss: 0.02604379504919052\n","Batch 720, Loss: 0.019219862297177315\n","Batch 730, Loss: 0.018185406923294067\n","Batch 740, Loss: 0.017839184030890465\n","Batch 750, Loss: 0.018829694017767906\n","Batch 760, Loss: 0.028064575046300888\n","Batch 770, Loss: 0.025971807539463043\n","Batch 780, Loss: 0.12393818795681\n","Batch 790, Loss: 0.028530243784189224\n","Batch 800, Loss: 0.012748843058943748\n","Batch 810, Loss: 0.013071422465145588\n","Batch 820, Loss: 0.025062821805477142\n","Batch 830, Loss: 0.04857741668820381\n","Batch 840, Loss: 0.06277047842741013\n","Batch 850, Loss: 0.05287570878863335\n","Batch 860, Loss: 0.042872603982686996\n","Batch 870, Loss: 0.038415148854255676\n","Batch 880, Loss: 0.011025259271264076\n","Batch 890, Loss: 0.10718167573213577\n","Batch 900, Loss: 0.025540536269545555\n","Batch 910, Loss: 0.04425093159079552\n","Batch 920, Loss: 0.017644263803958893\n","Batch 930, Loss: 0.0013621218968182802\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.842028 \n","\n","--------------------------------------------------\n","Epoch 72/100\n","Batch 0, Loss: 0.20374828577041626\n","Batch 10, Loss: 0.031777944415807724\n","Batch 20, Loss: 0.020092954859137535\n","Batch 30, Loss: 0.13608872890472412\n","Batch 40, Loss: 0.014320185407996178\n","Batch 50, Loss: 0.020454641431570053\n","Batch 60, Loss: 0.010960000567138195\n","Batch 70, Loss: 0.061481356620788574\n","Batch 80, Loss: 0.04980459436774254\n","Batch 90, Loss: 0.0803920105099678\n","Batch 100, Loss: 0.002437251154333353\n","Batch 110, Loss: 0.039226047694683075\n","Batch 120, Loss: 0.03426522761583328\n","Batch 130, Loss: 0.005765081383287907\n","Batch 140, Loss: 0.11209667474031448\n","Batch 150, Loss: 0.09193957597017288\n","Batch 160, Loss: 0.04679236188530922\n","Batch 170, Loss: 0.024895384907722473\n","Batch 180, Loss: 0.045858077704906464\n","Batch 190, Loss: 0.006449885666370392\n","Batch 200, Loss: 0.005539338104426861\n","Batch 210, Loss: 0.012709983624517918\n","Batch 220, Loss: 0.028346845880150795\n","Batch 230, Loss: 0.11919707804918289\n","Batch 240, Loss: 0.13472911715507507\n","Batch 250, Loss: 0.011580226942896843\n","Batch 260, Loss: 0.003979452885687351\n","Batch 270, Loss: 0.06290845572948456\n","Batch 280, Loss: 0.025462187826633453\n","Batch 290, Loss: 0.03511714190244675\n","Batch 300, Loss: 0.02341855689883232\n","Batch 310, Loss: 0.05336056277155876\n","Batch 320, Loss: 0.007161340210586786\n","Batch 330, Loss: 0.07748207449913025\n","Batch 340, Loss: 0.015245444141328335\n","Batch 350, Loss: 0.03742096573114395\n","Batch 360, Loss: 0.03610079735517502\n","Batch 370, Loss: 0.04136888310313225\n","Batch 380, Loss: 0.00894356332719326\n","Batch 390, Loss: 0.010740822181105614\n","Batch 400, Loss: 0.03795715421438217\n","Batch 410, Loss: 0.1299736201763153\n","Batch 420, Loss: 0.0546441525220871\n","Batch 430, Loss: 0.0827954113483429\n","Batch 440, Loss: 0.08469562232494354\n","Batch 450, Loss: 0.026633044704794884\n","Batch 460, Loss: 0.014260648749768734\n","Batch 470, Loss: 0.0131401801481843\n","Batch 480, Loss: 0.049147188663482666\n","Batch 490, Loss: 0.03437095135450363\n","Batch 500, Loss: 0.10147594660520554\n","Batch 510, Loss: 0.004016109276562929\n","Batch 520, Loss: 0.0243273563683033\n","Batch 530, Loss: 0.013166231103241444\n","Batch 540, Loss: 0.044788774102926254\n","Batch 550, Loss: 0.02671625278890133\n","Batch 560, Loss: 0.09101139008998871\n","Batch 570, Loss: 0.009013338014483452\n","Batch 580, Loss: 0.18572355806827545\n","Batch 590, Loss: 0.03527921438217163\n","Batch 600, Loss: 0.033720675855875015\n","Batch 610, Loss: 0.09931814670562744\n","Batch 620, Loss: 0.07105354219675064\n","Batch 630, Loss: 0.01444276049733162\n","Batch 640, Loss: 0.009867909364402294\n","Batch 650, Loss: 0.004575624596327543\n","Batch 660, Loss: 0.05086556822061539\n","Batch 670, Loss: 0.015757786110043526\n","Batch 680, Loss: 0.05195021629333496\n","Batch 690, Loss: 0.0912882536649704\n","Batch 700, Loss: 0.06951113045215607\n","Batch 710, Loss: 0.12476559728384018\n","Batch 720, Loss: 0.003798301098868251\n","Batch 730, Loss: 0.09941845387220383\n","Batch 740, Loss: 0.06578792631626129\n","Batch 750, Loss: 0.07310286909341812\n","Batch 760, Loss: 0.10862768441438675\n","Batch 770, Loss: 0.09211552888154984\n","Batch 780, Loss: 0.04739675670862198\n","Batch 790, Loss: 0.040952496230602264\n","Batch 800, Loss: 0.0810311958193779\n","Batch 810, Loss: 0.008888406679034233\n","Batch 820, Loss: 0.06904278695583344\n","Batch 830, Loss: 0.07036422193050385\n","Batch 840, Loss: 0.049542415887117386\n","Batch 850, Loss: 0.014611865393817425\n","Batch 860, Loss: 0.060218796133995056\n","Batch 870, Loss: 0.02635042369365692\n","Batch 880, Loss: 0.11158037930727005\n","Batch 890, Loss: 0.02974885143339634\n","Batch 900, Loss: 0.0222617257386446\n","Batch 910, Loss: 0.07798340171575546\n","Batch 920, Loss: 0.00890401378273964\n","Batch 930, Loss: 0.05479210615158081\n","Test Error: \n"," Accuracy: 89.2%, Avg loss: 1.003801 \n","\n","--------------------------------------------------\n","Epoch 73/100\n","Batch 0, Loss: 0.10937076061964035\n","Batch 10, Loss: 0.023813879117369652\n","Batch 20, Loss: 0.0427456796169281\n","Batch 30, Loss: 0.013313479721546173\n","Batch 40, Loss: 0.021412812173366547\n","Batch 50, Loss: 0.041160471737384796\n","Batch 60, Loss: 0.009069733321666718\n","Batch 70, Loss: 0.003873357316479087\n","Batch 80, Loss: 0.021889181807637215\n","Batch 90, Loss: 0.11109687387943268\n","Batch 100, Loss: 0.005540269892662764\n","Batch 110, Loss: 0.060185134410858154\n","Batch 120, Loss: 0.03056696429848671\n","Batch 130, Loss: 0.0077981422655284405\n","Batch 140, Loss: 0.03889443725347519\n","Batch 150, Loss: 0.008942686021327972\n","Batch 160, Loss: 0.005607199855148792\n","Batch 170, Loss: 0.03505473956465721\n","Batch 180, Loss: 0.07223374396562576\n","Batch 190, Loss: 0.028056563809514046\n","Batch 200, Loss: 0.0210751760751009\n","Batch 210, Loss: 0.034130118787288666\n","Batch 220, Loss: 0.030823690816760063\n","Batch 230, Loss: 0.031844060868024826\n","Batch 240, Loss: 0.006407562643289566\n","Batch 250, Loss: 0.08296959847211838\n","Batch 260, Loss: 0.039380237460136414\n","Batch 270, Loss: 0.01803991012275219\n","Batch 280, Loss: 0.03305348753929138\n","Batch 290, Loss: 0.012305415235459805\n","Batch 300, Loss: 0.04500100016593933\n","Batch 310, Loss: 0.02143683098256588\n","Batch 320, Loss: 0.026750994846224785\n","Batch 330, Loss: 0.05762607976794243\n","Batch 340, Loss: 0.012254011817276478\n","Batch 350, Loss: 0.03229876607656479\n","Batch 360, Loss: 0.021664367988705635\n","Batch 370, Loss: 0.12345302850008011\n","Batch 380, Loss: 0.1019606813788414\n","Batch 390, Loss: 0.11679449677467346\n","Batch 400, Loss: 0.0368155799806118\n","Batch 410, Loss: 0.0369669608771801\n","Batch 420, Loss: 0.0037704729475080967\n","Batch 430, Loss: 0.014378741383552551\n","Batch 440, Loss: 0.043659813702106476\n","Batch 450, Loss: 0.03685174137353897\n","Batch 460, Loss: 0.031398944556713104\n","Batch 470, Loss: 0.07707472890615463\n","Batch 480, Loss: 0.06650940328836441\n","Batch 490, Loss: 0.014545747078955173\n","Batch 500, Loss: 0.019715603440999985\n","Batch 510, Loss: 0.0010098295751959085\n","Batch 520, Loss: 0.07820818573236465\n","Batch 530, Loss: 0.018266810104250908\n","Batch 540, Loss: 0.19250677525997162\n","Batch 550, Loss: 0.09941035509109497\n","Batch 560, Loss: 0.006223780103027821\n","Batch 570, Loss: 0.07980562001466751\n","Batch 580, Loss: 0.03668978437781334\n","Batch 590, Loss: 0.05803826451301575\n","Batch 600, Loss: 0.01686697080731392\n","Batch 610, Loss: 0.04799500107765198\n","Batch 620, Loss: 0.005677747540175915\n","Batch 630, Loss: 0.017502587288618088\n","Batch 640, Loss: 0.07652197778224945\n","Batch 650, Loss: 0.03262675553560257\n","Batch 660, Loss: 0.032451972365379333\n","Batch 670, Loss: 0.027319690212607384\n","Batch 680, Loss: 0.06583697348833084\n","Batch 690, Loss: 0.0035701035521924496\n","Batch 700, Loss: 0.013022968545556068\n","Batch 710, Loss: 0.09379985183477402\n","Batch 720, Loss: 0.03224268555641174\n","Batch 730, Loss: 0.009329719468951225\n","Batch 740, Loss: 0.011587115935981274\n","Batch 750, Loss: 0.03933148458600044\n","Batch 760, Loss: 0.04234442487359047\n","Batch 770, Loss: 0.0029883147217333317\n","Batch 780, Loss: 0.07949649542570114\n","Batch 790, Loss: 0.004035643767565489\n","Batch 800, Loss: 0.007741226349025965\n","Batch 810, Loss: 0.01752953976392746\n","Batch 820, Loss: 0.013901084661483765\n","Batch 830, Loss: 0.07027272880077362\n","Batch 840, Loss: 0.0012046315241605043\n","Batch 850, Loss: 0.029667649418115616\n","Batch 860, Loss: 0.00882353913038969\n","Batch 870, Loss: 0.029885491356253624\n","Batch 880, Loss: 0.028410444036126137\n","Batch 890, Loss: 0.05187053233385086\n","Batch 900, Loss: 0.030162306502461433\n","Batch 910, Loss: 0.04521257057785988\n","Batch 920, Loss: 0.10055859386920929\n","Batch 930, Loss: 0.10585243999958038\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.933058 \n","\n","--------------------------------------------------\n","Epoch 74/100\n","Batch 0, Loss: 0.005702359136193991\n","Batch 10, Loss: 0.013270792551338673\n","Batch 20, Loss: 0.028151320293545723\n","Batch 30, Loss: 0.024523738771677017\n","Batch 40, Loss: 0.01381964236497879\n","Batch 50, Loss: 0.005809173919260502\n","Batch 60, Loss: 0.01306777261197567\n","Batch 70, Loss: 0.007535393349826336\n","Batch 80, Loss: 0.05510881170630455\n","Batch 90, Loss: 0.06517930328845978\n","Batch 100, Loss: 0.005165007431060076\n","Batch 110, Loss: 0.021242370828986168\n","Batch 120, Loss: 0.05119023472070694\n","Batch 130, Loss: 0.03125731274485588\n","Batch 140, Loss: 0.0018012713408097625\n","Batch 150, Loss: 0.03358329087495804\n","Batch 160, Loss: 0.024575255811214447\n","Batch 170, Loss: 0.06667188555002213\n","Batch 180, Loss: 0.016440538689494133\n","Batch 190, Loss: 0.011471201665699482\n","Batch 200, Loss: 0.05423321947455406\n","Batch 210, Loss: 0.020305210724473\n","Batch 220, Loss: 0.03021332249045372\n","Batch 230, Loss: 0.012863180600106716\n","Batch 240, Loss: 0.06115344166755676\n","Batch 250, Loss: 0.03475763648748398\n","Batch 260, Loss: 0.0025226448196917772\n","Batch 270, Loss: 0.01493940781801939\n","Batch 280, Loss: 0.04737846925854683\n","Batch 290, Loss: 0.022590670734643936\n","Batch 300, Loss: 0.009930530562996864\n","Batch 310, Loss: 0.13324566185474396\n","Batch 320, Loss: 0.07022298127412796\n","Batch 330, Loss: 0.08035635203123093\n","Batch 340, Loss: 0.035035163164138794\n","Batch 350, Loss: 0.07349083572626114\n","Batch 360, Loss: 0.03610174357891083\n","Batch 370, Loss: 0.008482053875923157\n","Batch 380, Loss: 0.03029520995914936\n","Batch 390, Loss: 0.09175404906272888\n","Batch 400, Loss: 0.01205780915915966\n","Batch 410, Loss: 0.22158923745155334\n","Batch 420, Loss: 0.0014927758602425456\n","Batch 430, Loss: 0.029025563970208168\n","Batch 440, Loss: 0.03344467654824257\n","Batch 450, Loss: 0.04592669755220413\n","Batch 460, Loss: 0.04208746552467346\n","Batch 470, Loss: 0.02726638875901699\n","Batch 480, Loss: 0.0319226048886776\n","Batch 490, Loss: 0.008217114955186844\n","Batch 500, Loss: 0.02568693645298481\n","Batch 510, Loss: 0.07913907617330551\n","Batch 520, Loss: 0.007095895707607269\n","Batch 530, Loss: 0.03758106753230095\n","Batch 540, Loss: 0.014167822897434235\n","Batch 550, Loss: 0.09802023321390152\n","Batch 560, Loss: 0.06176328659057617\n","Batch 570, Loss: 0.000672710535582155\n","Batch 580, Loss: 0.017410883679986\n","Batch 590, Loss: 0.011413922533392906\n","Batch 600, Loss: 0.016832055523991585\n","Batch 610, Loss: 0.0844946801662445\n","Batch 620, Loss: 0.020894331857562065\n","Batch 630, Loss: 0.013475407846271992\n","Batch 640, Loss: 0.002231225371360779\n","Batch 650, Loss: 0.002465240191668272\n","Batch 660, Loss: 0.025675058364868164\n","Batch 670, Loss: 0.029269104823470116\n","Batch 680, Loss: 0.016256095841526985\n","Batch 690, Loss: 0.019005494192242622\n","Batch 700, Loss: 0.03178873658180237\n","Batch 710, Loss: 0.00039485073648393154\n","Batch 720, Loss: 0.030576974153518677\n","Batch 730, Loss: 0.03549573943018913\n","Batch 740, Loss: 0.08512072265148163\n","Batch 750, Loss: 0.019651737064123154\n","Batch 760, Loss: 0.0463736429810524\n","Batch 770, Loss: 0.01380014419555664\n","Batch 780, Loss: 0.04124670475721359\n","Batch 790, Loss: 0.16733045876026154\n","Batch 800, Loss: 0.15454424917697906\n","Batch 810, Loss: 0.10715384781360626\n","Batch 820, Loss: 0.016533318907022476\n","Batch 830, Loss: 0.0959344133734703\n","Batch 840, Loss: 0.08840961009263992\n","Batch 850, Loss: 0.0012606293894350529\n","Batch 860, Loss: 0.0621148943901062\n","Batch 870, Loss: 0.009565341286361217\n","Batch 880, Loss: 0.14534670114517212\n","Batch 890, Loss: 0.044150352478027344\n","Batch 900, Loss: 0.04743335023522377\n","Batch 910, Loss: 0.025606803596019745\n","Batch 920, Loss: 0.04670961573719978\n","Batch 930, Loss: 0.15744177997112274\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.861047 \n","\n","--------------------------------------------------\n","Epoch 75/100\n","Batch 0, Loss: 0.009544589556753635\n","Batch 10, Loss: 0.03860650211572647\n","Batch 20, Loss: 0.0020725938957184553\n","Batch 30, Loss: 0.04516998305916786\n","Batch 40, Loss: 0.020656827837228775\n","Batch 50, Loss: 0.14461642503738403\n","Batch 60, Loss: 0.0157012939453125\n","Batch 70, Loss: 0.008404365740716457\n","Batch 80, Loss: 0.03644079342484474\n","Batch 90, Loss: 0.0751120075583458\n","Batch 100, Loss: 0.006356990896165371\n","Batch 110, Loss: 0.027742065489292145\n","Batch 120, Loss: 0.00477937888354063\n","Batch 130, Loss: 0.010335313156247139\n","Batch 140, Loss: 0.031837426126003265\n","Batch 150, Loss: 0.03298419341444969\n","Batch 160, Loss: 0.007280758582055569\n","Batch 170, Loss: 0.013894184492528439\n","Batch 180, Loss: 0.3124103844165802\n","Batch 190, Loss: 0.021144311875104904\n","Batch 200, Loss: 0.04084589332342148\n","Batch 210, Loss: 0.007023297715932131\n","Batch 220, Loss: 0.02050674520432949\n","Batch 230, Loss: 0.01568647287786007\n","Batch 240, Loss: 0.032140303403139114\n","Batch 250, Loss: 0.02698933333158493\n","Batch 260, Loss: 0.019993478432297707\n","Batch 270, Loss: 0.03481262922286987\n","Batch 280, Loss: 0.1030854731798172\n","Batch 290, Loss: 0.010600381530821323\n","Batch 300, Loss: 0.028427327051758766\n","Batch 310, Loss: 0.026577288284897804\n","Batch 320, Loss: 0.03697430342435837\n","Batch 330, Loss: 0.01726103387773037\n","Batch 340, Loss: 0.015638280659914017\n","Batch 350, Loss: 0.05339648574590683\n","Batch 360, Loss: 0.15786363184452057\n","Batch 370, Loss: 0.22720402479171753\n","Batch 380, Loss: 0.07144571095705032\n","Batch 390, Loss: 0.138526052236557\n","Batch 400, Loss: 0.03295070305466652\n","Batch 410, Loss: 0.09660613536834717\n","Batch 420, Loss: 0.044930003583431244\n","Batch 430, Loss: 0.05237821862101555\n","Batch 440, Loss: 0.049329012632369995\n","Batch 450, Loss: 0.048696503043174744\n","Batch 460, Loss: 0.07380156219005585\n","Batch 470, Loss: 0.056173231452703476\n","Batch 480, Loss: 0.05007859319448471\n","Batch 490, Loss: 0.008862157352268696\n","Batch 500, Loss: 0.08082809299230576\n","Batch 510, Loss: 0.1466897875070572\n","Batch 520, Loss: 0.055553097277879715\n","Batch 530, Loss: 0.001674323109909892\n","Batch 540, Loss: 0.05048085004091263\n","Batch 550, Loss: 0.07221394032239914\n","Batch 560, Loss: 0.07584451884031296\n","Batch 570, Loss: 0.01971171610057354\n","Batch 580, Loss: 0.019262952730059624\n","Batch 590, Loss: 0.04136621952056885\n","Batch 600, Loss: 0.2723674476146698\n","Batch 610, Loss: 0.03411848098039627\n","Batch 620, Loss: 0.10974586009979248\n","Batch 630, Loss: 0.005142407491803169\n","Batch 640, Loss: 0.031446848064661026\n","Batch 650, Loss: 0.014331428334116936\n","Batch 660, Loss: 0.010965988039970398\n","Batch 670, Loss: 0.04996173828840256\n","Batch 680, Loss: 0.008441213518381119\n","Batch 690, Loss: 0.09964302182197571\n","Batch 700, Loss: 0.044714611023664474\n","Batch 710, Loss: 0.028912443667650223\n","Batch 720, Loss: 0.08406119048595428\n","Batch 730, Loss: 0.18834349513053894\n","Batch 740, Loss: 0.025892699137330055\n","Batch 750, Loss: 0.05242752283811569\n","Batch 760, Loss: 0.011198915541172028\n","Batch 770, Loss: 0.009477086365222931\n","Batch 780, Loss: 0.01996942050755024\n","Batch 790, Loss: 0.005891275126487017\n","Batch 800, Loss: 0.005421783775091171\n","Batch 810, Loss: 0.046687643975019455\n","Batch 820, Loss: 0.16769428551197052\n","Batch 830, Loss: 0.010327769443392754\n","Batch 840, Loss: 0.03610164672136307\n","Batch 850, Loss: 0.005920598283410072\n","Batch 860, Loss: 0.004506443627178669\n","Batch 870, Loss: 0.0006830486236140132\n","Batch 880, Loss: 0.01288450974971056\n","Batch 890, Loss: 0.013668977655470371\n","Batch 900, Loss: 0.048674724996089935\n","Batch 910, Loss: 0.028817014768719673\n","Batch 920, Loss: 9.483434405410662e-05\n","Batch 930, Loss: 0.02177681401371956\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.920923 \n","\n","--------------------------------------------------\n","Epoch 76/100\n","Batch 0, Loss: 0.010631722398102283\n","Batch 10, Loss: 0.00099179707467556\n","Batch 20, Loss: 0.013346098363399506\n","Batch 30, Loss: 0.026135072112083435\n","Batch 40, Loss: 0.045290734618902206\n","Batch 50, Loss: 0.00735066831111908\n","Batch 60, Loss: 0.04138917475938797\n","Batch 70, Loss: 0.012246985919773579\n","Batch 80, Loss: 0.04577382653951645\n","Batch 90, Loss: 0.023594025522470474\n","Batch 100, Loss: 0.003681211033836007\n","Batch 110, Loss: 0.014707985334098339\n","Batch 120, Loss: 0.007431651931256056\n","Batch 130, Loss: 0.06428863108158112\n","Batch 140, Loss: 0.002248497446998954\n","Batch 150, Loss: 0.03643275052309036\n","Batch 160, Loss: 0.05010280758142471\n","Batch 170, Loss: 0.04343932867050171\n","Batch 180, Loss: 0.015348690561950207\n","Batch 190, Loss: 0.053569044917821884\n","Batch 200, Loss: 0.021060412749648094\n","Batch 210, Loss: 0.04950834810733795\n","Batch 220, Loss: 0.026957303285598755\n","Batch 230, Loss: 0.021637821570038795\n","Batch 240, Loss: 0.024073641747236252\n","Batch 250, Loss: 0.008899586275219917\n","Batch 260, Loss: 0.011505949310958385\n","Batch 270, Loss: 0.020432736724615097\n","Batch 280, Loss: 0.0048972186632454395\n","Batch 290, Loss: 0.0326620489358902\n","Batch 300, Loss: 0.03029109723865986\n","Batch 310, Loss: 0.13425053656101227\n","Batch 320, Loss: 0.05464218929409981\n","Batch 330, Loss: 0.007169113494455814\n","Batch 340, Loss: 0.015614926815032959\n","Batch 350, Loss: 0.026282580569386482\n","Batch 360, Loss: 0.0026085288263857365\n","Batch 370, Loss: 0.0009586884989403188\n","Batch 380, Loss: 0.04685789719223976\n","Batch 390, Loss: 0.020231928676366806\n","Batch 400, Loss: 0.0333697535097599\n","Batch 410, Loss: 0.0026235701516270638\n","Batch 420, Loss: 0.03228536993265152\n","Batch 430, Loss: 0.058713823556900024\n","Batch 440, Loss: 0.013008149340748787\n","Batch 450, Loss: 0.003106278134509921\n","Batch 460, Loss: 0.022407805547118187\n","Batch 470, Loss: 0.12429837137460709\n","Batch 480, Loss: 0.05781067535281181\n","Batch 490, Loss: 0.022447684779763222\n","Batch 500, Loss: 0.033864978700876236\n","Batch 510, Loss: 0.01213173195719719\n","Batch 520, Loss: 0.17507587373256683\n","Batch 530, Loss: 0.010326994583010674\n","Batch 540, Loss: 0.06882288306951523\n","Batch 550, Loss: 0.04305722564458847\n","Batch 560, Loss: 0.025769632309675217\n","Batch 570, Loss: 0.012683686800301075\n","Batch 580, Loss: 0.013791597448289394\n","Batch 590, Loss: 0.01984700746834278\n","Batch 600, Loss: 0.014284451492130756\n","Batch 610, Loss: 0.01598764769732952\n","Batch 620, Loss: 0.0058645145036280155\n","Batch 630, Loss: 0.03751727566123009\n","Batch 640, Loss: 0.006090100854635239\n","Batch 650, Loss: 0.021943653002381325\n","Batch 660, Loss: 0.01995362900197506\n","Batch 670, Loss: 0.08604473620653152\n","Batch 680, Loss: 0.08680128306150436\n","Batch 690, Loss: 0.02447977103292942\n","Batch 700, Loss: 0.047514330595731735\n","Batch 710, Loss: 0.1102936789393425\n","Batch 720, Loss: 0.04669098183512688\n","Batch 730, Loss: 0.022228481248021126\n","Batch 740, Loss: 0.05902353674173355\n","Batch 750, Loss: 0.04278481379151344\n","Batch 760, Loss: 0.11319516599178314\n","Batch 770, Loss: 0.008786891587078571\n","Batch 780, Loss: 0.011203748174011707\n","Batch 790, Loss: 0.007691150065511465\n","Batch 800, Loss: 0.007944172248244286\n","Batch 810, Loss: 0.01923324353992939\n","Batch 820, Loss: 0.014829947613179684\n","Batch 830, Loss: 0.02228548750281334\n","Batch 840, Loss: 0.009469320066273212\n","Batch 850, Loss: 0.016472069546580315\n","Batch 860, Loss: 0.0003376945969648659\n","Batch 870, Loss: 0.13629521429538727\n","Batch 880, Loss: 0.018980395048856735\n","Batch 890, Loss: 0.12335282564163208\n","Batch 900, Loss: 0.043821025639772415\n","Batch 910, Loss: 0.062289491295814514\n","Batch 920, Loss: 0.017281850799918175\n","Batch 930, Loss: 0.014377052895724773\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 0.869985 \n","\n","--------------------------------------------------\n","Epoch 77/100\n","Batch 0, Loss: 0.006304597482085228\n","Batch 10, Loss: 0.019118349999189377\n","Batch 20, Loss: 0.05449208617210388\n","Batch 30, Loss: 0.004145386628806591\n","Batch 40, Loss: 0.04180985316634178\n","Batch 50, Loss: 0.02439272031188011\n","Batch 60, Loss: 0.02077127993106842\n","Batch 70, Loss: 0.02817247062921524\n","Batch 80, Loss: 0.0326492041349411\n","Batch 90, Loss: 0.0016894774744287133\n","Batch 100, Loss: 0.019361024722456932\n","Batch 110, Loss: 0.007967684417963028\n","Batch 120, Loss: 0.023533686995506287\n","Batch 130, Loss: 0.005425879266113043\n","Batch 140, Loss: 0.0031296301167458296\n","Batch 150, Loss: 0.010476497001945972\n","Batch 160, Loss: 0.027629978954792023\n","Batch 170, Loss: 0.001581012737005949\n","Batch 180, Loss: 0.02181156352162361\n","Batch 190, Loss: 0.017803896218538284\n","Batch 200, Loss: 0.002483448712155223\n","Batch 210, Loss: 0.01598537340760231\n","Batch 220, Loss: 0.1670464277267456\n","Batch 230, Loss: 0.029777778312563896\n","Batch 240, Loss: 0.14205749332904816\n","Batch 250, Loss: 0.012702282518148422\n","Batch 260, Loss: 0.062154024839401245\n","Batch 270, Loss: 0.0871533676981926\n","Batch 280, Loss: 0.01087797898799181\n","Batch 290, Loss: 0.05584387853741646\n","Batch 300, Loss: 0.03172941878437996\n","Batch 310, Loss: 0.029851175844669342\n","Batch 320, Loss: 0.010317439213395119\n","Batch 330, Loss: 0.01713235303759575\n","Batch 340, Loss: 0.05328606441617012\n","Batch 350, Loss: 0.06959916651248932\n","Batch 360, Loss: 0.043358851224184036\n","Batch 370, Loss: 0.06698093563318253\n","Batch 380, Loss: 0.0069620003923773766\n","Batch 390, Loss: 0.037758249789476395\n","Batch 400, Loss: 0.01397384237498045\n","Batch 410, Loss: 0.03574983403086662\n","Batch 420, Loss: 0.014016141183674335\n","Batch 430, Loss: 0.13363055884838104\n","Batch 440, Loss: 0.014453526586294174\n","Batch 450, Loss: 0.0021515111438930035\n","Batch 460, Loss: 0.0821608379483223\n","Batch 470, Loss: 0.07289860397577286\n","Batch 480, Loss: 0.0046047642827034\n","Batch 490, Loss: 0.01559273712337017\n","Batch 500, Loss: 0.04294952377676964\n","Batch 510, Loss: 0.1273258924484253\n","Batch 520, Loss: 0.012575848959386349\n","Batch 530, Loss: 0.008503035642206669\n","Batch 540, Loss: 0.005866288673132658\n","Batch 550, Loss: 0.015669425949454308\n","Batch 560, Loss: 0.03832948952913284\n","Batch 570, Loss: 0.030737677589058876\n","Batch 580, Loss: 0.016237229108810425\n","Batch 590, Loss: 0.02112705633044243\n","Batch 600, Loss: 0.2086573988199234\n","Batch 610, Loss: 0.08546963334083557\n","Batch 620, Loss: 0.017084861174225807\n","Batch 630, Loss: 0.1764313280582428\n","Batch 640, Loss: 0.005995752289891243\n","Batch 650, Loss: 0.005184716545045376\n","Batch 660, Loss: 0.0540178008377552\n","Batch 670, Loss: 0.0029823118820786476\n","Batch 680, Loss: 0.13365894556045532\n","Batch 690, Loss: 0.006227252073585987\n","Batch 700, Loss: 0.0005005584680475295\n","Batch 710, Loss: 0.0934017151594162\n","Batch 720, Loss: 0.0223543643951416\n","Batch 730, Loss: 0.04297001287341118\n","Batch 740, Loss: 0.07328782975673676\n","Batch 750, Loss: 0.03573541343212128\n","Batch 760, Loss: 0.01414943765848875\n","Batch 770, Loss: 0.04033370688557625\n","Batch 780, Loss: 0.12910610437393188\n","Batch 790, Loss: 0.10341884940862656\n","Batch 800, Loss: 0.008571585640311241\n","Batch 810, Loss: 0.14951008558273315\n","Batch 820, Loss: 0.07419981807470322\n","Batch 830, Loss: 0.17413955926895142\n","Batch 840, Loss: 0.0920858159661293\n","Batch 850, Loss: 0.022209608927369118\n","Batch 860, Loss: 0.1722901314496994\n","Batch 870, Loss: 0.048793330788612366\n","Batch 880, Loss: 0.0021724754478782415\n","Batch 890, Loss: 0.04382156953215599\n","Batch 900, Loss: 0.09314065426588058\n","Batch 910, Loss: 0.008339830674231052\n","Batch 920, Loss: 0.024551808834075928\n","Batch 930, Loss: 0.15515820682048798\n","Test Error: \n"," Accuracy: 89.2%, Avg loss: 0.940741 \n","\n","--------------------------------------------------\n","Epoch 78/100\n","Batch 0, Loss: 0.028425518423318863\n","Batch 10, Loss: 0.034439608454704285\n","Batch 20, Loss: 0.039257943630218506\n","Batch 30, Loss: 0.019716491922736168\n","Batch 40, Loss: 0.0041956244967877865\n","Batch 50, Loss: 0.006404948886483908\n","Batch 60, Loss: 0.007003605365753174\n","Batch 70, Loss: 0.005940908566117287\n","Batch 80, Loss: 0.004230923485010862\n","Batch 90, Loss: 0.019171547144651413\n","Batch 100, Loss: 0.02140539512038231\n","Batch 110, Loss: 0.03715413063764572\n","Batch 120, Loss: 0.0002885411086026579\n","Batch 130, Loss: 0.031736135482788086\n","Batch 140, Loss: 0.05115944892168045\n","Batch 150, Loss: 0.014036551117897034\n","Batch 160, Loss: 0.2195981740951538\n","Batch 170, Loss: 0.06430201232433319\n","Batch 180, Loss: 0.13678202033042908\n","Batch 190, Loss: 0.03016357682645321\n","Batch 200, Loss: 0.045292388647794724\n","Batch 210, Loss: 0.015689656138420105\n","Batch 220, Loss: 0.02152480185031891\n","Batch 230, Loss: 0.029943764209747314\n","Batch 240, Loss: 0.0007157083600759506\n","Batch 250, Loss: 0.007083910051733255\n","Batch 260, Loss: 0.0012143010972067714\n","Batch 270, Loss: 0.0015378757379949093\n","Batch 280, Loss: 0.05040460452437401\n","Batch 290, Loss: 0.006936611607670784\n","Batch 300, Loss: 0.02534174546599388\n","Batch 310, Loss: 0.0073036993853747845\n","Batch 320, Loss: 0.021954050287604332\n","Batch 330, Loss: 0.03776487708091736\n","Batch 340, Loss: 0.009173552505671978\n","Batch 350, Loss: 0.04423415660858154\n","Batch 360, Loss: 0.05689430609345436\n","Batch 370, Loss: 0.013637959957122803\n","Batch 380, Loss: 0.017365461215376854\n","Batch 390, Loss: 0.05132602900266647\n","Batch 400, Loss: 0.0036283263470977545\n","Batch 410, Loss: 0.012896246276795864\n","Batch 420, Loss: 0.023310765624046326\n","Batch 430, Loss: 0.005564223974943161\n","Batch 440, Loss: 0.02900141291320324\n","Batch 450, Loss: 0.013110530562698841\n","Batch 460, Loss: 0.09203438460826874\n","Batch 470, Loss: 0.13859526813030243\n","Batch 480, Loss: 0.024963511154055595\n","Batch 490, Loss: 0.10416346788406372\n","Batch 500, Loss: 0.035874828696250916\n","Batch 510, Loss: 0.05279690772294998\n","Batch 520, Loss: 0.1298653483390808\n","Batch 530, Loss: 0.023118993267416954\n","Batch 540, Loss: 0.020802687853574753\n","Batch 550, Loss: 0.07644900679588318\n","Batch 560, Loss: 0.02792259119451046\n","Batch 570, Loss: 0.0014903750270605087\n","Batch 580, Loss: 0.028404518961906433\n","Batch 590, Loss: 0.013530978932976723\n","Batch 600, Loss: 0.008176893927156925\n","Batch 610, Loss: 0.021300077438354492\n","Batch 620, Loss: 0.03800763934850693\n","Batch 630, Loss: 0.0358443558216095\n","Batch 640, Loss: 0.05719989910721779\n","Batch 650, Loss: 0.0017857017228379846\n","Batch 660, Loss: 0.006137359421700239\n","Batch 670, Loss: 0.04231657087802887\n","Batch 680, Loss: 0.016695622354745865\n","Batch 690, Loss: 0.05883157625794411\n","Batch 700, Loss: 0.06669534742832184\n","Batch 710, Loss: 0.000756717287003994\n","Batch 720, Loss: 0.05438113212585449\n","Batch 730, Loss: 0.0021851458586752415\n","Batch 740, Loss: 0.011725571006536484\n","Batch 750, Loss: 0.021086834371089935\n","Batch 760, Loss: 0.018642015755176544\n","Batch 770, Loss: 0.047294650226831436\n","Batch 780, Loss: 0.06089361384510994\n","Batch 790, Loss: 0.06841558963060379\n","Batch 800, Loss: 0.04219584912061691\n","Batch 810, Loss: 0.10310006141662598\n","Batch 820, Loss: 0.035668328404426575\n","Batch 830, Loss: 0.01646186038851738\n","Batch 840, Loss: 0.010926952585577965\n","Batch 850, Loss: 0.05128646641969681\n","Batch 860, Loss: 0.030816394835710526\n","Batch 870, Loss: 0.00836631003767252\n","Batch 880, Loss: 0.0038952124305069447\n","Batch 890, Loss: 0.09739010035991669\n","Batch 900, Loss: 0.026415672153234482\n","Batch 910, Loss: 0.0022238895762711763\n","Batch 920, Loss: 0.0015604834770783782\n","Batch 930, Loss: 0.020985644310712814\n","Test Error: \n"," Accuracy: 89.0%, Avg loss: 0.992603 \n","\n","--------------------------------------------------\n","Epoch 79/100\n","Batch 0, Loss: 0.04532121866941452\n","Batch 10, Loss: 0.07320950925350189\n","Batch 20, Loss: 0.004603806883096695\n","Batch 30, Loss: 0.07666981965303421\n","Batch 40, Loss: 0.02703746221959591\n","Batch 50, Loss: 0.010927547700703144\n","Batch 60, Loss: 0.001901772222481668\n","Batch 70, Loss: 0.07026136666536331\n","Batch 80, Loss: 0.004449683241546154\n","Batch 90, Loss: 0.014262069016695023\n","Batch 100, Loss: 0.008432602509856224\n","Batch 110, Loss: 0.06934485584497452\n","Batch 120, Loss: 0.027153266593813896\n","Batch 130, Loss: 0.05610325187444687\n","Batch 140, Loss: 0.02559056505560875\n","Batch 150, Loss: 0.016203120350837708\n","Batch 160, Loss: 0.025088293477892876\n","Batch 170, Loss: 0.003881866578012705\n","Batch 180, Loss: 0.012977544218301773\n","Batch 190, Loss: 0.014903041534125805\n","Batch 200, Loss: 0.03232898935675621\n","Batch 210, Loss: 0.03549611195921898\n","Batch 220, Loss: 0.06367560476064682\n","Batch 230, Loss: 0.044391974806785583\n","Batch 240, Loss: 0.019311681389808655\n","Batch 250, Loss: 0.014901317656040192\n","Batch 260, Loss: 0.0047682118602097034\n","Batch 270, Loss: 0.012530568987131119\n","Batch 280, Loss: 0.07148711383342743\n","Batch 290, Loss: 0.027751386165618896\n","Batch 300, Loss: 0.013227749615907669\n","Batch 310, Loss: 0.015469866804778576\n","Batch 320, Loss: 0.1340152621269226\n","Batch 330, Loss: 0.0721893310546875\n","Batch 340, Loss: 0.0013070374261587858\n","Batch 350, Loss: 0.07296446710824966\n","Batch 360, Loss: 0.06255293637514114\n","Batch 370, Loss: 0.02898474596440792\n","Batch 380, Loss: 0.001803459832444787\n","Batch 390, Loss: 0.031148705631494522\n","Batch 400, Loss: 0.059036605060100555\n","Batch 410, Loss: 0.053100455552339554\n","Batch 420, Loss: 0.061086177825927734\n","Batch 430, Loss: 0.0031546775717288256\n","Batch 440, Loss: 0.03849444165825844\n","Batch 450, Loss: 0.0031948720570653677\n","Batch 460, Loss: 0.06378418207168579\n","Batch 470, Loss: 0.061036672443151474\n","Batch 480, Loss: 0.00848916545510292\n","Batch 490, Loss: 0.04619776830077171\n","Batch 500, Loss: 0.011441991664469242\n","Batch 510, Loss: 0.09464696049690247\n","Batch 520, Loss: 0.05780871957540512\n","Batch 530, Loss: 0.09236618876457214\n","Batch 540, Loss: 0.005060517229139805\n","Batch 550, Loss: 0.0169351939111948\n","Batch 560, Loss: 0.022883543744683266\n","Batch 570, Loss: 0.06814239919185638\n","Batch 580, Loss: 0.03208489343523979\n","Batch 590, Loss: 0.029704701155424118\n","Batch 600, Loss: 0.0051602269522845745\n","Batch 610, Loss: 0.0031688413582742214\n","Batch 620, Loss: 0.06052966043353081\n","Batch 630, Loss: 0.03945379704236984\n","Batch 640, Loss: 0.05540129542350769\n","Batch 650, Loss: 0.039598867297172546\n","Batch 660, Loss: 0.062317654490470886\n","Batch 670, Loss: 0.08081146329641342\n","Batch 680, Loss: 0.023188576102256775\n","Batch 690, Loss: 0.025361118838191032\n","Batch 700, Loss: 0.027112865820527077\n","Batch 710, Loss: 0.015284464694559574\n","Batch 720, Loss: 0.05038638412952423\n","Batch 730, Loss: 0.06442714482545853\n","Batch 740, Loss: 0.03405734896659851\n","Batch 750, Loss: 0.00568737369030714\n","Batch 760, Loss: 0.1403047889471054\n","Batch 770, Loss: 0.014844654127955437\n","Batch 780, Loss: 0.008048202842473984\n","Batch 790, Loss: 0.012145613320171833\n","Batch 800, Loss: 0.07664688676595688\n","Batch 810, Loss: 0.06263838708400726\n","Batch 820, Loss: 0.023027461022138596\n","Batch 830, Loss: 0.08796808123588562\n","Batch 840, Loss: 0.05336476117372513\n","Batch 850, Loss: 0.03427198529243469\n","Batch 860, Loss: 0.0431576631963253\n","Batch 870, Loss: 0.06689093261957169\n","Batch 880, Loss: 0.21421581506729126\n","Batch 890, Loss: 0.00978916697204113\n","Batch 900, Loss: 0.010997549630701542\n","Batch 910, Loss: 0.07447612285614014\n","Batch 920, Loss: 0.05268546938896179\n","Batch 930, Loss: 0.08219524472951889\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.916434 \n","\n","--------------------------------------------------\n","Epoch 80/100\n","Batch 0, Loss: 0.03796248137950897\n","Batch 10, Loss: 0.039078593254089355\n","Batch 20, Loss: 0.009139353409409523\n","Batch 30, Loss: 0.03193837031722069\n","Batch 40, Loss: 0.029919080436229706\n","Batch 50, Loss: 0.022445719689130783\n","Batch 60, Loss: 0.01598634384572506\n","Batch 70, Loss: 0.02803310751914978\n","Batch 80, Loss: 0.005079468712210655\n","Batch 90, Loss: 0.04843801632523537\n","Batch 100, Loss: 0.009458145126700401\n","Batch 110, Loss: 0.0387255996465683\n","Batch 120, Loss: 0.04765907675027847\n","Batch 130, Loss: 0.004769553896039724\n","Batch 140, Loss: 0.0003572370333131403\n","Batch 150, Loss: 0.01837710104882717\n","Batch 160, Loss: 0.016145283356308937\n","Batch 170, Loss: 0.059915490448474884\n","Batch 180, Loss: 0.031569261103868484\n","Batch 190, Loss: 0.01508285105228424\n","Batch 200, Loss: 0.0038455165922641754\n","Batch 210, Loss: 0.013711364939808846\n","Batch 220, Loss: 0.0858694538474083\n","Batch 230, Loss: 0.11034227907657623\n","Batch 240, Loss: 0.06628485023975372\n","Batch 250, Loss: 0.01576678827404976\n","Batch 260, Loss: 0.008081251755356789\n","Batch 270, Loss: 0.027669355273246765\n","Batch 280, Loss: 0.047119900584220886\n","Batch 290, Loss: 0.01323656551539898\n","Batch 300, Loss: 0.004798270296305418\n","Batch 310, Loss: 0.012258922681212425\n","Batch 320, Loss: 0.012078596279025078\n","Batch 330, Loss: 0.012421141378581524\n","Batch 340, Loss: 0.05557405948638916\n","Batch 350, Loss: 0.06686876714229584\n","Batch 360, Loss: 0.0018932310631498694\n","Batch 370, Loss: 0.013583643361926079\n","Batch 380, Loss: 0.07251071184873581\n","Batch 390, Loss: 0.5318362712860107\n","Batch 400, Loss: 0.02222728170454502\n","Batch 410, Loss: 0.0056532579474151134\n","Batch 420, Loss: 0.009140915237367153\n","Batch 430, Loss: 0.031273774802684784\n","Batch 440, Loss: 0.17401647567749023\n","Batch 450, Loss: 0.06646987050771713\n","Batch 460, Loss: 0.055644020438194275\n","Batch 470, Loss: 0.04374181106686592\n","Batch 480, Loss: 0.017942175269126892\n","Batch 490, Loss: 0.02182851731777191\n","Batch 500, Loss: 0.1132187768816948\n","Batch 510, Loss: 0.016136931255459785\n","Batch 520, Loss: 0.11462706327438354\n","Batch 530, Loss: 0.18952493369579315\n","Batch 540, Loss: 0.03534365072846413\n","Batch 550, Loss: 0.047748010605573654\n","Batch 560, Loss: 0.0119429100304842\n","Batch 570, Loss: 0.014307118952274323\n","Batch 580, Loss: 0.10848281532526016\n","Batch 590, Loss: 0.05679096654057503\n","Batch 600, Loss: 0.22356688976287842\n","Batch 610, Loss: 0.043514449149370193\n","Batch 620, Loss: 0.021909033879637718\n","Batch 630, Loss: 0.0154351107776165\n","Batch 640, Loss: 0.018810763955116272\n","Batch 650, Loss: 0.02146989107131958\n","Batch 660, Loss: 0.15334944427013397\n","Batch 670, Loss: 0.021918196231126785\n","Batch 680, Loss: 0.0937931090593338\n","Batch 690, Loss: 0.01014040969312191\n","Batch 700, Loss: 0.034631628543138504\n","Batch 710, Loss: 0.016064945608377457\n","Batch 720, Loss: 0.0370115302503109\n","Batch 730, Loss: 0.015148929320275784\n","Batch 740, Loss: 0.02365940436720848\n","Batch 750, Loss: 0.1946098953485489\n","Batch 760, Loss: 0.020001864060759544\n","Batch 770, Loss: 0.007043934427201748\n","Batch 780, Loss: 0.017020652070641518\n","Batch 790, Loss: 0.14433789253234863\n","Batch 800, Loss: 0.030801745131611824\n","Batch 810, Loss: 0.027339056134223938\n","Batch 820, Loss: 0.005249965004622936\n","Batch 830, Loss: 0.004797068424522877\n","Batch 840, Loss: 0.03447193279862404\n","Batch 850, Loss: 0.0027685121167451143\n","Batch 860, Loss: 0.030520429834723473\n","Batch 870, Loss: 0.08448752015829086\n","Batch 880, Loss: 0.022722193971276283\n","Batch 890, Loss: 0.0606859028339386\n","Batch 900, Loss: 0.0019470092374831438\n","Batch 910, Loss: 0.04123480245471001\n","Batch 920, Loss: 0.04637443646788597\n","Batch 930, Loss: 0.02277665212750435\n","Test Error: \n"," Accuracy: 89.8%, Avg loss: 0.907581 \n","\n","--------------------------------------------------\n","Epoch 81/100\n","Batch 0, Loss: 0.0014584342716261744\n","Batch 10, Loss: 0.004525345284491777\n","Batch 20, Loss: 0.01782478392124176\n","Batch 30, Loss: 0.002767666010186076\n","Batch 40, Loss: 0.08340932428836823\n","Batch 50, Loss: 0.008089845068752766\n","Batch 60, Loss: 0.0010177363874390721\n","Batch 70, Loss: 0.011506600305438042\n","Batch 80, Loss: 0.012588277459144592\n","Batch 90, Loss: 0.04457226023077965\n","Batch 100, Loss: 0.08294705301523209\n","Batch 110, Loss: 0.018922243267297745\n","Batch 120, Loss: 0.03395487740635872\n","Batch 130, Loss: 0.007914825342595577\n","Batch 140, Loss: 0.01767682284116745\n","Batch 150, Loss: 0.028060859069228172\n","Batch 160, Loss: 0.014147313311696053\n","Batch 170, Loss: 0.03904184699058533\n","Batch 180, Loss: 0.00046475802082568407\n","Batch 190, Loss: 0.012401383370161057\n","Batch 200, Loss: 0.05203801393508911\n","Batch 210, Loss: 0.01696176454424858\n","Batch 220, Loss: 0.004169325344264507\n","Batch 230, Loss: 0.00949200987815857\n","Batch 240, Loss: 0.010706585831940174\n","Batch 250, Loss: 0.001825731829740107\n","Batch 260, Loss: 0.003356780158355832\n","Batch 270, Loss: 0.002057464327663183\n","Batch 280, Loss: 0.019275501370429993\n","Batch 290, Loss: 0.02619045227766037\n","Batch 300, Loss: 0.04322117194533348\n","Batch 310, Loss: 0.04548231139779091\n","Batch 320, Loss: 0.0988679751753807\n","Batch 330, Loss: 0.042848747223615646\n","Batch 340, Loss: 0.01854807324707508\n","Batch 350, Loss: 0.012861073017120361\n","Batch 360, Loss: 0.004653955809772015\n","Batch 370, Loss: 0.02569231018424034\n","Batch 380, Loss: 0.009993314743041992\n","Batch 390, Loss: 0.02857670746743679\n","Batch 400, Loss: 0.008174383081495762\n","Batch 410, Loss: 0.00847046822309494\n","Batch 420, Loss: 0.06643865257501602\n","Batch 430, Loss: 0.008484402671456337\n","Batch 440, Loss: 0.03625355288386345\n","Batch 450, Loss: 0.007910490967333317\n","Batch 460, Loss: 0.004719206597656012\n","Batch 470, Loss: 0.01974821463227272\n","Batch 480, Loss: 0.07669687271118164\n","Batch 490, Loss: 0.053657837212085724\n","Batch 500, Loss: 0.018601521849632263\n","Batch 510, Loss: 0.010854864493012428\n","Batch 520, Loss: 0.011801522225141525\n","Batch 530, Loss: 0.041941240429878235\n","Batch 540, Loss: 0.020640114322304726\n","Batch 550, Loss: 0.027203049510717392\n","Batch 560, Loss: 0.009013843722641468\n","Batch 570, Loss: 0.0597272552549839\n","Batch 580, Loss: 0.0060104141011834145\n","Batch 590, Loss: 0.014110306277871132\n","Batch 600, Loss: 0.01567186787724495\n","Batch 610, Loss: 0.0035828014370054007\n","Batch 620, Loss: 0.05528637394309044\n","Batch 630, Loss: 0.011227128095924854\n","Batch 640, Loss: 0.02750232256948948\n","Batch 650, Loss: 0.003056657500565052\n","Batch 660, Loss: 0.10900271683931351\n","Batch 670, Loss: 0.16761258244514465\n","Batch 680, Loss: 0.00028549638227559626\n","Batch 690, Loss: 0.07988841831684113\n","Batch 700, Loss: 0.008158684708178043\n","Batch 710, Loss: 0.062105365097522736\n","Batch 720, Loss: 0.013206715695559978\n","Batch 730, Loss: 0.014834213070571423\n","Batch 740, Loss: 0.3623539209365845\n","Batch 750, Loss: 0.01146288774907589\n","Batch 760, Loss: 0.013804365880787373\n","Batch 770, Loss: 0.020695969462394714\n","Batch 780, Loss: 0.1678115278482437\n","Batch 790, Loss: 0.007663951721042395\n","Batch 800, Loss: 0.018249033018946648\n","Batch 810, Loss: 0.05905955657362938\n","Batch 820, Loss: 0.1355130821466446\n","Batch 830, Loss: 0.07311923801898956\n","Batch 840, Loss: 0.03700188174843788\n","Batch 850, Loss: 0.1297053098678589\n","Batch 860, Loss: 0.005835759453475475\n","Batch 870, Loss: 0.08211390674114227\n","Batch 880, Loss: 0.0542103610932827\n","Batch 890, Loss: 0.06673654913902283\n","Batch 900, Loss: 0.006672796793282032\n","Batch 910, Loss: 0.017222970724105835\n","Batch 920, Loss: 0.04122261703014374\n","Batch 930, Loss: 0.007261280436068773\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.932634 \n","\n","--------------------------------------------------\n","Epoch 82/100\n","Batch 0, Loss: 0.07486291974782944\n","Batch 10, Loss: 0.020138345658779144\n","Batch 20, Loss: 0.057710807770490646\n","Batch 30, Loss: 0.01407164428383112\n","Batch 40, Loss: 0.014655784703791142\n","Batch 50, Loss: 0.06541943550109863\n","Batch 60, Loss: 0.04139580950140953\n","Batch 70, Loss: 0.007094422820955515\n","Batch 80, Loss: 0.007196605205535889\n","Batch 90, Loss: 0.047763340175151825\n","Batch 100, Loss: 0.034131016582250595\n","Batch 110, Loss: 0.012107535265386105\n","Batch 120, Loss: 0.020881613716483116\n","Batch 130, Loss: 0.13125239312648773\n","Batch 140, Loss: 0.008183389902114868\n","Batch 150, Loss: 0.09405839443206787\n","Batch 160, Loss: 0.027730979025363922\n","Batch 170, Loss: 0.02106822095811367\n","Batch 180, Loss: 0.01354295015335083\n","Batch 190, Loss: 0.00735845323652029\n","Batch 200, Loss: 0.006543155759572983\n","Batch 210, Loss: 0.002554705599322915\n","Batch 220, Loss: 0.05822620913386345\n","Batch 230, Loss: 0.05987992882728577\n","Batch 240, Loss: 0.028011947870254517\n","Batch 250, Loss: 0.0042794994078576565\n","Batch 260, Loss: 0.03831106051802635\n","Batch 270, Loss: 0.0026849014684557915\n","Batch 280, Loss: 0.002926375949755311\n","Batch 290, Loss: 0.03033580631017685\n","Batch 300, Loss: 0.004137515090405941\n","Batch 310, Loss: 0.009942347183823586\n","Batch 320, Loss: 0.01948878914117813\n","Batch 330, Loss: 0.050172097980976105\n","Batch 340, Loss: 0.04596228897571564\n","Batch 350, Loss: 0.0015201696660369635\n","Batch 360, Loss: 0.0031472169794142246\n","Batch 370, Loss: 0.0021338597871363163\n","Batch 380, Loss: 0.001371067832224071\n","Batch 390, Loss: 0.08015906810760498\n","Batch 400, Loss: 0.0019170016748830676\n","Batch 410, Loss: 0.06943273544311523\n","Batch 420, Loss: 0.010565761476755142\n","Batch 430, Loss: 0.00010816050780704245\n","Batch 440, Loss: 0.09168098121881485\n","Batch 450, Loss: 0.04877244681119919\n","Batch 460, Loss: 0.008892728947103024\n","Batch 470, Loss: 0.01930743083357811\n","Batch 480, Loss: 0.011362971737980843\n","Batch 490, Loss: 0.020932434126734734\n","Batch 500, Loss: 0.04563431441783905\n","Batch 510, Loss: 0.024802053347229958\n","Batch 520, Loss: 0.010564180091023445\n","Batch 530, Loss: 0.01228614803403616\n","Batch 540, Loss: 0.08226609230041504\n","Batch 550, Loss: 0.07311166077852249\n","Batch 560, Loss: 0.06990588456392288\n","Batch 570, Loss: 0.012366401962935925\n","Batch 580, Loss: 0.006706432439386845\n","Batch 590, Loss: 0.018393779173493385\n","Batch 600, Loss: 0.04510445520281792\n","Batch 610, Loss: 0.03162667527794838\n","Batch 620, Loss: 0.014118931256234646\n","Batch 630, Loss: 0.00759189622476697\n","Batch 640, Loss: 0.0743880420923233\n","Batch 650, Loss: 0.022174397483468056\n","Batch 660, Loss: 0.08811347186565399\n","Batch 670, Loss: 0.010973743163049221\n","Batch 680, Loss: 0.007458941545337439\n","Batch 690, Loss: 0.0022058822214603424\n","Batch 700, Loss: 0.0030644794460386038\n","Batch 710, Loss: 0.0694497600197792\n","Batch 720, Loss: 0.01860373094677925\n","Batch 730, Loss: 0.00495134387165308\n","Batch 740, Loss: 0.0013435191940516233\n","Batch 750, Loss: 0.008103223517537117\n","Batch 760, Loss: 7.912884757388383e-05\n","Batch 770, Loss: 0.03050188347697258\n","Batch 780, Loss: 0.01602119952440262\n","Batch 790, Loss: 0.0002746766258496791\n","Batch 800, Loss: 0.031890541315078735\n","Batch 810, Loss: 0.014204629696905613\n","Batch 820, Loss: 0.0030774930492043495\n","Batch 830, Loss: 0.004958826117217541\n","Batch 840, Loss: 0.018922898918390274\n","Batch 850, Loss: 0.1038329228758812\n","Batch 860, Loss: 0.0007006786181591451\n","Batch 870, Loss: 0.03292457014322281\n","Batch 880, Loss: 0.003310160478577018\n","Batch 890, Loss: 0.017542488873004913\n","Batch 900, Loss: 0.0639321506023407\n","Batch 910, Loss: 0.11431834101676941\n","Batch 920, Loss: 0.10329993069171906\n","Batch 930, Loss: 0.01009927038103342\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 1.123326 \n","\n","--------------------------------------------------\n","Epoch 83/100\n","Batch 0, Loss: 0.014452752657234669\n","Batch 10, Loss: 0.19324198365211487\n","Batch 20, Loss: 0.0022926866076886654\n","Batch 30, Loss: 0.007899969816207886\n","Batch 40, Loss: 0.0271486584097147\n","Batch 50, Loss: 0.006284002214670181\n","Batch 60, Loss: 0.0001431753917131573\n","Batch 70, Loss: 0.005227322690188885\n","Batch 80, Loss: 0.006422433070838451\n","Batch 90, Loss: 0.021959299221634865\n","Batch 100, Loss: 0.014073911122977734\n","Batch 110, Loss: 0.004494999535381794\n","Batch 120, Loss: 0.024690009653568268\n","Batch 130, Loss: 0.006378809921443462\n","Batch 140, Loss: 0.022040164098143578\n","Batch 150, Loss: 0.0010291686048731208\n","Batch 160, Loss: 0.0032451823353767395\n","Batch 170, Loss: 0.012822376564145088\n","Batch 180, Loss: 0.021997544914484024\n","Batch 190, Loss: 0.0038898836355656385\n","Batch 200, Loss: 0.014950874261558056\n","Batch 210, Loss: 0.021373528987169266\n","Batch 220, Loss: 0.044475018978118896\n","Batch 230, Loss: 0.030237819999456406\n","Batch 240, Loss: 0.00962687749415636\n","Batch 250, Loss: 0.002048267750069499\n","Batch 260, Loss: 0.0006068092188797891\n","Batch 270, Loss: 0.0202251598238945\n","Batch 280, Loss: 0.012279967777431011\n","Batch 290, Loss: 0.04986002668738365\n","Batch 300, Loss: 0.0038790786638855934\n","Batch 310, Loss: 0.022273804992437363\n","Batch 320, Loss: 0.029546016827225685\n","Batch 330, Loss: 0.014763752929866314\n","Batch 340, Loss: 0.008871793746948242\n","Batch 350, Loss: 0.10683728754520416\n","Batch 360, Loss: 0.004329435992985964\n","Batch 370, Loss: 0.03184736147522926\n","Batch 380, Loss: 0.009711336344480515\n","Batch 390, Loss: 0.008530866354703903\n","Batch 400, Loss: 0.003955961670726538\n","Batch 410, Loss: 0.031247051432728767\n","Batch 420, Loss: 0.008174421265721321\n","Batch 430, Loss: 0.0005800531944260001\n","Batch 440, Loss: 0.036180995404720306\n","Batch 450, Loss: 0.03744581341743469\n","Batch 460, Loss: 0.010403510183095932\n","Batch 470, Loss: 0.044109199196100235\n","Batch 480, Loss: 0.07294995337724686\n","Batch 490, Loss: 0.006670852191746235\n","Batch 500, Loss: 0.004832422826439142\n","Batch 510, Loss: 0.007081423886120319\n","Batch 520, Loss: 0.08404061198234558\n","Batch 530, Loss: 0.09383039176464081\n","Batch 540, Loss: 0.1467224508523941\n","Batch 550, Loss: 0.01365428976714611\n","Batch 560, Loss: 0.021832337602972984\n","Batch 570, Loss: 0.15787151455879211\n","Batch 580, Loss: 0.017647456377744675\n","Batch 590, Loss: 0.03622884303331375\n","Batch 600, Loss: 0.005748047027736902\n","Batch 610, Loss: 0.009208697825670242\n","Batch 620, Loss: 0.03867729380726814\n","Batch 630, Loss: 0.06346964091062546\n","Batch 640, Loss: 0.10049334168434143\n","Batch 650, Loss: 0.06871416419744492\n","Batch 660, Loss: 0.009113541804254055\n","Batch 670, Loss: 0.040820393711328506\n","Batch 680, Loss: 0.0033781169913709164\n","Batch 690, Loss: 0.007419205270707607\n","Batch 700, Loss: 0.025272909551858902\n","Batch 710, Loss: 0.029521731659770012\n","Batch 720, Loss: 0.02779749222099781\n","Batch 730, Loss: 0.031181715428829193\n","Batch 740, Loss: 0.031222812831401825\n","Batch 750, Loss: 0.026045242324471474\n","Batch 760, Loss: 0.030344903469085693\n","Batch 770, Loss: 0.0033321017399430275\n","Batch 780, Loss: 0.09652129560709\n","Batch 790, Loss: 0.0017850259318947792\n","Batch 800, Loss: 0.03083665855228901\n","Batch 810, Loss: 0.023471983149647713\n","Batch 820, Loss: 0.006356402765959501\n","Batch 830, Loss: 0.003092667320743203\n","Batch 840, Loss: 0.07242625951766968\n","Batch 850, Loss: 0.06588155031204224\n","Batch 860, Loss: 0.004967626184225082\n","Batch 870, Loss: 0.021049227565526962\n","Batch 880, Loss: 0.0010378658771514893\n","Batch 890, Loss: 0.03205912932753563\n","Batch 900, Loss: 0.03250821679830551\n","Batch 910, Loss: 0.028471700847148895\n","Batch 920, Loss: 0.02596272900700569\n","Batch 930, Loss: 0.01805240660905838\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.984264 \n","\n","--------------------------------------------------\n","Epoch 84/100\n","Batch 0, Loss: 0.1783515214920044\n","Batch 10, Loss: 0.07460140436887741\n","Batch 20, Loss: 0.04054274037480354\n","Batch 30, Loss: 0.0862559974193573\n","Batch 40, Loss: 0.003748818300664425\n","Batch 50, Loss: 0.26203325390815735\n","Batch 60, Loss: 0.1783781200647354\n","Batch 70, Loss: 0.05607675015926361\n","Batch 80, Loss: 0.04749990999698639\n","Batch 90, Loss: 0.007698148023337126\n","Batch 100, Loss: 0.014623451046645641\n","Batch 110, Loss: 0.1278051733970642\n","Batch 120, Loss: 0.06351833790540695\n","Batch 130, Loss: 0.14018234610557556\n","Batch 140, Loss: 0.02987554855644703\n","Batch 150, Loss: 0.04744544252753258\n","Batch 160, Loss: 0.045345552265644073\n","Batch 170, Loss: 0.009421849623322487\n","Batch 180, Loss: 0.02512333355844021\n","Batch 190, Loss: 0.10269369930028915\n","Batch 200, Loss: 0.20551975071430206\n","Batch 210, Loss: 0.062214359641075134\n","Batch 220, Loss: 0.06946828961372375\n","Batch 230, Loss: 0.016511699184775352\n","Batch 240, Loss: 0.007318515796214342\n","Batch 250, Loss: 0.13708119094371796\n","Batch 260, Loss: 0.019808072596788406\n","Batch 270, Loss: 0.06369064003229141\n","Batch 280, Loss: 0.1617121398448944\n","Batch 290, Loss: 0.002936814446002245\n","Batch 300, Loss: 0.026217611506581306\n","Batch 310, Loss: 0.04319029301404953\n","Batch 320, Loss: 0.06925928592681885\n","Batch 330, Loss: 0.00973590463399887\n","Batch 340, Loss: 0.027352958917617798\n","Batch 350, Loss: 0.12288869917392731\n","Batch 360, Loss: 0.014001688919961452\n","Batch 370, Loss: 0.0038943560793995857\n","Batch 380, Loss: 0.008111205883324146\n","Batch 390, Loss: 0.05091922730207443\n","Batch 400, Loss: 0.09737490117549896\n","Batch 410, Loss: 0.006038465537130833\n","Batch 420, Loss: 0.036360275000333786\n","Batch 430, Loss: 0.003675139509141445\n","Batch 440, Loss: 0.01643243245780468\n","Batch 450, Loss: 0.003348442493006587\n","Batch 460, Loss: 0.01860625110566616\n","Batch 470, Loss: 0.029863152652978897\n","Batch 480, Loss: 0.027443397790193558\n","Batch 490, Loss: 0.0014468578156083822\n","Batch 500, Loss: 0.006718908436596394\n","Batch 510, Loss: 0.009439097717404366\n","Batch 520, Loss: 0.01476769708096981\n","Batch 530, Loss: 0.06525138020515442\n","Batch 540, Loss: 0.0259782113134861\n","Batch 550, Loss: 0.008614907041192055\n","Batch 560, Loss: 0.08555437624454498\n","Batch 570, Loss: 0.07527603209018707\n","Batch 580, Loss: 0.04788433015346527\n","Batch 590, Loss: 0.03562193363904953\n","Batch 600, Loss: 0.012990974821150303\n","Batch 610, Loss: 0.038877323269844055\n","Batch 620, Loss: 0.031572189182043076\n","Batch 630, Loss: 0.05085545405745506\n","Batch 640, Loss: 0.007053593173623085\n","Batch 650, Loss: 0.0020629463251680136\n","Batch 660, Loss: 0.03983369469642639\n","Batch 670, Loss: 0.002466450911015272\n","Batch 680, Loss: 0.07768957316875458\n","Batch 690, Loss: 0.01982497051358223\n","Batch 700, Loss: 0.004230920225381851\n","Batch 710, Loss: 0.014178987592458725\n","Batch 720, Loss: 0.02040867693722248\n","Batch 730, Loss: 0.031365226954221725\n","Batch 740, Loss: 0.018372004851698875\n","Batch 750, Loss: 0.002825362840667367\n","Batch 760, Loss: 0.07719598710536957\n","Batch 770, Loss: 0.026007818058133125\n","Batch 780, Loss: 0.026708094403147697\n","Batch 790, Loss: 0.026798537001013756\n","Batch 800, Loss: 0.04497716575860977\n","Batch 810, Loss: 0.04031819850206375\n","Batch 820, Loss: 0.030450882390141487\n","Batch 830, Loss: 0.02053036168217659\n","Batch 840, Loss: 0.0217690858989954\n","Batch 850, Loss: 0.010698635131120682\n","Batch 860, Loss: 0.016902893781661987\n","Batch 870, Loss: 0.01988408900797367\n","Batch 880, Loss: 0.08877581357955933\n","Batch 890, Loss: 0.012497403658926487\n","Batch 900, Loss: 0.01611541025340557\n","Batch 910, Loss: 0.03922009468078613\n","Batch 920, Loss: 0.006174732930958271\n","Batch 930, Loss: 0.06559203565120697\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 1.062535 \n","\n","--------------------------------------------------\n","Epoch 85/100\n","Batch 0, Loss: 0.00032779903267510235\n","Batch 10, Loss: 0.008258858695626259\n","Batch 20, Loss: 0.04705118387937546\n","Batch 30, Loss: 0.0041769398376345634\n","Batch 40, Loss: 0.058836277574300766\n","Batch 50, Loss: 0.03250890597701073\n","Batch 60, Loss: 0.0079538244754076\n","Batch 70, Loss: 0.0009080942254513502\n","Batch 80, Loss: 0.0013501886278390884\n","Batch 90, Loss: 0.035946428775787354\n","Batch 100, Loss: 0.1320296823978424\n","Batch 110, Loss: 0.002182142809033394\n","Batch 120, Loss: 0.0817466452717781\n","Batch 130, Loss: 0.13197189569473267\n","Batch 140, Loss: 0.006539376452565193\n","Batch 150, Loss: 0.23105667531490326\n","Batch 160, Loss: 0.029746878892183304\n","Batch 170, Loss: 0.02932905964553356\n","Batch 180, Loss: 0.01067558117210865\n","Batch 190, Loss: 0.02331731468439102\n","Batch 200, Loss: 0.04859606549143791\n","Batch 210, Loss: 0.045015282928943634\n","Batch 220, Loss: 0.003994555212557316\n","Batch 230, Loss: 0.008338039740920067\n","Batch 240, Loss: 0.007009818218648434\n","Batch 250, Loss: 0.033402711153030396\n","Batch 260, Loss: 0.007952406071126461\n","Batch 270, Loss: 0.01252143643796444\n","Batch 280, Loss: 0.006915845442563295\n","Batch 290, Loss: 0.01610110141336918\n","Batch 300, Loss: 0.03262927755713463\n","Batch 310, Loss: 0.02677612565457821\n","Batch 320, Loss: 0.0039021698758006096\n","Batch 330, Loss: 0.16813090443611145\n","Batch 340, Loss: 0.031815528869628906\n","Batch 350, Loss: 0.01588071882724762\n","Batch 360, Loss: 0.00878418143838644\n","Batch 370, Loss: 0.0021553444676101208\n","Batch 380, Loss: 0.009543977677822113\n","Batch 390, Loss: 0.0291555505245924\n","Batch 400, Loss: 0.09577056765556335\n","Batch 410, Loss: 0.03055565059185028\n","Batch 420, Loss: 0.0065569388680160046\n","Batch 430, Loss: 0.0021840264089405537\n","Batch 440, Loss: 0.07597493380308151\n","Batch 450, Loss: 0.005437110085040331\n","Batch 460, Loss: 0.003287037368863821\n","Batch 470, Loss: 0.02867000363767147\n","Batch 480, Loss: 0.012285897508263588\n","Batch 490, Loss: 0.04852345213294029\n","Batch 500, Loss: 0.05638612434267998\n","Batch 510, Loss: 0.08408785611391068\n","Batch 520, Loss: 0.05567241832613945\n","Batch 530, Loss: 0.14443781971931458\n","Batch 540, Loss: 0.05177514627575874\n","Batch 550, Loss: 0.046044450253248215\n","Batch 560, Loss: 0.09044903516769409\n","Batch 570, Loss: 0.17024821043014526\n","Batch 580, Loss: 0.031183652579784393\n","Batch 590, Loss: 0.030407842248678207\n","Batch 600, Loss: 0.026477202773094177\n","Batch 610, Loss: 0.02567807212471962\n","Batch 620, Loss: 0.16574501991271973\n","Batch 630, Loss: 0.021298887208104134\n","Batch 640, Loss: 0.019027436152100563\n","Batch 650, Loss: 0.008027639240026474\n","Batch 660, Loss: 0.056312575936317444\n","Batch 670, Loss: 0.010903294198215008\n","Batch 680, Loss: 0.0016091063152998686\n","Batch 690, Loss: 0.01719249226152897\n","Batch 700, Loss: 0.0015865336172282696\n","Batch 710, Loss: 0.014858326874673367\n","Batch 720, Loss: 0.004132760688662529\n","Batch 730, Loss: 0.00705890916287899\n","Batch 740, Loss: 0.006700546480715275\n","Batch 750, Loss: 0.008782224729657173\n","Batch 760, Loss: 0.008138386532664299\n","Batch 770, Loss: 0.007027456536889076\n","Batch 780, Loss: 0.03059719316661358\n","Batch 790, Loss: 0.09862913191318512\n","Batch 800, Loss: 0.007964862510561943\n","Batch 810, Loss: 0.011478148400783539\n","Batch 820, Loss: 0.0010791048407554626\n","Batch 830, Loss: 0.03641685098409653\n","Batch 840, Loss: 0.0771905854344368\n","Batch 850, Loss: 0.007051186636090279\n","Batch 860, Loss: 0.032876644283533096\n","Batch 870, Loss: 0.01796364225447178\n","Batch 880, Loss: 0.01748337410390377\n","Batch 890, Loss: 0.049512509256601334\n","Batch 900, Loss: 0.0808948427438736\n","Batch 910, Loss: 0.0036758766509592533\n","Batch 920, Loss: 0.030707024037837982\n","Batch 930, Loss: 0.010086140595376492\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 0.962748 \n","\n","--------------------------------------------------\n","Epoch 86/100\n","Batch 0, Loss: 0.0373559333384037\n","Batch 10, Loss: 0.019463667646050453\n","Batch 20, Loss: 0.034313611686229706\n","Batch 30, Loss: 0.13660551607608795\n","Batch 40, Loss: 0.017709048464894295\n","Batch 50, Loss: 0.0775904431939125\n","Batch 60, Loss: 0.06077272817492485\n","Batch 70, Loss: 0.006575156003236771\n","Batch 80, Loss: 0.011508231982588768\n","Batch 90, Loss: 0.02480652555823326\n","Batch 100, Loss: 0.028722040355205536\n","Batch 110, Loss: 0.05303981900215149\n","Batch 120, Loss: 0.03035721182823181\n","Batch 130, Loss: 0.015316546894609928\n","Batch 140, Loss: 0.0056689223274588585\n","Batch 150, Loss: 0.004412513691931963\n","Batch 160, Loss: 0.005672766361385584\n","Batch 170, Loss: 0.0047721560113132\n","Batch 180, Loss: 0.004879281856119633\n","Batch 190, Loss: 0.015579624101519585\n","Batch 200, Loss: 0.09508627653121948\n","Batch 210, Loss: 0.06635111570358276\n","Batch 220, Loss: 0.02228366956114769\n","Batch 230, Loss: 0.0755988210439682\n","Batch 240, Loss: 0.13988755643367767\n","Batch 250, Loss: 0.02054932340979576\n","Batch 260, Loss: 0.0007820978062227368\n","Batch 270, Loss: 0.011691929772496223\n","Batch 280, Loss: 0.11659032106399536\n","Batch 290, Loss: 0.0008103758445940912\n","Batch 300, Loss: 0.02156677469611168\n","Batch 310, Loss: 0.02165801450610161\n","Batch 320, Loss: 0.11894940584897995\n","Batch 330, Loss: 0.16671741008758545\n","Batch 340, Loss: 0.02185923233628273\n","Batch 350, Loss: 0.02989756502211094\n","Batch 360, Loss: 0.00696973642334342\n","Batch 370, Loss: 0.012577898800373077\n","Batch 380, Loss: 0.04043285921216011\n","Batch 390, Loss: 0.004601644817739725\n","Batch 400, Loss: 0.05078985542058945\n","Batch 410, Loss: 0.04764572158455849\n","Batch 420, Loss: 0.0032347391825169325\n","Batch 430, Loss: 0.04729513078927994\n","Batch 440, Loss: 0.023209480568766594\n","Batch 450, Loss: 0.03170788288116455\n","Batch 460, Loss: 0.008798426948487759\n","Batch 470, Loss: 0.010512049309909344\n","Batch 480, Loss: 0.028453892096877098\n","Batch 490, Loss: 0.018788456916809082\n","Batch 500, Loss: 0.015310167334973812\n","Batch 510, Loss: 0.08173009008169174\n","Batch 520, Loss: 0.2271544188261032\n","Batch 530, Loss: 0.021064994856715202\n","Batch 540, Loss: 0.00499197281897068\n","Batch 550, Loss: 0.013499414548277855\n","Batch 560, Loss: 0.040430501103401184\n","Batch 570, Loss: 0.004279131069779396\n","Batch 580, Loss: 0.054869312793016434\n","Batch 590, Loss: 0.03307148814201355\n","Batch 600, Loss: 0.1437421590089798\n","Batch 610, Loss: 0.03408583253622055\n","Batch 620, Loss: 0.04013708233833313\n","Batch 630, Loss: 0.04172609746456146\n","Batch 640, Loss: 0.1250775158405304\n","Batch 650, Loss: 0.07315745949745178\n","Batch 660, Loss: 0.026019010692834854\n","Batch 670, Loss: 0.05571029707789421\n","Batch 680, Loss: 0.037331629544496536\n","Batch 690, Loss: 0.053593095391988754\n","Batch 700, Loss: 0.00384140876121819\n","Batch 710, Loss: 0.040081799030303955\n","Batch 720, Loss: 0.23527798056602478\n","Batch 730, Loss: 0.03744804114103317\n","Batch 740, Loss: 0.00826356839388609\n","Batch 750, Loss: 0.0009627569233998656\n","Batch 760, Loss: 0.06828275322914124\n","Batch 770, Loss: 0.016284508630633354\n","Batch 780, Loss: 0.003409535391256213\n","Batch 790, Loss: 0.007068713195621967\n","Batch 800, Loss: 0.032076865434646606\n","Batch 810, Loss: 0.012318184599280357\n","Batch 820, Loss: 0.022174710407853127\n","Batch 830, Loss: 0.0664634183049202\n","Batch 840, Loss: 0.025336258113384247\n","Batch 850, Loss: 0.05529389902949333\n","Batch 860, Loss: 0.0044096605852246284\n","Batch 870, Loss: 0.046526409685611725\n","Batch 880, Loss: 0.021153686568140984\n","Batch 890, Loss: 0.03314535319805145\n","Batch 900, Loss: 0.003453104756772518\n","Batch 910, Loss: 0.06447643786668777\n","Batch 920, Loss: 0.004634002223610878\n","Batch 930, Loss: 0.03818293288350105\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.975198 \n","\n","--------------------------------------------------\n","Epoch 87/100\n","Batch 0, Loss: 0.04357372596859932\n","Batch 10, Loss: 0.028239818289875984\n","Batch 20, Loss: 0.022867774590849876\n","Batch 30, Loss: 0.0038435119204223156\n","Batch 40, Loss: 0.0923529639840126\n","Batch 50, Loss: 0.0135079650208354\n","Batch 60, Loss: 0.01678912155330181\n","Batch 70, Loss: 0.016847938299179077\n","Batch 80, Loss: 0.031268563121557236\n","Batch 90, Loss: 0.07545746117830276\n","Batch 100, Loss: 0.019888531416654587\n","Batch 110, Loss: 0.01813490130007267\n","Batch 120, Loss: 0.0038799636531621218\n","Batch 130, Loss: 0.0034323493018746376\n","Batch 140, Loss: 0.007913153618574142\n","Batch 150, Loss: 0.002247805707156658\n","Batch 160, Loss: 0.0055228970013558865\n","Batch 170, Loss: 0.03233305737376213\n","Batch 180, Loss: 0.013027805835008621\n","Batch 190, Loss: 0.011312424205243587\n","Batch 200, Loss: 0.0014062478439882398\n","Batch 210, Loss: 0.0004887856193818152\n","Batch 220, Loss: 0.006231496576219797\n","Batch 230, Loss: 0.006734163034707308\n","Batch 240, Loss: 0.011578118428587914\n","Batch 250, Loss: 0.00015777154476381838\n","Batch 260, Loss: 0.0650327131152153\n","Batch 270, Loss: 0.0005136135150678456\n","Batch 280, Loss: 0.004183459561318159\n","Batch 290, Loss: 0.01473922561854124\n","Batch 300, Loss: 0.013780880719423294\n","Batch 310, Loss: 0.017256170511245728\n","Batch 320, Loss: 0.03681233525276184\n","Batch 330, Loss: 0.3839169442653656\n","Batch 340, Loss: 0.007060378324240446\n","Batch 350, Loss: 0.0054656947031617165\n","Batch 360, Loss: 0.2968812882900238\n","Batch 370, Loss: 0.04425574094057083\n","Batch 380, Loss: 0.07443450391292572\n","Batch 390, Loss: 0.03251498565077782\n","Batch 400, Loss: 0.13028128445148468\n","Batch 410, Loss: 0.13349811732769012\n","Batch 420, Loss: 0.08268836885690689\n","Batch 430, Loss: 0.03253057971596718\n","Batch 440, Loss: 0.006946822162717581\n","Batch 450, Loss: 0.03471627086400986\n","Batch 460, Loss: 0.09783844649791718\n","Batch 470, Loss: 0.05560977756977081\n","Batch 480, Loss: 0.027435140684247017\n","Batch 490, Loss: 0.006339455023407936\n","Batch 500, Loss: 0.008248645812273026\n","Batch 510, Loss: 0.0012443431187421083\n","Batch 520, Loss: 0.027905866503715515\n","Batch 530, Loss: 0.003172852098941803\n","Batch 540, Loss: 0.01721995137631893\n","Batch 550, Loss: 0.26505330204963684\n","Batch 560, Loss: 0.005969403311610222\n","Batch 570, Loss: 0.2607761025428772\n","Batch 580, Loss: 0.0017538325628265738\n","Batch 590, Loss: 0.06878761202096939\n","Batch 600, Loss: 0.013647057116031647\n","Batch 610, Loss: 0.0008803451200947165\n","Batch 620, Loss: 0.005859628319740295\n","Batch 630, Loss: 0.020297881215810776\n","Batch 640, Loss: 0.061643969267606735\n","Batch 650, Loss: 0.01999075710773468\n","Batch 660, Loss: 0.023534083738923073\n","Batch 670, Loss: 0.09119368344545364\n","Batch 680, Loss: 0.02513175830245018\n","Batch 690, Loss: 0.0530182421207428\n","Batch 700, Loss: 0.0008816908812150359\n","Batch 710, Loss: 0.006542217917740345\n","Batch 720, Loss: 0.025698702782392502\n","Batch 730, Loss: 0.0011778046609833837\n","Batch 740, Loss: 0.0008429755107499659\n","Batch 750, Loss: 0.01335669681429863\n","Batch 760, Loss: 0.07061077654361725\n","Batch 770, Loss: 0.00015553006960544735\n","Batch 780, Loss: 0.13020531833171844\n","Batch 790, Loss: 0.0058117154985666275\n","Batch 800, Loss: 0.03758849948644638\n","Batch 810, Loss: 0.000941342965234071\n","Batch 820, Loss: 0.17213357985019684\n","Batch 830, Loss: 0.0526030994951725\n","Batch 840, Loss: 0.012588469311594963\n","Batch 850, Loss: 0.014825480990111828\n","Batch 860, Loss: 0.011905244551599026\n","Batch 870, Loss: 0.03950217366218567\n","Batch 880, Loss: 0.03224695101380348\n","Batch 890, Loss: 0.021209586411714554\n","Batch 900, Loss: 0.014630082994699478\n","Batch 910, Loss: 0.05304839462041855\n","Batch 920, Loss: 0.00540111493319273\n","Batch 930, Loss: 0.05344865098595619\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 0.989111 \n","\n","--------------------------------------------------\n","Epoch 88/100\n","Batch 0, Loss: 0.018691053614020348\n","Batch 10, Loss: 0.014057441614568233\n","Batch 20, Loss: 0.0211542546749115\n","Batch 30, Loss: 0.010946892201900482\n","Batch 40, Loss: 0.0217422004789114\n","Batch 50, Loss: 0.014050142839550972\n","Batch 60, Loss: 0.0010335033293813467\n","Batch 70, Loss: 0.0026626265607774258\n","Batch 80, Loss: 0.007487848401069641\n","Batch 90, Loss: 0.012524169869720936\n","Batch 100, Loss: 0.052284203469753265\n","Batch 110, Loss: 0.004899434745311737\n","Batch 120, Loss: 0.0629454031586647\n","Batch 130, Loss: 0.00399855338037014\n","Batch 140, Loss: 0.0011645290069282055\n","Batch 150, Loss: 0.02695184014737606\n","Batch 160, Loss: 0.14219211041927338\n","Batch 170, Loss: 0.11167165637016296\n","Batch 180, Loss: 0.007856582291424274\n","Batch 190, Loss: 0.0015261337393894792\n","Batch 200, Loss: 0.005349579732865095\n","Batch 210, Loss: 0.08319159597158432\n","Batch 220, Loss: 0.02257392928004265\n","Batch 230, Loss: 0.11452376842498779\n","Batch 240, Loss: 0.0467214360833168\n","Batch 250, Loss: 0.0186705831438303\n","Batch 260, Loss: 0.024373505264520645\n","Batch 270, Loss: 0.0020609041675925255\n","Batch 280, Loss: 0.02929331548511982\n","Batch 290, Loss: 0.00796663947403431\n","Batch 300, Loss: 0.0701838955283165\n","Batch 310, Loss: 0.01915322057902813\n","Batch 320, Loss: 0.004307648167014122\n","Batch 330, Loss: 0.0010681276908144355\n","Batch 340, Loss: 0.058950018137693405\n","Batch 350, Loss: 0.059709809720516205\n","Batch 360, Loss: 0.044187095016241074\n","Batch 370, Loss: 0.03567052260041237\n","Batch 380, Loss: 0.0015398927498608828\n","Batch 390, Loss: 0.14890430867671967\n","Batch 400, Loss: 0.03547346964478493\n","Batch 410, Loss: 0.11312706023454666\n","Batch 420, Loss: 0.05378532409667969\n","Batch 430, Loss: 0.048700764775276184\n","Batch 440, Loss: 0.11883369833230972\n","Batch 450, Loss: 0.09131035953760147\n","Batch 460, Loss: 0.12265990674495697\n","Batch 470, Loss: 0.06453298032283783\n","Batch 480, Loss: 0.017612524330615997\n","Batch 490, Loss: 0.06198013201355934\n","Batch 500, Loss: 0.06548749655485153\n","Batch 510, Loss: 0.010888321325182915\n","Batch 520, Loss: 0.004691074136644602\n","Batch 530, Loss: 0.049224305897951126\n","Batch 540, Loss: 0.029579760506749153\n","Batch 550, Loss: 0.0005504603614099324\n","Batch 560, Loss: 0.03652874380350113\n","Batch 570, Loss: 0.015201606787741184\n","Batch 580, Loss: 0.002356729470193386\n","Batch 590, Loss: 0.031294502317905426\n","Batch 600, Loss: 0.09149685502052307\n","Batch 610, Loss: 0.12902730703353882\n","Batch 620, Loss: 0.017903771251440048\n","Batch 630, Loss: 0.01825721561908722\n","Batch 640, Loss: 0.1530330926179886\n","Batch 650, Loss: 0.018167871981859207\n","Batch 660, Loss: 0.049831636250019073\n","Batch 670, Loss: 0.024521593004465103\n","Batch 680, Loss: 0.2801450192928314\n","Batch 690, Loss: 0.06353051215410233\n","Batch 700, Loss: 0.015047687105834484\n","Batch 710, Loss: 0.017264926806092262\n","Batch 720, Loss: 0.05793560668826103\n","Batch 730, Loss: 0.019612349569797516\n","Batch 740, Loss: 0.0027194255962967873\n","Batch 750, Loss: 0.014866062439978123\n","Batch 760, Loss: 0.0028022611513733864\n","Batch 770, Loss: 0.039256419986486435\n","Batch 780, Loss: 0.005712499376386404\n","Batch 790, Loss: 0.009752781130373478\n","Batch 800, Loss: 0.00671797851100564\n","Batch 810, Loss: 0.056342825293540955\n","Batch 820, Loss: 0.009989677928388119\n","Batch 830, Loss: 0.0006794682703912258\n","Batch 840, Loss: 0.003889289917424321\n","Batch 850, Loss: 0.005324871279299259\n","Batch 860, Loss: 0.005067362915724516\n","Batch 870, Loss: 0.1619194895029068\n","Batch 880, Loss: 0.016309121623635292\n","Batch 890, Loss: 0.04538962244987488\n","Batch 900, Loss: 0.04314551129937172\n","Batch 910, Loss: 0.03936617076396942\n","Batch 920, Loss: 0.008105331100523472\n","Batch 930, Loss: 0.012674004770815372\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 1.051397 \n","\n","--------------------------------------------------\n","Epoch 89/100\n","Batch 0, Loss: 0.003136394778266549\n","Batch 10, Loss: 0.0170219074934721\n","Batch 20, Loss: 0.003937115892767906\n","Batch 30, Loss: 0.014599202200770378\n","Batch 40, Loss: 0.004834028892219067\n","Batch 50, Loss: 0.035709429532289505\n","Batch 60, Loss: 0.009393906220793724\n","Batch 70, Loss: 0.028445204719901085\n","Batch 80, Loss: 0.035373758524656296\n","Batch 90, Loss: 0.011863705702126026\n","Batch 100, Loss: 0.08969944715499878\n","Batch 110, Loss: 0.012601757422089577\n","Batch 120, Loss: 0.0022787125781178474\n","Batch 130, Loss: 0.01301568653434515\n","Batch 140, Loss: 0.006096566095948219\n","Batch 150, Loss: 0.0006647346308454871\n","Batch 160, Loss: 0.03846866264939308\n","Batch 170, Loss: 0.23358845710754395\n","Batch 180, Loss: 0.008206544443964958\n","Batch 190, Loss: 0.02269972488284111\n","Batch 200, Loss: 0.012790086679160595\n","Batch 210, Loss: 0.0021770906168967485\n","Batch 220, Loss: 0.00926009751856327\n","Batch 230, Loss: 0.02651224099099636\n","Batch 240, Loss: 0.022483685985207558\n","Batch 250, Loss: 0.0009031036752276123\n","Batch 260, Loss: 0.019996894523501396\n","Batch 270, Loss: 0.0010054206941276789\n","Batch 280, Loss: 0.030501196160912514\n","Batch 290, Loss: 6.167880928842351e-05\n","Batch 300, Loss: 0.036089055240154266\n","Batch 310, Loss: 0.0012256274931132793\n","Batch 320, Loss: 0.005228586494922638\n","Batch 330, Loss: 0.05468697473406792\n","Batch 340, Loss: 0.032702162861824036\n","Batch 350, Loss: 0.012784091755747795\n","Batch 360, Loss: 0.12050789594650269\n","Batch 370, Loss: 0.0035390565171837807\n","Batch 380, Loss: 0.019576076418161392\n","Batch 390, Loss: 0.012273394502699375\n","Batch 400, Loss: 0.015659969300031662\n","Batch 410, Loss: 0.2551955282688141\n","Batch 420, Loss: 0.044100187718868256\n","Batch 430, Loss: 0.0029142824932932854\n","Batch 440, Loss: 0.0023357816971838474\n","Batch 450, Loss: 0.10478934645652771\n","Batch 460, Loss: 0.02035720832645893\n","Batch 470, Loss: 0.022007152438163757\n","Batch 480, Loss: 0.04288075119256973\n","Batch 490, Loss: 0.26208874583244324\n","Batch 500, Loss: 0.07603402435779572\n","Batch 510, Loss: 0.019513525068759918\n","Batch 520, Loss: 0.01389459427446127\n","Batch 530, Loss: 0.013038788922131062\n","Batch 540, Loss: 0.018659112975001335\n","Batch 550, Loss: 0.009427797049283981\n","Batch 560, Loss: 0.013843120075762272\n","Batch 570, Loss: 0.039830148220062256\n","Batch 580, Loss: 0.02285687066614628\n","Batch 590, Loss: 0.02196270227432251\n","Batch 600, Loss: 0.0033811505418270826\n","Batch 610, Loss: 0.01269444078207016\n","Batch 620, Loss: 0.08216533064842224\n","Batch 630, Loss: 0.022391824051737785\n","Batch 640, Loss: 0.01929383911192417\n","Batch 650, Loss: 0.23195041716098785\n","Batch 660, Loss: 0.09592597186565399\n","Batch 670, Loss: 0.08738292753696442\n","Batch 680, Loss: 0.12445145100355148\n","Batch 690, Loss: 0.046888742595911026\n","Batch 700, Loss: 0.04772323742508888\n","Batch 710, Loss: 0.05673622339963913\n","Batch 720, Loss: 0.05914418026804924\n","Batch 730, Loss: 0.06994649022817612\n","Batch 740, Loss: 0.10201694816350937\n","Batch 750, Loss: 0.011413827538490295\n","Batch 760, Loss: 0.01778927445411682\n","Batch 770, Loss: 0.007240965496748686\n","Batch 780, Loss: 0.2082100510597229\n","Batch 790, Loss: 0.16979053616523743\n","Batch 800, Loss: 0.02558724582195282\n","Batch 810, Loss: 0.16268202662467957\n","Batch 820, Loss: 0.018725818023085594\n","Batch 830, Loss: 0.012181705795228481\n","Batch 840, Loss: 0.3022898733615875\n","Batch 850, Loss: 0.28487101197242737\n","Batch 860, Loss: 0.17404642701148987\n","Batch 870, Loss: 0.05608602613210678\n","Batch 880, Loss: 0.24503612518310547\n","Batch 890, Loss: 0.10645169764757156\n","Batch 900, Loss: 0.002389038447290659\n","Batch 910, Loss: 0.02161438949406147\n","Batch 920, Loss: 0.03852114453911781\n","Batch 930, Loss: 0.008763139136135578\n","Test Error: \n"," Accuracy: 88.4%, Avg loss: 1.048972 \n","\n","--------------------------------------------------\n","Epoch 90/100\n","Batch 0, Loss: 0.07911470532417297\n","Batch 10, Loss: 0.10186346620321274\n","Batch 20, Loss: 0.18068361282348633\n","Batch 30, Loss: 0.17711175978183746\n","Batch 40, Loss: 0.03756655380129814\n","Batch 50, Loss: 0.04046158120036125\n","Batch 60, Loss: 0.09820961207151413\n","Batch 70, Loss: 0.00033377937506884336\n","Batch 80, Loss: 0.005332332570105791\n","Batch 90, Loss: 0.030306169763207436\n","Batch 100, Loss: 0.03221716731786728\n","Batch 110, Loss: 0.0032717548310756683\n","Batch 120, Loss: 0.04319910332560539\n","Batch 130, Loss: 0.022797899320721626\n","Batch 140, Loss: 0.03312685340642929\n","Batch 150, Loss: 0.09126093238592148\n","Batch 160, Loss: 0.04197471961379051\n","Batch 170, Loss: 0.03235258907079697\n","Batch 180, Loss: 0.016799569129943848\n","Batch 190, Loss: 0.005435093306005001\n","Batch 200, Loss: 0.009720425121486187\n","Batch 210, Loss: 0.04571422189474106\n","Batch 220, Loss: 0.0016734151868149638\n","Batch 230, Loss: 0.10366291552782059\n","Batch 240, Loss: 0.0033147530630230904\n","Batch 250, Loss: 0.05053161829710007\n","Batch 260, Loss: 0.011229484342038631\n","Batch 270, Loss: 0.0013360558077692986\n","Batch 280, Loss: 0.006165658123791218\n","Batch 290, Loss: 0.06722451001405716\n","Batch 300, Loss: 0.04405064508318901\n","Batch 310, Loss: 0.004888330586254597\n","Batch 320, Loss: 0.023319728672504425\n","Batch 330, Loss: 0.02555229514837265\n","Batch 340, Loss: 0.002255992963910103\n","Batch 350, Loss: 0.005658145993947983\n","Batch 360, Loss: 0.0048344554379582405\n","Batch 370, Loss: 0.010062252171337605\n","Batch 380, Loss: 0.015907492488622665\n","Batch 390, Loss: 0.004668877460062504\n","Batch 400, Loss: 0.0009294491028413177\n","Batch 410, Loss: 0.01823035627603531\n","Batch 420, Loss: 0.0005913347704336047\n","Batch 430, Loss: 0.04093192517757416\n","Batch 440, Loss: 0.007171712815761566\n","Batch 450, Loss: 0.015295792371034622\n","Batch 460, Loss: 0.00741448812186718\n","Batch 470, Loss: 0.0018613669089972973\n","Batch 480, Loss: 0.1107264831662178\n","Batch 490, Loss: 0.020875364542007446\n","Batch 500, Loss: 0.025199273601174355\n","Batch 510, Loss: 0.014952754601836205\n","Batch 520, Loss: 0.01405859924852848\n","Batch 530, Loss: 0.0060312170535326\n","Batch 540, Loss: 0.015405518934130669\n","Batch 550, Loss: 0.0666443407535553\n","Batch 560, Loss: 0.0704645961523056\n","Batch 570, Loss: 0.0005590147920884192\n","Batch 580, Loss: 0.08854954689741135\n","Batch 590, Loss: 0.026392357423901558\n","Batch 600, Loss: 0.08458707481622696\n","Batch 610, Loss: 0.04092373698949814\n","Batch 620, Loss: 0.02543153613805771\n","Batch 630, Loss: 0.013021355494856834\n","Batch 640, Loss: 0.03638901934027672\n","Batch 650, Loss: 0.025286294519901276\n","Batch 660, Loss: 0.011426611803472042\n","Batch 670, Loss: 0.00547658558934927\n","Batch 680, Loss: 0.03408649563789368\n","Batch 690, Loss: 0.00029993269708938897\n","Batch 700, Loss: 0.012414474971592426\n","Batch 710, Loss: 0.06813880801200867\n","Batch 720, Loss: 0.009266364388167858\n","Batch 730, Loss: 0.10413474589586258\n","Batch 740, Loss: 0.012569177895784378\n","Batch 750, Loss: 0.004431107547134161\n","Batch 760, Loss: 0.07964057475328445\n","Batch 770, Loss: 0.06459968537092209\n","Batch 780, Loss: 0.0026642605662345886\n","Batch 790, Loss: 0.14836379885673523\n","Batch 800, Loss: 0.08906828612089157\n","Batch 810, Loss: 0.01572318561375141\n","Batch 820, Loss: 0.19454841315746307\n","Batch 830, Loss: 0.04284704849123955\n","Batch 840, Loss: 0.11644559353590012\n","Batch 850, Loss: 0.00572223961353302\n","Batch 860, Loss: 0.02606995403766632\n","Batch 870, Loss: 0.010805963538587093\n","Batch 880, Loss: 0.027316005900502205\n","Batch 890, Loss: 0.047416701912879944\n","Batch 900, Loss: 0.013639646582305431\n","Batch 910, Loss: 0.019164571538567543\n","Batch 920, Loss: 0.006910631898790598\n","Batch 930, Loss: 0.0741083025932312\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 1.094763 \n","\n","--------------------------------------------------\n","Epoch 91/100\n","Batch 0, Loss: 0.009276856668293476\n","Batch 10, Loss: 0.0002426119172014296\n","Batch 20, Loss: 0.0025655548088252544\n","Batch 30, Loss: 0.011167393065989017\n","Batch 40, Loss: 0.0012716870987787843\n","Batch 50, Loss: 0.09979311376810074\n","Batch 60, Loss: 0.0024776174686849117\n","Batch 70, Loss: 0.01959105022251606\n","Batch 80, Loss: 0.017884662374854088\n","Batch 90, Loss: 0.0060186441987752914\n","Batch 100, Loss: 0.06674733757972717\n","Batch 110, Loss: 0.02914564125239849\n","Batch 120, Loss: 0.00664939871057868\n","Batch 130, Loss: 0.05490798503160477\n","Batch 140, Loss: 0.012249168008565903\n","Batch 150, Loss: 0.0020944103598594666\n","Batch 160, Loss: 0.041131503880023956\n","Batch 170, Loss: 0.018190186470746994\n","Batch 180, Loss: 0.024261707440018654\n","Batch 190, Loss: 0.018273858353495598\n","Batch 200, Loss: 0.018381519243121147\n","Batch 210, Loss: 0.01451397780328989\n","Batch 220, Loss: 0.029924426227808\n","Batch 230, Loss: 0.0833715870976448\n","Batch 240, Loss: 0.02229253575205803\n","Batch 250, Loss: 0.008055245503783226\n","Batch 260, Loss: 0.037182822823524475\n","Batch 270, Loss: 0.0018819590331986547\n","Batch 280, Loss: 0.012544785626232624\n","Batch 290, Loss: 0.030190808698534966\n","Batch 300, Loss: 0.05384761095046997\n","Batch 310, Loss: 0.011784497648477554\n","Batch 320, Loss: 0.008064636960625648\n","Batch 330, Loss: 0.005250788293778896\n","Batch 340, Loss: 0.09049051254987717\n","Batch 350, Loss: 0.0006238550995476544\n","Batch 360, Loss: 0.019129963591694832\n","Batch 370, Loss: 0.0004651978670153767\n","Batch 380, Loss: 0.07875517010688782\n","Batch 390, Loss: 0.0062876250594854355\n","Batch 400, Loss: 0.019588761031627655\n","Batch 410, Loss: 0.0017247864743694663\n","Batch 420, Loss: 0.029342148452997208\n","Batch 430, Loss: 0.007746994029730558\n","Batch 440, Loss: 0.146182119846344\n","Batch 450, Loss: 0.029247846454381943\n","Batch 460, Loss: 0.010544304735958576\n","Batch 470, Loss: 0.030715586617588997\n","Batch 480, Loss: 0.029061736539006233\n","Batch 490, Loss: 0.013961629942059517\n","Batch 500, Loss: 0.024713940918445587\n","Batch 510, Loss: 0.06817026436328888\n","Batch 520, Loss: 0.00927563477307558\n","Batch 530, Loss: 0.1542302817106247\n","Batch 540, Loss: 0.008612179197371006\n","Batch 550, Loss: 0.0038342431653290987\n","Batch 560, Loss: 0.004517196211963892\n","Batch 570, Loss: 0.1515934318304062\n","Batch 580, Loss: 0.07270822674036026\n","Batch 590, Loss: 0.1110590398311615\n","Batch 600, Loss: 0.21496938169002533\n","Batch 610, Loss: 0.020886531099677086\n","Batch 620, Loss: 0.03736982122063637\n","Batch 630, Loss: 0.010619688779115677\n","Batch 640, Loss: 0.016378173604607582\n","Batch 650, Loss: 0.004702996928244829\n","Batch 660, Loss: 0.0036721481010317802\n","Batch 670, Loss: 0.03973381221294403\n","Batch 680, Loss: 0.006894501391798258\n","Batch 690, Loss: 0.009581850841641426\n","Batch 700, Loss: 0.001019053510390222\n","Batch 710, Loss: 0.020380262285470963\n","Batch 720, Loss: 0.02625522017478943\n","Batch 730, Loss: 0.024700304493308067\n","Batch 740, Loss: 0.009188871830701828\n","Batch 750, Loss: 0.012433800846338272\n","Batch 760, Loss: 0.011807180009782314\n","Batch 770, Loss: 0.07057598233222961\n","Batch 780, Loss: 0.06183232367038727\n","Batch 790, Loss: 0.015971245244145393\n","Batch 800, Loss: 0.005661148577928543\n","Batch 810, Loss: 0.007046828046441078\n","Batch 820, Loss: 0.012397335842251778\n","Batch 830, Loss: 0.03545286878943443\n","Batch 840, Loss: 0.08885052800178528\n","Batch 850, Loss: 0.08979665488004684\n","Batch 860, Loss: 0.0016565888654440641\n","Batch 870, Loss: 0.0537269152700901\n","Batch 880, Loss: 0.048257339745759964\n","Batch 890, Loss: 0.0020432081073522568\n","Batch 900, Loss: 0.04050874337553978\n","Batch 910, Loss: 0.01199270784854889\n","Batch 920, Loss: 0.014997363090515137\n","Batch 930, Loss: 0.002993031870573759\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 1.049138 \n","\n","--------------------------------------------------\n","Epoch 92/100\n","Batch 0, Loss: 0.0026269452646374702\n","Batch 10, Loss: 0.0016456603771075606\n","Batch 20, Loss: 0.0035401759669184685\n","Batch 30, Loss: 0.03157167136669159\n","Batch 40, Loss: 0.0007117021596059203\n","Batch 50, Loss: 0.014751805923879147\n","Batch 60, Loss: 0.005643651355057955\n","Batch 70, Loss: 0.004944531247019768\n","Batch 80, Loss: 0.019952792674303055\n","Batch 90, Loss: 0.003296233480796218\n","Batch 100, Loss: 0.008206075057387352\n","Batch 110, Loss: 0.020749224349856377\n","Batch 120, Loss: 0.017859643325209618\n","Batch 130, Loss: 0.001180135877802968\n","Batch 140, Loss: 0.009696724824607372\n","Batch 150, Loss: 0.12961407005786896\n","Batch 160, Loss: 0.036908406764268875\n","Batch 170, Loss: 0.010669277980923653\n","Batch 180, Loss: 0.023239370435476303\n","Batch 190, Loss: 0.0014800073113292456\n","Batch 200, Loss: 0.0012275164481252432\n","Batch 210, Loss: 0.0031691112089902163\n","Batch 220, Loss: 0.037958063185214996\n","Batch 230, Loss: 0.10953760147094727\n","Batch 240, Loss: 0.011347183957695961\n","Batch 250, Loss: 0.03915877640247345\n","Batch 260, Loss: 0.020751502364873886\n","Batch 270, Loss: 0.36409974098205566\n","Batch 280, Loss: 0.044992800801992416\n","Batch 290, Loss: 0.0012623554794117808\n","Batch 300, Loss: 0.006468300241976976\n","Batch 310, Loss: 0.009218030609190464\n","Batch 320, Loss: 0.015284453518688679\n","Batch 330, Loss: 0.013484753668308258\n","Batch 340, Loss: 0.05348987877368927\n","Batch 350, Loss: 0.018470928072929382\n","Batch 360, Loss: 0.0432475283741951\n","Batch 370, Loss: 0.005496296565979719\n","Batch 380, Loss: 0.04857417196035385\n","Batch 390, Loss: 0.0048377313651144505\n","Batch 400, Loss: 0.0013646803563460708\n","Batch 410, Loss: 0.06121833622455597\n","Batch 420, Loss: 0.03576689586043358\n","Batch 430, Loss: 0.057773757725954056\n","Batch 440, Loss: 0.04454715922474861\n","Batch 450, Loss: 0.017703313380479813\n","Batch 460, Loss: 0.01561411190778017\n","Batch 470, Loss: 0.00849353801459074\n","Batch 480, Loss: 0.044382255524396896\n","Batch 490, Loss: 0.02957778051495552\n","Batch 500, Loss: 0.07162817567586899\n","Batch 510, Loss: 0.07910826057195663\n","Batch 520, Loss: 0.04270121827721596\n","Batch 530, Loss: 0.025867167860269547\n","Batch 540, Loss: 0.02948392927646637\n","Batch 550, Loss: 0.11545072495937347\n","Batch 560, Loss: 0.21842250227928162\n","Batch 570, Loss: 0.05316421389579773\n","Batch 580, Loss: 0.1760675013065338\n","Batch 590, Loss: 0.007337544113397598\n","Batch 600, Loss: 0.21245698630809784\n","Batch 610, Loss: 0.006308096460998058\n","Batch 620, Loss: 0.0796155035495758\n","Batch 630, Loss: 0.037984784692525864\n","Batch 640, Loss: 0.04482599347829819\n","Batch 650, Loss: 0.019544832408428192\n","Batch 660, Loss: 0.019024193286895752\n","Batch 670, Loss: 0.009908730164170265\n","Batch 680, Loss: 0.06294890493154526\n","Batch 690, Loss: 0.09158441424369812\n","Batch 700, Loss: 0.04415762796998024\n","Batch 710, Loss: 0.014168979600071907\n","Batch 720, Loss: 0.022962462157011032\n","Batch 730, Loss: 0.016340436413884163\n","Batch 740, Loss: 0.001063621137291193\n","Batch 750, Loss: 0.0053807878866791725\n","Batch 760, Loss: 0.06280767172574997\n","Batch 770, Loss: 0.013534016907215118\n","Batch 780, Loss: 0.00704274931922555\n","Batch 790, Loss: 0.005741431377828121\n","Batch 800, Loss: 0.011470393277704716\n","Batch 810, Loss: 0.10762251913547516\n","Batch 820, Loss: 0.0412001833319664\n","Batch 830, Loss: 0.014063918963074684\n","Batch 840, Loss: 0.04042663425207138\n","Batch 850, Loss: 0.0399545319378376\n","Batch 860, Loss: 0.07798097282648087\n","Batch 870, Loss: 0.16615082323551178\n","Batch 880, Loss: 0.1485718935728073\n","Batch 890, Loss: 0.11771328002214432\n","Batch 900, Loss: 0.01269388385117054\n","Batch 910, Loss: 0.028903912752866745\n","Batch 920, Loss: 0.031141595914959908\n","Batch 930, Loss: 0.1137826144695282\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 1.069216 \n","\n","--------------------------------------------------\n","Epoch 93/100\n","Batch 0, Loss: 0.03115508146584034\n","Batch 10, Loss: 0.0017974295187741518\n","Batch 20, Loss: 0.04632299020886421\n","Batch 30, Loss: 0.036261048167943954\n","Batch 40, Loss: 0.05120589956641197\n","Batch 50, Loss: 0.0882197767496109\n","Batch 60, Loss: 0.09521160274744034\n","Batch 70, Loss: 0.07672242820262909\n","Batch 80, Loss: 0.009587038308382034\n","Batch 90, Loss: 0.013198978267610073\n","Batch 100, Loss: 0.005132672376930714\n","Batch 110, Loss: 0.01053503155708313\n","Batch 120, Loss: 0.021499041467905045\n","Batch 130, Loss: 0.00764560466632247\n","Batch 140, Loss: 0.014427419751882553\n","Batch 150, Loss: 0.10721287876367569\n","Batch 160, Loss: 0.03971990942955017\n","Batch 170, Loss: 0.06597010791301727\n","Batch 180, Loss: 0.0047712866216897964\n","Batch 190, Loss: 0.0335707850754261\n","Batch 200, Loss: 0.008360447362065315\n","Batch 210, Loss: 0.008540796115994453\n","Batch 220, Loss: 0.007976268418133259\n","Batch 230, Loss: 0.0002081808925140649\n","Batch 240, Loss: 0.008819732815027237\n","Batch 250, Loss: 0.001151770818978548\n","Batch 260, Loss: 0.023283787071704865\n","Batch 270, Loss: 0.023465188220143318\n","Batch 280, Loss: 0.010890490375459194\n","Batch 290, Loss: 0.033870305866003036\n","Batch 300, Loss: 0.0641368106007576\n","Batch 310, Loss: 0.007101544179022312\n","Batch 320, Loss: 0.0037035003770142794\n","Batch 330, Loss: 0.0074194613844156265\n","Batch 340, Loss: 0.0027892342768609524\n","Batch 350, Loss: 0.04911346733570099\n","Batch 360, Loss: 0.006028566509485245\n","Batch 370, Loss: 0.03256339207291603\n","Batch 380, Loss: 0.012386124581098557\n","Batch 390, Loss: 0.01649286411702633\n","Batch 400, Loss: 0.07213249057531357\n","Batch 410, Loss: 0.026067890226840973\n","Batch 420, Loss: 0.024900849908590317\n","Batch 430, Loss: 0.037377312779426575\n","Batch 440, Loss: 0.008401363156735897\n","Batch 450, Loss: 0.014450198039412498\n","Batch 460, Loss: 0.02347247675061226\n","Batch 470, Loss: 0.03566779941320419\n","Batch 480, Loss: 0.0018669632263481617\n","Batch 490, Loss: 0.01392459124326706\n","Batch 500, Loss: 0.010130547918379307\n","Batch 510, Loss: 0.059786077588796616\n","Batch 520, Loss: 0.03166048973798752\n","Batch 530, Loss: 0.004565168172121048\n","Batch 540, Loss: 0.010114298202097416\n","Batch 550, Loss: 0.030070709064602852\n","Batch 560, Loss: 0.027806879952549934\n","Batch 570, Loss: 0.0007560507510788739\n","Batch 580, Loss: 0.012486202642321587\n","Batch 590, Loss: 0.059149302542209625\n","Batch 600, Loss: 0.0020623730961233377\n","Batch 610, Loss: 0.04677978903055191\n","Batch 620, Loss: 0.002518574008718133\n","Batch 630, Loss: 0.001909920247271657\n","Batch 640, Loss: 0.014388059265911579\n","Batch 650, Loss: 0.005600583273917437\n","Batch 660, Loss: 0.0013058288022875786\n","Batch 670, Loss: 0.006665750406682491\n","Batch 680, Loss: 0.0820235088467598\n","Batch 690, Loss: 0.03380290046334267\n","Batch 700, Loss: 0.047451943159103394\n","Batch 710, Loss: 0.056285370141267776\n","Batch 720, Loss: 0.024452926591038704\n","Batch 730, Loss: 0.0011431314051151276\n","Batch 740, Loss: 0.0453573502600193\n","Batch 750, Loss: 0.0026146061718463898\n","Batch 760, Loss: 0.02644052915275097\n","Batch 770, Loss: 0.018187832087278366\n","Batch 780, Loss: 0.043901216238737106\n","Batch 790, Loss: 0.040989864617586136\n","Batch 800, Loss: 0.030619582161307335\n","Batch 810, Loss: 0.05995618551969528\n","Batch 820, Loss: 0.013580923900008202\n","Batch 830, Loss: 0.030474457889795303\n","Batch 840, Loss: 0.01754525676369667\n","Batch 850, Loss: 0.026691507548093796\n","Batch 860, Loss: 0.10822372138500214\n","Batch 870, Loss: 0.009573541581630707\n","Batch 880, Loss: 0.05151567980647087\n","Batch 890, Loss: 0.08556807786226273\n","Batch 900, Loss: 0.0894891619682312\n","Batch 910, Loss: 0.033972397446632385\n","Batch 920, Loss: 0.03795454651117325\n","Batch 930, Loss: 0.02190523035824299\n","Test Error: \n"," Accuracy: 89.1%, Avg loss: 1.057244 \n","\n","--------------------------------------------------\n","Epoch 94/100\n","Batch 0, Loss: 0.00028788269264623523\n","Batch 10, Loss: 0.03294217586517334\n","Batch 20, Loss: 0.04921340569853783\n","Batch 30, Loss: 0.07048127800226212\n","Batch 40, Loss: 0.002946501364931464\n","Batch 50, Loss: 0.09394028037786484\n","Batch 60, Loss: 0.008783701807260513\n","Batch 70, Loss: 0.007695009000599384\n","Batch 80, Loss: 0.04110466688871384\n","Batch 90, Loss: 0.013462401926517487\n","Batch 100, Loss: 0.17615120112895966\n","Batch 110, Loss: 0.008969911374151707\n","Batch 120, Loss: 0.0027858412358909845\n","Batch 130, Loss: 0.0004990289453417063\n","Batch 140, Loss: 0.006391989998519421\n","Batch 150, Loss: 0.0983351394534111\n","Batch 160, Loss: 0.0014420830411836505\n","Batch 170, Loss: 0.015810340642929077\n","Batch 180, Loss: 0.0024638932663947344\n","Batch 190, Loss: 0.0035452053416520357\n","Batch 200, Loss: 0.025016408413648605\n","Batch 210, Loss: 0.007647853344678879\n","Batch 220, Loss: 0.00029311777325347066\n","Batch 230, Loss: 0.018134837970137596\n","Batch 240, Loss: 0.025349631905555725\n","Batch 250, Loss: 0.02970372512936592\n","Batch 260, Loss: 0.09274142235517502\n","Batch 270, Loss: 0.007377383299171925\n","Batch 280, Loss: 0.012169661931693554\n","Batch 290, Loss: 0.0721682459115982\n","Batch 300, Loss: 0.0195388812571764\n","Batch 310, Loss: 0.009093177504837513\n","Batch 320, Loss: 0.1479077935218811\n","Batch 330, Loss: 0.0579446405172348\n","Batch 340, Loss: 0.09225919842720032\n","Batch 350, Loss: 0.01176638063043356\n","Batch 360, Loss: 0.020610420033335686\n","Batch 370, Loss: 0.046887412667274475\n","Batch 380, Loss: 0.02067927084863186\n","Batch 390, Loss: 0.05557609722018242\n","Batch 400, Loss: 0.022213710471987724\n","Batch 410, Loss: 0.012520935386419296\n","Batch 420, Loss: 0.0037740168627351522\n","Batch 430, Loss: 0.051782362163066864\n","Batch 440, Loss: 0.021572032943367958\n","Batch 450, Loss: 0.010136154480278492\n","Batch 460, Loss: 0.022532399743795395\n","Batch 470, Loss: 0.0317746065557003\n","Batch 480, Loss: 0.04778187721967697\n","Batch 490, Loss: 0.05627550184726715\n","Batch 500, Loss: 0.006322585977613926\n","Batch 510, Loss: 0.14929398894309998\n","Batch 520, Loss: 0.008248462341725826\n","Batch 530, Loss: 0.041119534522295\n","Batch 540, Loss: 0.025223197415471077\n","Batch 550, Loss: 0.07550989091396332\n","Batch 560, Loss: 0.023429781198501587\n","Batch 570, Loss: 0.2180529087781906\n","Batch 580, Loss: 0.014350736513733864\n","Batch 590, Loss: 0.0875789076089859\n","Batch 600, Loss: 0.05954575538635254\n","Batch 610, Loss: 0.22071994841098785\n","Batch 620, Loss: 0.10856813937425613\n","Batch 630, Loss: 0.0026275671552866697\n","Batch 640, Loss: 0.01311653945595026\n","Batch 650, Loss: 0.03689335659146309\n","Batch 660, Loss: 0.0506473109126091\n","Batch 670, Loss: 0.27748674154281616\n","Batch 680, Loss: 0.0062927138060331345\n","Batch 690, Loss: 0.03555262088775635\n","Batch 700, Loss: 0.031046615913510323\n","Batch 710, Loss: 0.02594158798456192\n","Batch 720, Loss: 0.0034077351447194815\n","Batch 730, Loss: 0.042469389736652374\n","Batch 740, Loss: 0.012685264460742474\n","Batch 750, Loss: 0.06866120547056198\n","Batch 760, Loss: 0.10094082355499268\n","Batch 770, Loss: 0.032598260790109634\n","Batch 780, Loss: 0.15445126593112946\n","Batch 790, Loss: 0.01380748301744461\n","Batch 800, Loss: 0.06687816232442856\n","Batch 810, Loss: 0.05801745504140854\n","Batch 820, Loss: 0.030430778861045837\n","Batch 830, Loss: 0.09997619688510895\n","Batch 840, Loss: 0.04673360288143158\n","Batch 850, Loss: 0.021520158275961876\n","Batch 860, Loss: 0.07539425045251846\n","Batch 870, Loss: 0.03536059707403183\n","Batch 880, Loss: 0.12132318317890167\n","Batch 890, Loss: 0.011073101311922073\n","Batch 900, Loss: 0.047446224838495255\n","Batch 910, Loss: 0.05561118200421333\n","Batch 920, Loss: 0.007599606644362211\n","Batch 930, Loss: 0.02290026657283306\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 1.025081 \n","\n","--------------------------------------------------\n","Epoch 95/100\n","Batch 0, Loss: 0.022625157609581947\n","Batch 10, Loss: 0.006239867303520441\n","Batch 20, Loss: 0.030848151072859764\n","Batch 30, Loss: 0.00118666747584939\n","Batch 40, Loss: 0.0003265056002419442\n","Batch 50, Loss: 0.008324279449880123\n","Batch 60, Loss: 0.0026813391596078873\n","Batch 70, Loss: 0.0045543573796749115\n","Batch 80, Loss: 0.0006432835943996906\n","Batch 90, Loss: 0.06290439516305923\n","Batch 100, Loss: 0.06391239911317825\n","Batch 110, Loss: 0.06718302518129349\n","Batch 120, Loss: 0.0005829131114296615\n","Batch 130, Loss: 0.0008153440430760384\n","Batch 140, Loss: 0.08210225403308868\n","Batch 150, Loss: 0.05055016279220581\n","Batch 160, Loss: 0.01005454733967781\n","Batch 170, Loss: 0.04447009786963463\n","Batch 180, Loss: 0.004529740195721388\n","Batch 190, Loss: 0.047332555055618286\n","Batch 200, Loss: 0.13451553881168365\n","Batch 210, Loss: 0.002775364089757204\n","Batch 220, Loss: 0.01755995862185955\n","Batch 230, Loss: 0.014353658072650433\n","Batch 240, Loss: 0.029076779261231422\n","Batch 250, Loss: 0.00496717682108283\n","Batch 260, Loss: 0.002436254173517227\n","Batch 270, Loss: 0.050401538610458374\n","Batch 280, Loss: 0.002417908748611808\n","Batch 290, Loss: 0.0062116095796227455\n","Batch 300, Loss: 0.07309138029813766\n","Batch 310, Loss: 0.06353379040956497\n","Batch 320, Loss: 0.0005705714575015008\n","Batch 330, Loss: 0.014716055244207382\n","Batch 340, Loss: 0.03925294056534767\n","Batch 350, Loss: 0.02936139516532421\n","Batch 360, Loss: 0.019638976082205772\n","Batch 370, Loss: 0.014375083148479462\n","Batch 380, Loss: 0.0027608568780124187\n","Batch 390, Loss: 0.008074648678302765\n","Batch 400, Loss: 0.032450832426548004\n","Batch 410, Loss: 0.004140743054449558\n","Batch 420, Loss: 0.004108008462935686\n","Batch 430, Loss: 0.004863074980676174\n","Batch 440, Loss: 0.0009924281621351838\n","Batch 450, Loss: 0.07843521237373352\n","Batch 460, Loss: 0.021355992183089256\n","Batch 470, Loss: 0.040185123682022095\n","Batch 480, Loss: 0.00579649955034256\n","Batch 490, Loss: 0.008029568940401077\n","Batch 500, Loss: 0.07437855005264282\n","Batch 510, Loss: 0.03783527761697769\n","Batch 520, Loss: 0.0033478112891316414\n","Batch 530, Loss: 0.02329261600971222\n","Batch 540, Loss: 0.07443191856145859\n","Batch 550, Loss: 0.037487369030714035\n","Batch 560, Loss: 0.005316787865012884\n","Batch 570, Loss: 0.03867657855153084\n","Batch 580, Loss: 0.03088611178100109\n","Batch 590, Loss: 0.005387012381106615\n","Batch 600, Loss: 0.07591649144887924\n","Batch 610, Loss: 0.003378360066562891\n","Batch 620, Loss: 0.007252546027302742\n","Batch 630, Loss: 0.0010368810035288334\n","Batch 640, Loss: 0.004797482863068581\n","Batch 650, Loss: 0.005195140838623047\n","Batch 660, Loss: 0.014139055274426937\n","Batch 670, Loss: 0.0015060886507853866\n","Batch 680, Loss: 0.007633327506482601\n","Batch 690, Loss: 0.005344270262867212\n","Batch 700, Loss: 0.13131970167160034\n","Batch 710, Loss: 0.017186753451824188\n","Batch 720, Loss: 0.03487018495798111\n","Batch 730, Loss: 0.027064094319939613\n","Batch 740, Loss: 0.05212249606847763\n","Batch 750, Loss: 0.0014445544220507145\n","Batch 760, Loss: 0.010322090238332748\n","Batch 770, Loss: 0.016483206301927567\n","Batch 780, Loss: 0.02294531650841236\n","Batch 790, Loss: 0.009784688241779804\n","Batch 800, Loss: 0.007071330212056637\n","Batch 810, Loss: 0.0014510622713714838\n","Batch 820, Loss: 0.0015348935266956687\n","Batch 830, Loss: 0.0739826038479805\n","Batch 840, Loss: 0.04182834178209305\n","Batch 850, Loss: 0.03354154899716377\n","Batch 860, Loss: 0.0017596216639503837\n","Batch 870, Loss: 0.00019459781469777226\n","Batch 880, Loss: 0.025995446369051933\n","Batch 890, Loss: 0.015607932582497597\n","Batch 900, Loss: 0.000839651096612215\n","Batch 910, Loss: 0.0031833667308092117\n","Batch 920, Loss: 0.003558400785550475\n","Batch 930, Loss: 0.012068148702383041\n","Test Error: \n"," Accuracy: 89.3%, Avg loss: 1.028136 \n","\n","--------------------------------------------------\n","Epoch 96/100\n","Batch 0, Loss: 0.021239861845970154\n","Batch 10, Loss: 0.06323900073766708\n","Batch 20, Loss: 0.013313322328031063\n","Batch 30, Loss: 0.004795738495886326\n","Batch 40, Loss: 0.006950984243303537\n","Batch 50, Loss: 0.03279660642147064\n","Batch 60, Loss: 0.09605385363101959\n","Batch 70, Loss: 0.004169996827840805\n","Batch 80, Loss: 0.00875786691904068\n","Batch 90, Loss: 0.042420078068971634\n","Batch 100, Loss: 0.0354740135371685\n","Batch 110, Loss: 0.0616559199988842\n","Batch 120, Loss: 0.0009689012076705694\n","Batch 130, Loss: 0.010449742898344994\n","Batch 140, Loss: 0.03415320813655853\n","Batch 150, Loss: 0.004370405338704586\n","Batch 160, Loss: 0.05620645731687546\n","Batch 170, Loss: 0.06374834477901459\n","Batch 180, Loss: 0.008223754353821278\n","Batch 190, Loss: 0.010215247049927711\n","Batch 200, Loss: 0.0030574193224310875\n","Batch 210, Loss: 0.0083695063367486\n","Batch 220, Loss: 0.044905368238687515\n","Batch 230, Loss: 0.0695604681968689\n","Batch 240, Loss: 0.004972260445356369\n","Batch 250, Loss: 0.005040118005126715\n","Batch 260, Loss: 0.0034909737296402454\n","Batch 270, Loss: 0.0031007230281829834\n","Batch 280, Loss: 0.030917637050151825\n","Batch 290, Loss: 0.0020992548670619726\n","Batch 300, Loss: 0.001487061264924705\n","Batch 310, Loss: 0.022089965641498566\n","Batch 320, Loss: 0.02147856168448925\n","Batch 330, Loss: 0.0026358880568295717\n","Batch 340, Loss: 0.005669784732162952\n","Batch 350, Loss: 0.08480554074048996\n","Batch 360, Loss: 0.42967382073402405\n","Batch 370, Loss: 0.011372188106179237\n","Batch 380, Loss: 0.008619079366326332\n","Batch 390, Loss: 0.07581580430269241\n","Batch 400, Loss: 0.03959490731358528\n","Batch 410, Loss: 0.01840128004550934\n","Batch 420, Loss: 0.0028059021569788456\n","Batch 430, Loss: 0.1348339170217514\n","Batch 440, Loss: 0.04590738192200661\n","Batch 450, Loss: 0.02130395919084549\n","Batch 460, Loss: 0.013599487952888012\n","Batch 470, Loss: 0.018217558041214943\n","Batch 480, Loss: 0.022290153428912163\n","Batch 490, Loss: 0.0006580476183444262\n","Batch 500, Loss: 0.0865221843123436\n","Batch 510, Loss: 0.04607433080673218\n","Batch 520, Loss: 0.011936280876398087\n","Batch 530, Loss: 0.023382745683193207\n","Batch 540, Loss: 0.012546264566481113\n","Batch 550, Loss: 0.005373359192162752\n","Batch 560, Loss: 0.013753479346632957\n","Batch 570, Loss: 0.013271584175527096\n","Batch 580, Loss: 0.0022224076092243195\n","Batch 590, Loss: 0.008103853091597557\n","Batch 600, Loss: 0.0011275915894657373\n","Batch 610, Loss: 0.011590022593736649\n","Batch 620, Loss: 0.033703774213790894\n","Batch 630, Loss: 0.01971110701560974\n","Batch 640, Loss: 0.0025027713272720575\n","Batch 650, Loss: 3.852051668218337e-05\n","Batch 660, Loss: 0.003660369198769331\n","Batch 670, Loss: 0.02434067614376545\n","Batch 680, Loss: 0.017296237871050835\n","Batch 690, Loss: 0.04548897221684456\n","Batch 700, Loss: 0.023385800421237946\n","Batch 710, Loss: 0.01003847736865282\n","Batch 720, Loss: 0.014640739187598228\n","Batch 730, Loss: 0.04387172311544418\n","Batch 740, Loss: 0.0030633702408522367\n","Batch 750, Loss: 0.0060583194717764854\n","Batch 760, Loss: 0.02548174560070038\n","Batch 770, Loss: 0.007689362391829491\n","Batch 780, Loss: 0.0063956119120121\n","Batch 790, Loss: 0.017389509826898575\n","Batch 800, Loss: 0.029870493337512016\n","Batch 810, Loss: 0.06078873202204704\n","Batch 820, Loss: 0.0713079646229744\n","Batch 830, Loss: 0.001126609742641449\n","Batch 840, Loss: 0.0014816559851169586\n","Batch 850, Loss: 0.001241010264493525\n","Batch 860, Loss: 0.013703872449696064\n","Batch 870, Loss: 0.011108801700174809\n","Batch 880, Loss: 0.023732269182801247\n","Batch 890, Loss: 0.1439630091190338\n","Batch 900, Loss: 0.0024113121908158064\n","Batch 910, Loss: 0.030360953882336617\n","Batch 920, Loss: 0.05748962610960007\n","Batch 930, Loss: 0.06742329150438309\n","Test Error: \n"," Accuracy: 89.2%, Avg loss: 1.051420 \n","\n","--------------------------------------------------\n","Epoch 97/100\n","Batch 0, Loss: 0.01615968905389309\n","Batch 10, Loss: 0.030042923986911774\n","Batch 20, Loss: 0.037295855581760406\n","Batch 30, Loss: 0.005654463544487953\n","Batch 40, Loss: 0.08749103546142578\n","Batch 50, Loss: 0.061413414776325226\n","Batch 60, Loss: 0.005584675818681717\n","Batch 70, Loss: 0.006954954005777836\n","Batch 80, Loss: 0.05159378796815872\n","Batch 90, Loss: 0.037680987268686295\n","Batch 100, Loss: 0.017832625657320023\n","Batch 110, Loss: 0.0681537389755249\n","Batch 120, Loss: 0.05027541518211365\n","Batch 130, Loss: 0.045106545090675354\n","Batch 140, Loss: 0.027896517887711525\n","Batch 150, Loss: 0.00618712417781353\n","Batch 160, Loss: 0.07405184209346771\n","Batch 170, Loss: 0.019993891939520836\n","Batch 180, Loss: 0.03655056282877922\n","Batch 190, Loss: 0.02979927882552147\n","Batch 200, Loss: 0.012513683177530766\n","Batch 210, Loss: 0.012816982343792915\n","Batch 220, Loss: 0.011449426412582397\n","Batch 230, Loss: 0.05166919156908989\n","Batch 240, Loss: 0.006174138281494379\n","Batch 250, Loss: 0.003325011348351836\n","Batch 260, Loss: 0.05037594586610794\n","Batch 270, Loss: 0.05294466391205788\n","Batch 280, Loss: 0.010744677856564522\n","Batch 290, Loss: 0.006071729119867086\n","Batch 300, Loss: 0.02908436767756939\n","Batch 310, Loss: 0.010133239440619946\n","Batch 320, Loss: 0.04159349948167801\n","Batch 330, Loss: 0.02497224137187004\n","Batch 340, Loss: 0.07514512538909912\n","Batch 350, Loss: 0.08834503591060638\n","Batch 360, Loss: 0.0008249204256571829\n","Batch 370, Loss: 0.01252714917063713\n","Batch 380, Loss: 0.05940582975745201\n","Batch 390, Loss: 0.05607990175485611\n","Batch 400, Loss: 0.0012769140303134918\n","Batch 410, Loss: 0.019280176609754562\n","Batch 420, Loss: 0.00218426575884223\n","Batch 430, Loss: 0.004282042849808931\n","Batch 440, Loss: 0.10760896652936935\n","Batch 450, Loss: 0.088292196393013\n","Batch 460, Loss: 0.03657951205968857\n","Batch 470, Loss: 0.01160032395273447\n","Batch 480, Loss: 0.033090267330408096\n","Batch 490, Loss: 0.00045954942470416427\n","Batch 500, Loss: 0.04547511786222458\n","Batch 510, Loss: 0.0056267608888447285\n","Batch 520, Loss: 0.033018920570611954\n","Batch 530, Loss: 0.15275797247886658\n","Batch 540, Loss: 0.0271590668708086\n","Batch 550, Loss: 0.028424590826034546\n","Batch 560, Loss: 0.002225944772362709\n","Batch 570, Loss: 0.009026426821947098\n","Batch 580, Loss: 0.020981216803193092\n","Batch 590, Loss: 0.0009035307448357344\n","Batch 600, Loss: 0.02905251458287239\n","Batch 610, Loss: 0.10883874446153641\n","Batch 620, Loss: 0.002325589768588543\n","Batch 630, Loss: 0.12121668457984924\n","Batch 640, Loss: 5.068104655947536e-05\n","Batch 650, Loss: 0.00859154388308525\n","Batch 660, Loss: 0.0384095124900341\n","Batch 670, Loss: 0.004073175135999918\n","Batch 680, Loss: 0.007345778867602348\n","Batch 690, Loss: 0.06572151929140091\n","Batch 700, Loss: 0.028573861345648766\n","Batch 710, Loss: 0.010186297819018364\n","Batch 720, Loss: 0.03510613739490509\n","Batch 730, Loss: 0.0182843916118145\n","Batch 740, Loss: 0.00243980810046196\n","Batch 750, Loss: 0.003274092450737953\n","Batch 760, Loss: 0.11476998776197433\n","Batch 770, Loss: 0.006228594109416008\n","Batch 780, Loss: 0.07115083187818527\n","Batch 790, Loss: 0.02241336740553379\n","Batch 800, Loss: 0.004633775912225246\n","Batch 810, Loss: 0.006777554750442505\n","Batch 820, Loss: 0.0002862745022866875\n","Batch 830, Loss: 0.004761808551847935\n","Batch 840, Loss: 0.03199383243918419\n","Batch 850, Loss: 0.004368904512375593\n","Batch 860, Loss: 0.09283389896154404\n","Batch 870, Loss: 0.004493460059165955\n","Batch 880, Loss: 0.00027032976504415274\n","Batch 890, Loss: 0.022010590881109238\n","Batch 900, Loss: 0.055640798062086105\n","Batch 910, Loss: 0.0025074738077819347\n","Batch 920, Loss: 0.01878633350133896\n","Batch 930, Loss: 0.035997722297906876\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.998634 \n","\n","--------------------------------------------------\n","Epoch 98/100\n","Batch 0, Loss: 0.0010565418051555753\n","Batch 10, Loss: 0.04357380047440529\n","Batch 20, Loss: 0.010112973861396313\n","Batch 30, Loss: 0.03521144390106201\n","Batch 40, Loss: 0.07618261128664017\n","Batch 50, Loss: 0.01448589377105236\n","Batch 60, Loss: 0.0024514461401849985\n","Batch 70, Loss: 0.003243229817599058\n","Batch 80, Loss: 0.001795359537936747\n","Batch 90, Loss: 0.06086652725934982\n","Batch 100, Loss: 0.0052751763723790646\n","Batch 110, Loss: 0.00029854197055101395\n","Batch 120, Loss: 0.00046735932119190693\n","Batch 130, Loss: 0.020247340202331543\n","Batch 140, Loss: 0.009126259945333004\n","Batch 150, Loss: 0.001894405111670494\n","Batch 160, Loss: 0.007392167113721371\n","Batch 170, Loss: 0.0035216358955949545\n","Batch 180, Loss: 0.08742750436067581\n","Batch 190, Loss: 0.019617894664406776\n","Batch 200, Loss: 0.0181929599493742\n","Batch 210, Loss: 0.0023926743306219578\n","Batch 220, Loss: 0.004158559255301952\n","Batch 230, Loss: 0.07980665564537048\n","Batch 240, Loss: 0.010394608601927757\n","Batch 250, Loss: 0.001322788535617292\n","Batch 260, Loss: 0.011900092475116253\n","Batch 270, Loss: 0.15541015565395355\n","Batch 280, Loss: 0.029403075575828552\n","Batch 290, Loss: 0.08569877594709396\n","Batch 300, Loss: 0.0016338326968252659\n","Batch 310, Loss: 0.01210666261613369\n","Batch 320, Loss: 0.0019366861088201404\n","Batch 330, Loss: 0.001962188398465514\n","Batch 340, Loss: 0.0036040095146745443\n","Batch 350, Loss: 0.02101331390440464\n","Batch 360, Loss: 0.055666908621788025\n","Batch 370, Loss: 0.008188122883439064\n","Batch 380, Loss: 0.0012569325044751167\n","Batch 390, Loss: 0.006333753000944853\n","Batch 400, Loss: 0.0038084122352302074\n","Batch 410, Loss: 1.063523450284265e-05\n","Batch 420, Loss: 0.012381810694932938\n","Batch 430, Loss: 0.0018124523339793086\n","Batch 440, Loss: 0.00495908921584487\n","Batch 450, Loss: 0.030621418729424477\n","Batch 460, Loss: 0.056290388107299805\n","Batch 470, Loss: 0.006319534033536911\n","Batch 480, Loss: 0.061322569847106934\n","Batch 490, Loss: 0.043028574436903\n","Batch 500, Loss: 0.0108342869207263\n","Batch 510, Loss: 0.03317582607269287\n","Batch 520, Loss: 0.19979874789714813\n","Batch 530, Loss: 0.005771380849182606\n","Batch 540, Loss: 0.048518985509872437\n","Batch 550, Loss: 0.007003838662058115\n","Batch 560, Loss: 0.048055216670036316\n","Batch 570, Loss: 0.018924305215477943\n","Batch 580, Loss: 0.04306955635547638\n","Batch 590, Loss: 0.2262398600578308\n","Batch 600, Loss: 0.06800207495689392\n","Batch 610, Loss: 0.011093338951468468\n","Batch 620, Loss: 0.06208353489637375\n","Batch 630, Loss: 0.02672329545021057\n","Batch 640, Loss: 0.10327466577291489\n","Batch 650, Loss: 0.13951528072357178\n","Batch 660, Loss: 0.025369547307491302\n","Batch 670, Loss: 0.005151140037924051\n","Batch 680, Loss: 0.010209777392446995\n","Batch 690, Loss: 0.003457761835306883\n","Batch 700, Loss: 0.007065458223223686\n","Batch 710, Loss: 0.05881420522928238\n","Batch 720, Loss: 0.016304565593600273\n","Batch 730, Loss: 0.044692423194646835\n","Batch 740, Loss: 0.003942999988794327\n","Batch 750, Loss: 0.04434516653418541\n","Batch 760, Loss: 0.025388631969690323\n","Batch 770, Loss: 0.04989755153656006\n","Batch 780, Loss: 0.047950126230716705\n","Batch 790, Loss: 0.007468870375305414\n","Batch 800, Loss: 0.007460433058440685\n","Batch 810, Loss: 0.04194114729762077\n","Batch 820, Loss: 0.03506981208920479\n","Batch 830, Loss: 0.03086482733488083\n","Batch 840, Loss: 0.035330630838871\n","Batch 850, Loss: 0.08784279227256775\n","Batch 860, Loss: 0.005344511941075325\n","Batch 870, Loss: 0.03246429190039635\n","Batch 880, Loss: 0.023461787030100822\n","Batch 890, Loss: 0.00529510248452425\n","Batch 900, Loss: 0.0025273298379033804\n","Batch 910, Loss: 0.0018808573950082064\n","Batch 920, Loss: 0.015007086098194122\n","Batch 930, Loss: 0.09975579380989075\n","Test Error: \n"," Accuracy: 89.1%, Avg loss: 1.160025 \n","\n","--------------------------------------------------\n","Epoch 99/100\n","Batch 0, Loss: 0.13623636960983276\n","Batch 10, Loss: 0.06273189932107925\n","Batch 20, Loss: 0.010679397732019424\n","Batch 30, Loss: 0.047308098524808884\n","Batch 40, Loss: 0.009333465248346329\n","Batch 50, Loss: 0.005946894641965628\n","Batch 60, Loss: 0.001582369557581842\n","Batch 70, Loss: 0.010488538071513176\n","Batch 80, Loss: 0.0037238355726003647\n","Batch 90, Loss: 0.028913652524352074\n","Batch 100, Loss: 0.0021529283840209246\n","Batch 110, Loss: 0.05849112942814827\n","Batch 120, Loss: 0.009585590101778507\n","Batch 130, Loss: 0.00223827688023448\n","Batch 140, Loss: 0.05775144696235657\n","Batch 150, Loss: 0.018330184742808342\n","Batch 160, Loss: 0.004282000474631786\n","Batch 170, Loss: 0.010734798386693\n","Batch 180, Loss: 0.015691397711634636\n","Batch 190, Loss: 0.03744925931096077\n","Batch 200, Loss: 0.08548781275749207\n","Batch 210, Loss: 0.01614266261458397\n","Batch 220, Loss: 0.019794749096035957\n","Batch 230, Loss: 0.015026532113552094\n","Batch 240, Loss: 0.0012635033344849944\n","Batch 250, Loss: 0.0005711998092010617\n","Batch 260, Loss: 0.00276527414098382\n","Batch 270, Loss: 0.0010455850278958678\n","Batch 280, Loss: 0.0020783531945198774\n","Batch 290, Loss: 0.03197875991463661\n","Batch 300, Loss: 0.07059340178966522\n","Batch 310, Loss: 0.011557639576494694\n","Batch 320, Loss: 0.0035944455303251743\n","Batch 330, Loss: 0.007945678196847439\n","Batch 340, Loss: 0.0009065907215699553\n","Batch 350, Loss: 0.0018110566306859255\n","Batch 360, Loss: 0.001644979463890195\n","Batch 370, Loss: 0.04903900623321533\n","Batch 380, Loss: 0.0038845736999064684\n","Batch 390, Loss: 0.038811855018138885\n","Batch 400, Loss: 0.049346938729286194\n","Batch 410, Loss: 0.030620772391557693\n","Batch 420, Loss: 0.0007174224592745304\n","Batch 430, Loss: 0.0026541713159531355\n","Batch 440, Loss: 0.008689834736287594\n","Batch 450, Loss: 0.0014654488768428564\n","Batch 460, Loss: 0.013962896540760994\n","Batch 470, Loss: 0.0658913180232048\n","Batch 480, Loss: 0.00028639088850468397\n","Batch 490, Loss: 0.021739192306995392\n","Batch 500, Loss: 0.0053496891632676125\n","Batch 510, Loss: 0.017180800437927246\n","Batch 520, Loss: 0.021543586626648903\n","Batch 530, Loss: 0.06701317429542542\n","Batch 540, Loss: 0.0024486605543643236\n","Batch 550, Loss: 0.03959767892956734\n","Batch 560, Loss: 0.0011937281815335155\n","Batch 570, Loss: 0.07332214713096619\n","Batch 580, Loss: 0.04359814152121544\n","Batch 590, Loss: 0.00012635682651307434\n","Batch 600, Loss: 0.023534705862402916\n","Batch 610, Loss: 0.04494968801736832\n","Batch 620, Loss: 0.0277607012540102\n","Batch 630, Loss: 0.005510690156370401\n","Batch 640, Loss: 0.0018567010993137956\n","Batch 650, Loss: 0.003887876169756055\n","Batch 660, Loss: 0.018201913684606552\n","Batch 670, Loss: 0.022736426442861557\n","Batch 680, Loss: 0.02586599625647068\n","Batch 690, Loss: 0.03499201312661171\n","Batch 700, Loss: 0.02557852491736412\n","Batch 710, Loss: 0.017072102054953575\n","Batch 720, Loss: 0.16306814551353455\n","Batch 730, Loss: 0.001854723785072565\n","Batch 740, Loss: 0.054923996329307556\n","Batch 750, Loss: 0.0015752223553135991\n","Batch 760, Loss: 0.007440680637955666\n","Batch 770, Loss: 0.015774376690387726\n","Batch 780, Loss: 0.024433480575680733\n","Batch 790, Loss: 0.004252322018146515\n","Batch 800, Loss: 0.13020206987857819\n","Batch 810, Loss: 0.0038798984605818987\n","Batch 820, Loss: 0.08661337196826935\n","Batch 830, Loss: 0.0020140630658715963\n","Batch 840, Loss: 0.05486210435628891\n","Batch 850, Loss: 0.11557517945766449\n","Batch 860, Loss: 0.0355190671980381\n","Batch 870, Loss: 0.07837872207164764\n","Batch 880, Loss: 0.049641456454992294\n","Batch 890, Loss: 0.0519992895424366\n","Batch 900, Loss: 0.024139542132616043\n","Batch 910, Loss: 0.005828057881444693\n","Batch 920, Loss: 0.0046925111673772335\n","Batch 930, Loss: 0.03553108870983124\n","Test Error: \n"," Accuracy: 89.6%, Avg loss: 1.131775 \n","\n","--------------------------------------------------\n","Epoch 100/100\n","Batch 0, Loss: 0.12986336648464203\n","Batch 10, Loss: 0.007926789112389088\n","Batch 20, Loss: 0.004139867145568132\n","Batch 30, Loss: 0.01128370314836502\n","Batch 40, Loss: 0.005720160901546478\n","Batch 50, Loss: 0.0035718996077775955\n","Batch 60, Loss: 0.005888414569199085\n","Batch 70, Loss: 0.020860351622104645\n","Batch 80, Loss: 0.0013518462656065822\n","Batch 90, Loss: 0.06376651674509048\n","Batch 100, Loss: 0.01375475712120533\n","Batch 110, Loss: 0.0012039293069392443\n","Batch 120, Loss: 0.0423397421836853\n","Batch 130, Loss: 0.00021574947459157556\n","Batch 140, Loss: 0.0017553574871271849\n","Batch 150, Loss: 0.0109145762398839\n","Batch 160, Loss: 0.0035458095371723175\n","Batch 170, Loss: 0.03686806187033653\n","Batch 180, Loss: 0.005036305636167526\n","Batch 190, Loss: 0.0034609311260282993\n","Batch 200, Loss: 0.011428039520978928\n","Batch 210, Loss: 0.05302590876817703\n","Batch 220, Loss: 0.01148452702909708\n","Batch 230, Loss: 0.008289766497910023\n","Batch 240, Loss: 0.0051922607235610485\n","Batch 250, Loss: 0.029071234166622162\n","Batch 260, Loss: 0.00013874663272872567\n","Batch 270, Loss: 0.011087781749665737\n","Batch 280, Loss: 0.004646872170269489\n","Batch 290, Loss: 0.007177002727985382\n","Batch 300, Loss: 0.03506247326731682\n","Batch 310, Loss: 0.0015449123457074165\n","Batch 320, Loss: 0.006874251179397106\n","Batch 330, Loss: 0.0017835474573075771\n","Batch 340, Loss: 0.0014374128077179193\n","Batch 350, Loss: 0.03735866770148277\n","Batch 360, Loss: 0.05543285235762596\n","Batch 370, Loss: 0.00042561793816275895\n","Batch 380, Loss: 0.009624801576137543\n","Batch 390, Loss: 0.0028270594775676727\n","Batch 400, Loss: 0.005074096843600273\n","Batch 410, Loss: 0.004224963486194611\n","Batch 420, Loss: 0.001021294854581356\n","Batch 430, Loss: 0.01539203617721796\n","Batch 440, Loss: 0.007035469636321068\n","Batch 450, Loss: 0.04234304279088974\n","Batch 460, Loss: 0.09306727349758148\n","Batch 470, Loss: 0.0012545146746560931\n","Batch 480, Loss: 0.0179931428283453\n","Batch 490, Loss: 0.13836127519607544\n","Batch 500, Loss: 0.042525514960289\n","Batch 510, Loss: 0.019744591787457466\n","Batch 520, Loss: 0.039172861725091934\n","Batch 530, Loss: 0.026397302746772766\n","Batch 540, Loss: 0.004728821571916342\n","Batch 550, Loss: 0.0008005845593288541\n","Batch 560, Loss: 0.06397368758916855\n","Batch 570, Loss: 0.0534997321665287\n","Batch 580, Loss: 0.0007349351071752608\n","Batch 590, Loss: 0.00532252574339509\n","Batch 600, Loss: 0.01228285487741232\n","Batch 610, Loss: 0.04898325353860855\n","Batch 620, Loss: 0.00016372810932807624\n","Batch 630, Loss: 0.030527252703905106\n","Batch 640, Loss: 0.006651295814663172\n","Batch 650, Loss: 0.004744112491607666\n","Batch 660, Loss: 0.0008758002077229321\n","Batch 670, Loss: 0.03757895901799202\n","Batch 680, Loss: 0.04192786291241646\n","Batch 690, Loss: 0.014864865690469742\n","Batch 700, Loss: 0.02097693271934986\n","Batch 710, Loss: 0.0021792808547616005\n","Batch 720, Loss: 0.011426441371440887\n","Batch 730, Loss: 0.14810572564601898\n","Batch 740, Loss: 0.003286989638581872\n","Batch 750, Loss: 0.035356342792510986\n","Batch 760, Loss: 0.05660456418991089\n","Batch 770, Loss: 0.010974136181175709\n","Batch 780, Loss: 0.10164415091276169\n","Batch 790, Loss: 0.00037379536661319435\n","Batch 800, Loss: 0.14065569639205933\n","Batch 810, Loss: 0.043087203055620193\n","Batch 820, Loss: 0.05158603936433792\n","Batch 830, Loss: 0.04486967250704765\n","Batch 840, Loss: 0.029297981411218643\n","Batch 850, Loss: 0.007835758849978447\n","Batch 860, Loss: 0.0022578786592930555\n","Batch 870, Loss: 0.004149407148361206\n","Batch 880, Loss: 0.036330197006464005\n","Batch 890, Loss: 0.034862641245126724\n","Batch 900, Loss: 0.024466726928949356\n","Batch 910, Loss: 0.04205351322889328\n","Batch 920, Loss: 0.008747058920562267\n","Batch 930, Loss: 0.0034878256265074015\n","Test Error: \n"," Accuracy: 89.8%, Avg loss: 1.162360 \n","\n","--------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["# 17번\n","- 학습된 파라미터를 저장합니다.\n","- 파일명은 model_weights.pth로 합니다.\n","- 3점"],"metadata":{"id":"fMblMnMHKO7N"}},{"cell_type":"code","source":["torch.save(model.state_dict(), \"model_weights.pth\")\n","print('Model weights saved to model_weights.pth')"],"metadata":{"id":"YuBsJQRyNMY3","executionInfo":{"status":"ok","timestamp":1721353649512,"user_tz":-540,"elapsed":534,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bd78bb5-0166-4a73-b79d-873e8ef61bb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model weights saved to model_weights.pth\n"]}]},{"cell_type":"markdown","source":["# 18번\n","- 새로운 인공신경망을 GPU에 만들고 위 학습된 파일(model_weights.pth)을 불러옵니다.\n","- 3점"],"metadata":{"id":"9umiR2NoKb5Q"}},{"cell_type":"code","source":["# 새로운 인공신경망 생성 및 GPU로 이동\n","new_model = NeuralNetwork().to(device)\n","\n","# 학습된 파라미터 불러오기\n","new_model.load_state_dict(torch.load(\"model_weights.pth\"))\n","\n","# 모델 출력\n","print(new_model)"],"metadata":{"id":"XVzspxniNYcr","executionInfo":{"status":"ok","timestamp":1721353660761,"user_tz":-540,"elapsed":585,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4f0c1a9-a0b9-475c-cca1-8984f36aec45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["# 19번\n","- 위 모델에 test 데이터로더를 입력하고 결과를 확인합니다.\n","- 3점"],"metadata":{"id":"wJvuPDtHKrAM"}},{"cell_type":"code","source":["# 결과를 저장할 리스트\n","all_images = []\n","all_labels = []\n","all_preds = []\n","# 테스트 데이터로더를 통한 반복\n","with torch.no_grad():  # Gradient 계산을 비활성화\n","    for inputs, labels in test_loader:\n","        # 데이터를 GPU로 이동\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # 모델의 예측 수행\n","        outputs = new_model(inputs)\n","        # 예측 값을 가져오기\n","        _, preds = torch.max(outputs, 1)\n","        # 결과를 리스트에 추가\n","        all_images.append(inputs.cpu())\n","        all_labels.append(labels.cpu())\n","        all_preds.append(preds.cpu())\n","        # 필요에 따라 몇 샘플만 가져올 수 있습니다.\n","        break  # 여기를 제거하면 전체 데이터를 확인할 수 있습니다.\n","# 모든 이미지, 레이블, 예측을 결합\n","all_images = torch.cat(all_images)\n","all_labels = torch.cat(all_labels)\n","all_preds = torch.cat(all_preds)\n","# 예측 결과와 실제 레이블을 출력\n","print(\"이미지:\", all_images)\n","print(\"예측 결과:\", all_preds)\n","print(\"실제 레이블:\", all_labels)"],"metadata":{"id":"yiBSjIpkX1ma","executionInfo":{"status":"ok","timestamp":1721353723523,"user_tz":-540,"elapsed":2362,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c983109-ea24-4ee9-9e27-008c81b2e523"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이미지: tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        ...,\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]],\n","\n","\n","        [[[0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          ...,\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.],\n","          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n","예측 결과: tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 5, 3, 4, 1, 2, 2, 8, 0, 2, 5, 7, 5,\n","        1, 6, 6, 0, 9, 4, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 0, 1, 6, 7, 6, 7, 2, 1,\n","        2, 2, 4, 2, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n","실제 레이블: tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n","        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n","        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"]}]},{"cell_type":"markdown","source":["# 20번\n","- 2행 5열로 test 데이터를 이미지로 출력합니다.\n","- 학습된 모델이 분류기가 잘 작동하는지 label과 예측된 결과를 동시에 출력합니다.\n","- 3점"],"metadata":{"id":"ypSNt_7N9Wk8"}},{"cell_type":"code","source":["# 이미지를 2행 5열로 출력\n","num_images = 10\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","axes = axes.flatten()\n","for i in range(num_images):\n","    # 이미지를 numpy 배열로 변환 (예: [C, H, W] -> [H, W, C])\n","    image = all_images[i].permute(1, 2, 0).numpy()\n","    # 레이블과 예측 결과 가져오기\n","    label = all_labels[i].item()\n","    pred = all_preds[i].item()\n","    # 이미지 출력\n","    axes[i].imshow(image, cmap='gray')\n","    axes[i].set_title(f\"Label: {label}\\nPred: {pred}\")\n","    axes[i].axis('off')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"rO8Qqv-dYL1Q","executionInfo":{"status":"ok","timestamp":1721353767391,"user_tz":-540,"elapsed":1488,"user":{"displayName":"Heeseon Im","userId":"07947113443531630188"}},"colab":{"base_uri":"https://localhost:8080/","height":472},"outputId":"13b96d7e-b27d-4da2-f132-e12efcf36c35"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x600 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"waRpPx7flAFJ"},"execution_count":null,"outputs":[]}]}